根據你提供的程式碼，目前的做法是分別針對不同來源（例如 InstantReviewT 與 InstantReviewRt）的差分圖進行處理，然後各自生成獨立的 YOLO 訓練圖片及其對應的標籤。也就是說：

程式會依據圖像類型（例如 "T" 代表測試圖、"Rt" 代表另一角度的測試圖）來分別生成處理後的差分圖。
在生成元數據（例如在 db_to_metadata 函數中），程式將每個缺陷分別記錄為兩個條目，一個對應 InstantReviewT，一個對應 InstantReviewRt。
在 create_dataset 中，對於每個缺陷，分別保存兩張圖像（例如 "T_123_diff.png" 與 "Rt_123_diff.png"，雖然你的代碼中，兩者可能在不同資料夾或依據 diff_map 模式決定）。
這兩張圖片各自擁有獨立的標籤檔案，供 YOLO 訓練時使用。


總結來說，根據你現有的程式碼：

每一個圖像（不論是 T 還是 Rt）都是獨立處理並存成單獨的訓練樣本，
如果你的訓練策略是讓 YOLO 從單一圖片中檢測缺陷，那麼它就會針對每個視角分別進行學習，
如果你想融合多視角資訊，就需要修改預處理流程將它們合併後再生成訓練數據。

在你目前的程式碼中（例如在 create_dataset → process_data 函數中），"T_123_diff.png" 和 "Rt_123_diff.png" 會根據它們的檔案名稱區分，但它們會存放在同一個目標圖片資料夾中（例如 train/images、val/images 或 test/images），而不會自動分到不同的資料夾中。

也就是說，你是透過檔名前面的 "T_" 或 "Rt_" 來區分這兩種圖片，而不是透過不同的資料夾結構來分開存放。
