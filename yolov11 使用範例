æ•°æ®é›†é…ç½®æ–‡ä»¶ç¤ºä¾‹ï¼ˆdataset.yamlï¼‰ï¼š
train: path/to/your/train/images  # è®­ç»ƒå›¾åƒæ–‡ä»¶å¤¹è·¯å¾„
val: path/to/your/val/images      # éªŒè¯å›¾åƒæ–‡ä»¶å¤¹è·¯å¾„

names:
  0: defect_type_1
  1: defect_type_2
  # æ·»åŠ æ›´å¤šç±»åˆ«



ç›®å½•ç»“æ„ç¤ºä¾‹ï¼š
datasets/
    my_dataset/
        images/
            train/  # è®­ç»ƒå›¾ç‰‡
            val/    # éªŒè¯å›¾ç‰‡
        labels/
            train/  # è®­ç»ƒæ ‡ç­¾ (YOLOæ ¼å¼)
            val/    # éªŒè¯æ ‡ç­¾ (YOLOæ ¼å¼)







########################yolov11 ä½¿ç”¨é æ¸¬å¤šç¨®é¡/æ•´é«”   ç¼ºé™·æƒ…æ³ sample code###########################

import torch
from yolov11 import YOLOv11  # å‡è®¾æœ‰ä¸€ä¸ª YOLOv11 çš„ Python å®ç°

# åŠ è½½é¢„è®­ç»ƒçš„ YOLOv11 æ¨¡å‹
model = YOLOv11(pretrained=True)
model.eval()

# å®šä¹‰éªŒè¯æ•°æ®é›†çš„è·¯å¾„
val_data_path = 'path/to/your/validation/dataset'  # æ›¿æ¢ä¸ºæ‚¨çš„éªŒè¯æ•°æ®é›†è·¯å¾„

# æ‰§è¡ŒéªŒè¯
results = model.val(data=val_data_path)

# è¾“å‡ºæ•´ä½“è¯„ä¼°æŒ‡æ ‡
print(f"Overall mAP@0.5: {results['mAP_0.5']:.4f}")
print(f"Overall mAP@0.5:0.95: {results['mAP_0.5:0.95']:.4f}")
print(f"Overall Precision: {results['precision']:.4f}")
print(f"Overall Recall: {results['recall']:.4f}")
print(f"Overall F1 Score: {results['f1']:.4f}")

# è¾“å‡ºæ¯ä¸ªç±»åˆ«çš„è¯„ä¼°æŒ‡æ ‡
for idx, class_name in enumerate(results['names']):
    class_precision = results['per_class_precision'][idx]
    class_recall = results['per_class_recall'][idx]
    class_f1 = results['per_class_f1'][idx]
    class_ap = results['per_class_ap'][idx]
    print(f"Class: {class_name}")
    print(f"  Precision: {class_precision:.4f}")
    print(f"  Recall: {class_recall:.4f}")
    print(f"  F1 Score: {class_f1:.4f}")
    print(f"  AP@0.5: {class_ap:.4f}")



æ³¨æ„äº‹é¡¹ï¼š

ç»“æœå­—å…¸ç»“æ„ï¼šä¸Šè¿°ä»£ç å‡è®¾ results å­—å…¸åŒ…å«ä»¥ä¸‹é”®ï¼š

'mAP_0.5'ï¼šæ•´ä½“ mAP@0.5 å€¼ã€‚
'mAP_0.5:0.95'ï¼šæ•´ä½“ mAP@0.5:0.95 å€¼ã€‚
'precision'ï¼šæ•´ä½“ç²¾åº¦ã€‚
'recall'ï¼šæ•´ä½“å¬å›ç‡ã€‚
'f1'ï¼šæ•´ä½“ F1 åˆ†æ•°ã€‚
'names'ï¼šç±»åˆ«åç§°åˆ—è¡¨ã€‚
'per_class_precision'ï¼šæ¯ä¸ªç±»åˆ«çš„ç²¾åº¦åˆ—è¡¨ã€‚
'per_class_recall'ï¼šæ¯ä¸ªç±»åˆ«çš„å¬å›ç‡åˆ—è¡¨ã€‚
'per_class_f1'ï¼šæ¯ä¸ªç±»åˆ«çš„ F1 åˆ†æ•°åˆ—è¡¨ã€‚
'per_class_ap'ï¼šæ¯ä¸ªç±»åˆ«çš„ AP@0.5 å€¼åˆ—è¡¨ã€‚
æ¨¡å‹å®ç°ï¼šç¡®ä¿æ‚¨ä½¿ç”¨çš„ YOLOv11 å®ç°çš„ val æ–¹æ³•è¿”å›çš„ results å­—å…¸åŒ…å«ä¸Šè¿°é”®ã€‚å¦‚æœæ²¡æœ‰ï¼Œæ‚¨å¯èƒ½éœ€è¦æŸ¥çœ‹æ¨¡å‹çš„æºç ï¼Œäº†è§£å¦‚ä½•æå–æ¯ä¸ªç±»åˆ«çš„è¯„ä¼°æŒ‡æ ‡ã€‚

è¯„ä¼°æŒ‡æ ‡è®¡ç®—ï¼šå¦‚æœæ¨¡å‹æœªæä¾›æ¯ä¸ªç±»åˆ«çš„æŒ‡æ ‡ï¼Œæ‚¨å¯èƒ½éœ€è¦æ‰‹åŠ¨è®¡ç®—ã€‚è¿™æ¶‰åŠå°†é¢„æµ‹ç»“æœä¸çœŸå®æ ‡ç­¾è¿›è¡Œæ¯”è¾ƒï¼Œè®¡ç®—æ¯ä¸ªç±»åˆ«çš„ TPã€FPã€FNï¼Œç„¶åæ ¹æ®è¿™äº›å€¼è®¡ç®—ç²¾åº¦ã€å¬å›ç‡å’Œ F1 åˆ†æ•°ã€‚è¿™å¯èƒ½éœ€è¦æ·±å…¥äº†è§£æ¨¡å‹çš„è¾“å‡ºæ ¼å¼å’Œè¯„ä¼°æµç¨‹ã€‚

é€šè¿‡ä¸Šè¿°ä¿®æ”¹ï¼Œæ‚¨çš„ä»£ç å°†èƒ½å¤Ÿè¾“å‡ºæ¯ä¸ªç¼ºé™·ç±»åˆ«çš„è¯„ä¼°æŒ‡æ ‡ï¼Œå¸®åŠ©æ‚¨æ›´ç»†è‡´åœ°è¯„ä¼°æ¨¡å‹åœ¨å„ä¸ªç±»åˆ«ä¸Šçš„æ€§èƒ½ã€‚




åœ¨ç›®æ ‡æ£€æµ‹ä»»åŠ¡ä¸­ï¼Œè¯„ä¼°æ¨¡å‹æ€§èƒ½çš„æŒ‡æ ‡ä¸»è¦åŒ…æ‹¬ç²¾ç¡®ç‡ï¼ˆPrecisionï¼‰ã€å¬å›ç‡ï¼ˆRecallï¼‰ã€F1 åˆ†æ•°ï¼ˆF1 Scoreï¼‰ã€å¹³å‡ç²¾åº¦ï¼ˆAPï¼‰å’Œå¹³å‡ç²¾åº¦å‡å€¼ï¼ˆmAPï¼‰ã€‚ç†è§£è¿™äº›æŒ‡æ ‡çš„è®¡ç®—å…¬å¼å’Œç›®çš„ï¼Œæœ‰åŠ©äºåˆ¤æ–­æ¨¡å‹çš„ä¼˜åŠ£ï¼Œå¹¶å‘ä»–äººæ¸…æ™°åœ°è§£é‡Šæ¨¡å‹æ€§èƒ½ã€‚

1. ç²¾ç¡®ç‡ï¼ˆPrecisionï¼‰

è®¡ç®—å…¬å¼ï¼š

Precision
=
ğ‘‡
ğ‘ƒ
ğ‘‡
ğ‘ƒ
+
ğ¹
ğ‘ƒ
Precision= 
TP+FP
TP
â€‹
 

å…¶ä¸­ï¼ŒTPï¼ˆTrue Positiveï¼‰è¡¨ç¤ºè¢«æ­£ç¡®æ£€æµ‹ä¸ºç›®æ ‡çš„æ•°é‡ï¼ŒFPï¼ˆFalse Positiveï¼‰è¡¨ç¤ºè¢«é”™è¯¯æ£€æµ‹ä¸ºç›®æ ‡çš„æ•°é‡ã€‚

ç›®çš„ï¼š

ç²¾ç¡®ç‡è¡¡é‡æ¨¡å‹é¢„æµ‹çš„å‡†ç¡®æ€§ï¼Œå³æ¨¡å‹é¢„æµ‹ä¸ºç›®æ ‡çš„å®ä¾‹ä¸­ï¼Œæœ‰å¤šå°‘æ˜¯çœŸæ­£çš„ç›®æ ‡ã€‚é«˜ç²¾ç¡®ç‡è¡¨ç¤ºæ¨¡å‹çš„è¯¯æŠ¥ç‡ä½ã€‚

2. å¬å›ç‡ï¼ˆRecallï¼‰

è®¡ç®—å…¬å¼ï¼š

Recall
=
ğ‘‡
ğ‘ƒ
ğ‘‡
ğ‘ƒ
+
ğ¹
ğ‘
Recall= 
TP+FN
TP
â€‹
 

å…¶ä¸­ï¼ŒFNï¼ˆFalse Negativeï¼‰è¡¨ç¤ºè¢«æ¼æ£€çš„ç›®æ ‡æ•°é‡ã€‚

ç›®çš„ï¼š

å¬å›ç‡è¡¡é‡æ¨¡å‹çš„æ£€æµ‹èƒ½åŠ›ï¼Œå³å®é™…å­˜åœ¨çš„ç›®æ ‡ä¸­ï¼Œæœ‰å¤šå°‘è¢«æ¨¡å‹æˆåŠŸæ£€æµ‹å‡ºæ¥ã€‚é«˜å¬å›ç‡è¡¨ç¤ºæ¨¡å‹çš„æ¼æ£€ç‡ä½ã€‚

3. F1 åˆ†æ•°ï¼ˆF1 Scoreï¼‰

è®¡ç®—å…¬å¼ï¼š

ğ¹
1
=
2
Ã—
Precision
Ã—
Recall
Precision
+
Recall
F1=2Ã— 
Precision+Recall
PrecisionÃ—Recall
â€‹
 

ç›®çš„ï¼š

F1 åˆ†æ•°æ˜¯ç²¾ç¡®ç‡å’Œå¬å›ç‡çš„è°ƒå’Œå¹³å‡ï¼Œæä¾›äº†ä¸¤è€…ä¹‹é—´çš„å¹³è¡¡è¯„ä¼°ã€‚å½“éœ€è¦åœ¨ç²¾ç¡®ç‡å’Œå¬å›ç‡ä¹‹é—´å–å¾—å¹³è¡¡æ—¶ï¼ŒF1 åˆ†æ•°æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„æŒ‡æ ‡ã€‚

4. å¹³å‡ç²¾åº¦ï¼ˆAPï¼‰

è®¡ç®—æ–¹æ³•ï¼š

AP æ˜¯ Precision-Recall æ›²çº¿ä¸‹çš„é¢ç§¯ã€‚é€šè¿‡æ”¹å˜æ£€æµ‹é˜ˆå€¼ï¼Œç»˜åˆ¶å‡ºä¸åŒçš„ç²¾ç¡®ç‡å’Œå¬å›ç‡ç»„åˆï¼Œå½¢æˆæ›²çº¿ï¼Œç„¶åè®¡ç®—è¯¥æ›²çº¿ä¸‹çš„é¢ç§¯å³ä¸º APã€‚

ç›®çš„ï¼š

AP è¡¡é‡æ¨¡å‹åœ¨ç‰¹å®šç±»åˆ«ä¸Šçš„æ£€æµ‹æ€§èƒ½ï¼Œç»¼åˆè€ƒè™‘äº†ä¸åŒé˜ˆå€¼ä¸‹çš„ç²¾ç¡®ç‡å’Œå¬å›ç‡ã€‚

5. å¹³å‡ç²¾åº¦å‡å€¼ï¼ˆmAPï¼‰

è®¡ç®—æ–¹æ³•ï¼š

mAP æ˜¯å¯¹æ‰€æœ‰ç±»åˆ«çš„ AP å–å¹³å‡å€¼ã€‚

ç›®çš„ï¼š

mAP æä¾›äº†æ¨¡å‹åœ¨æ‰€æœ‰ç±»åˆ«ä¸Šçš„æ€»ä½“æ£€æµ‹æ€§èƒ½ï¼Œæ˜¯è¯„ä¼°å¤šç±»åˆ«ç›®æ ‡æ£€æµ‹æ¨¡å‹çš„å…³é”®æŒ‡æ ‡ã€‚

å¦‚ä½•åˆ¤æ–­æ¨¡å‹çš„å¥½å

åœ¨è¯„ä¼°æ¨¡å‹æ€§èƒ½æ—¶ï¼Œåº”ç»¼åˆè€ƒè™‘ä¸Šè¿°æŒ‡æ ‡ï¼š

é«˜ç²¾ç¡®ç‡å’Œé«˜å¬å›ç‡ï¼šç†æƒ³æƒ…å†µä¸‹ï¼Œæ¨¡å‹åº”å…·æœ‰é«˜ç²¾ç¡®ç‡å’Œé«˜å¬å›ç‡ï¼Œå³è¯¯æŠ¥å’Œæ¼æ£€éƒ½å°‘ã€‚

F1 åˆ†æ•°ï¼šå½“éœ€è¦åœ¨ç²¾ç¡®ç‡å’Œå¬å›ç‡ä¹‹é—´å–å¾—å¹³è¡¡æ—¶ï¼Œå…³æ³¨ F1 åˆ†æ•°ã€‚

AP å’Œ mAPï¼šå¯¹äºå¤šç±»åˆ«æ£€æµ‹ä»»åŠ¡ï¼Œå…³æ³¨æ¯ä¸ªç±»åˆ«çš„ AP å’Œæ•´ä½“çš„ mAPï¼Œä»¥è¯„ä¼°æ¨¡å‹åœ¨å„ç±»åˆ«ä¸Šçš„æ€§èƒ½å’Œæ€»ä½“è¡¨ç°ã€‚

é€šè¿‡å…¨é¢åˆ†æè¿™äº›æŒ‡æ ‡ï¼Œå¯ä»¥æ›´å‡†ç¡®åœ°åˆ¤æ–­æ¨¡å‹çš„ä¼˜åŠ£ï¼Œå¹¶ä¸ºæ¨¡å‹çš„æ”¹è¿›æä¾›æŒ‡å¯¼ã€‚
############################################################################################################################








##########################################
import torch
from yolov11 import YOLOv11  # å‡è®¾æœ‰ä¸€ä¸ª YOLOv11 çš„ Python å®ç°

# åŠ è½½é¢„è®­ç»ƒçš„ YOLOv11 æ¨¡å‹
model = YOLOv11(pretrained=True)
model.eval()

# å®šä¹‰éªŒè¯å’Œæµ‹è¯•æ•°æ®é›†çš„è·¯å¾„
val_data_path = 'path/to/your/validation/dataset'  # æ›¿æ¢ä¸ºæ‚¨çš„éªŒè¯æ•°æ®é›†è·¯å¾„
test_data_path = 'path/to/your/test/dataset'       # æ›¿æ¢ä¸ºæ‚¨çš„æµ‹è¯•æ•°æ®é›†è·¯å¾„

def evaluate_model(data_path, dataset_type='Validation'):
    """
    ä½¿ç”¨æŒ‡å®šçš„æ•°æ®é›†è¯„ä¼°æ¨¡å‹æ€§èƒ½ã€‚

    å‚æ•°ï¼š
    - data_path: æ•°æ®é›†çš„è·¯å¾„
    - dataset_type: æ•°æ®é›†ç±»å‹ï¼ˆ'Validation' æˆ– 'Test'ï¼‰
    """
    print(f"Evaluating on {dataset_type} Dataset...")
    results = model.val(data=data_path)

    # è¾“å‡ºæ•´ä½“è¯„ä¼°æŒ‡æ ‡
    print(f"{dataset_type} Dataset - Overall mAP@0.5: {results['mAP_0.5']:.4f}")
    print(f"{dataset_type} Dataset - Overall mAP@0.5:0.95: {results['mAP_0.5:0.95']:.4f}")
    print(f"{dataset_type} Dataset - Overall Precision: {results['precision']:.4f}")
    print(f"{dataset_type} Dataset - Overall Recall: {results['recall']:.4f}")
    print(f"{dataset_type} Dataset - Overall F1 Score: {results['f1']:.4f}")

    # è¾“å‡ºæ¯ä¸ªç±»åˆ«çš„è¯„ä¼°æŒ‡æ ‡
    for idx, class_name in enumerate(results['names']):
        class_precision = results['per_class_precision'][idx]
        class_recall = results['per_class_recall'][idx]
        class_f1 = results['per_class_f1'][idx]
        class_ap = results['per_class_ap'][idx]
        print(f"Class: {class_name}")
        print(f"  Precision: {class_precision:.4f}")
        print(f"  Recall: {class_recall:.4f}")
        print(f"  F1 Score: {class_f1:.4f}")
        print(f"  AP@0.5: {class_ap:.4f}")

# å¯¹éªŒè¯æ•°æ®é›†è¿›è¡Œè¯„ä¼°
evaluate_model(val_data_path, 'Validation')

# å¯¹æµ‹è¯•æ•°æ®é›†è¿›è¡Œè¯„ä¼°
evaluate_model(test_data_path, 'Test')


æ³¨æ„äº‹é¡¹ï¼š

æ•°æ®é›†é…ç½®ï¼šç¡®ä¿ val_data_path å’Œ test_data_path åˆ†åˆ«æŒ‡å‘éªŒè¯å’Œæµ‹è¯•æ•°æ®é›†çš„é…ç½®æ–‡ä»¶ï¼ˆé€šå¸¸ä¸º .yaml æ ¼å¼ï¼‰ã€‚è¿™äº›é…ç½®æ–‡ä»¶åº”åŒ…å«æ•°æ®é›†çš„ç›¸å…³ä¿¡æ¯ï¼Œå¦‚å›¾åƒè·¯å¾„ã€æ ‡ç­¾è·¯å¾„å’Œç±»åˆ«åç§°ç­‰ã€‚

è¯„ä¼°æ–¹æ³•ï¼šä¸Šè¿°ä»£ç å‡è®¾ YOLOv11 ç±»æä¾›äº† val æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯ä»¥æ¥å—æ•°æ®é›†é…ç½®æ–‡ä»¶çš„è·¯å¾„ï¼Œå¹¶è¿”å›åŒ…å«è¯„ä¼°æŒ‡æ ‡çš„ç»“æœå­—å…¸ã€‚å¦‚æœæ‚¨çš„å®ç°æœ‰æ‰€ä¸åŒï¼Œè¯·æ ¹æ®å®é™…æƒ…å†µè¿›è¡Œè°ƒæ•´ã€‚

æ€§èƒ½æŒ‡æ ‡ï¼šresults å­—å…¸åº”åŒ…å«æ•´ä½“å’Œæ¯ä¸ªç±»åˆ«çš„è¯„ä¼°æŒ‡æ ‡ï¼Œå¦‚ mAPã€Precisionã€Recallã€F1 Score ç­‰ã€‚å¦‚æœæŸäº›æŒ‡æ ‡ä¸å¯ç”¨ï¼Œè¯·æ ¹æ®æ‚¨çš„éœ€æ±‚å’Œæ¨¡å‹å®ç°è¿›è¡Œç›¸åº”çš„ä¿®æ”¹ã€‚

é€šè¿‡ä¸Šè¿°ä»£ç ï¼Œæ‚¨å¯ä»¥å¯¹éªŒè¯å’Œæµ‹è¯•æ•°æ®é›†è¿›è¡Œè¯„ä¼°ï¼Œå¹¶è¾“å‡ºæ¨¡å‹åœ¨ä¸åŒæ•°æ®é›†ä¸Šçš„æ€§èƒ½æŒ‡æ ‡ã€‚è¿™æœ‰åŠ©äºå…¨é¢äº†è§£æ¨¡å‹çš„è¡¨ç°ï¼Œå¹¶ä¸ºè¿›ä¸€æ­¥çš„ä¼˜åŒ–æä¾›å‚è€ƒã€‚
##########################################################################################################







#####################################################################################################

1. æ•°æ®é›†ç›®å½•ç»“æ„ç¤ºä¾‹
å‡è®¾æ‚¨çš„æ•°æ®é›†å­˜æ”¾åœ¨ä¸€ä¸ªæ ¹ç›®å½•ä¸‹ï¼Œç›®å½•ç»“æ„å¦‚ä¸‹ï¼š


dataset/
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ train/     # è®­ç»ƒå›¾åƒ
â”‚   â”œâ”€â”€ val/       # éªŒè¯å›¾åƒ
â”‚   â””â”€â”€ test/      # æµ‹è¯•å›¾åƒ
â””â”€â”€ labels/
    â”œâ”€â”€ train/     # è®­ç»ƒæ ‡ç­¾
    â”œâ”€â”€ val/       # éªŒè¯æ ‡ç­¾
    â””â”€â”€ test/      # æµ‹è¯•æ ‡ç­¾
images/ æ–‡ä»¶å¤¹ä¸­å­˜æ”¾æ‰€æœ‰å›¾åƒæ–‡ä»¶ã€‚

train/ ç”¨äºè®­ç»ƒçš„å›¾åƒã€‚
val/ ç”¨äºéªŒè¯çš„å›¾åƒã€‚
test/ ç”¨äºæµ‹è¯•çš„å›¾åƒã€‚
labels/ æ–‡ä»¶å¤¹ä¸­å­˜æ”¾å›¾åƒå¯¹åº”çš„æ ‡ç­¾æ–‡ä»¶ã€‚

æ¯ä¸ªæ ‡ç­¾æ–‡ä»¶çš„æ–‡ä»¶åä¸å¯¹åº”å›¾åƒç›¸åŒï¼ˆä½†æ‰©å±•åä¸º .txtï¼‰ï¼Œæ–‡ä»¶å†…å®¹é‡‡ç”¨ YOLO æ ¼å¼ã€‚
2. æ ‡ç­¾æ–‡ä»¶æ ¼å¼è¯´æ˜
æ¯ä¸ªæ ‡ç­¾æ–‡ä»¶é‡‡ç”¨ YOLO æ ¼å¼ï¼Œä¸€è¡Œå¯¹åº”å›¾åƒä¸­çš„ä¸€ä¸ªç›®æ ‡ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š


<class_id> <x_center> <y_center> <width> <height>
å…¶ä¸­ï¼š
<class_id>ï¼šç›®æ ‡ç±»åˆ«çš„ç´¢å¼•ï¼ˆæ•´æ•°ï¼‰ï¼Œå¯¹åº”é…ç½®æ–‡ä»¶ä¸­ names åˆ—è¡¨çš„ç´¢å¼•ï¼ˆä» 0 å¼€å§‹ï¼‰ã€‚
<x_center> å’Œ <y_center>ï¼šè¾¹ç•Œæ¡†ä¸­å¿ƒç‚¹çš„å½’ä¸€åŒ–åæ ‡ï¼ˆç›¸å¯¹äºå›¾åƒå®½åº¦å’Œé«˜åº¦ï¼Œå–å€¼èŒƒå›´ 0ï½1ï¼‰ã€‚
<width> å’Œ <height>ï¼šè¾¹ç•Œæ¡†çš„å½’ä¸€åŒ–å®½åº¦å’Œé«˜åº¦ï¼ˆç›¸å¯¹äºå›¾åƒå°ºå¯¸ï¼Œå–å€¼èŒƒå›´ 0ï½1ï¼‰ã€‚
ç¤ºä¾‹ï¼š
å‡è®¾æœ‰ä¸€å¼ éªŒè¯å›¾åƒ image1.jpgï¼Œå¯¹åº”çš„æ ‡ç­¾æ–‡ä»¶ image1.txt å†…å®¹å¦‚ä¸‹ï¼š

0 0.5 0.5 0.2 0.3
1 0.7 0.8 0.1 0.1
è¡¨ç¤ºå›¾åƒä¸­æœ‰ä¸¤ä¸ªç›®æ ‡ï¼Œç¬¬ä¸€ä¸ªç›®æ ‡ç±»åˆ«ä¸º 0ï¼Œä¸­å¿ƒåœ¨å›¾åƒæ­£ä¸­å¤®ï¼Œå®½åº¦ä¸ºå›¾åƒå®½åº¦çš„ 20%ã€é«˜åº¦ä¸º 30%ï¼›ç¬¬äºŒä¸ªç›®æ ‡ç±»åˆ«ä¸º 1ï¼Œä¸­å¿ƒä½äºå›¾åƒå®½åº¦ 70% å’Œé«˜åº¦ 80% çš„ä½ç½®ï¼Œè¾¹ç•Œæ¡†å°ºå¯¸ä¸ºå›¾åƒå°ºå¯¸çš„ 10%ã€‚

3. æ•°æ®é›†é…ç½®æ–‡ä»¶ï¼ˆdataset.yamlï¼‰
åˆ›å»ºä¸€ä¸ªåä¸º dataset.yaml çš„æ–‡ä»¶ï¼Œç”¨äºæŒ‡å®šæ•°æ®é›†æ ¹ç›®å½•ã€å„å­ç›®å½•åŠç±»åˆ«ä¿¡æ¯ã€‚ä¾‹å¦‚ï¼š

# æ•°æ®é›†é…ç½®æ–‡ä»¶

# å›¾åƒå’Œæ ‡ç­¾çš„æ ¹ç›®å½•ï¼ˆè¯·æ›¿æ¢ä¸ºæ‚¨çš„å®é™…è·¯å¾„ï¼‰
path: path/to/your/dataset

# è®­ç»ƒã€éªŒè¯å’Œæµ‹è¯•å›¾åƒçš„å­ç›®å½•ï¼ˆç›¸å¯¹äº pathï¼‰
train: images/train
val: images/val
test: images/test

# ç±»åˆ«æ•°ï¼ˆè¯·æ›¿æ¢ä¸ºæ‚¨çš„ç±»åˆ«æ•°é‡ï¼‰
nc: 3

# ç±»åˆ«åç§°åˆ—è¡¨ï¼ˆæŒ‰ç´¢å¼•é¡ºåºå¯¹åº”æ ‡ç­¾ä¸­çš„ class_idï¼‰
names:
  0: defect_type_1
  1: defect_type_2
  2: defect_type_3
è¯·ç¡®ä¿å°† path/to/your/dataset æ›¿æ¢ä¸ºæ‚¨çš„æ•°æ®é›†æ ¹ç›®å½•å®é™…è·¯å¾„ã€‚

4. è¯„ä¼°ä»£ç ç¤ºä¾‹
ä¸‹é¢çš„ä»£ç ä½¿ç”¨æ‚¨æä¾›çš„è¯„ä¼°ä»£ç ï¼Œå¹¶æ¼”ç¤ºå¦‚ä½•åˆ©ç”¨æ•°æ®é›†é…ç½®æ–‡ä»¶ï¼ˆä¾‹å¦‚ dataset.yamlï¼‰å¯¹éªŒè¯é›†å’Œæµ‹è¯•é›†è¿›è¡Œè¯„ä¼°ï¼š




import torch
from yolov11 import YOLOv11  # å‡è®¾æœ‰ä¸€ä¸ª YOLOv11 çš„ Python å®ç°

# åŠ è½½é¢„è®­ç»ƒçš„ YOLOv11 æ¨¡å‹
model = YOLOv11(pretrained=True)
model.eval()

# å®šä¹‰æ•°æ®é›†é…ç½®æ–‡ä»¶çš„è·¯å¾„ï¼ˆåŒ…å«éªŒè¯å’Œæµ‹è¯•é›†çš„é…ç½®ä¿¡æ¯ï¼‰
data_config_path = 'path/to/your/dataset.yaml'  # æ›¿æ¢ä¸ºæ‚¨çš„æ•°æ®é›†é…ç½®æ–‡ä»¶è·¯å¾„

def evaluate_model(data_path, dataset_type='Validation'):
    """
    ä½¿ç”¨æŒ‡å®šçš„æ•°æ®é›†è¯„ä¼°æ¨¡å‹æ€§èƒ½ã€‚

    å‚æ•°ï¼š
    - data_path: æ•°æ®é›†é…ç½®æ–‡ä»¶çš„è·¯å¾„
    - dataset_type: æ•°æ®é›†ç±»å‹ï¼ˆ'Validation' æˆ– 'Test'ï¼‰
    """
    print(f"Evaluating on {dataset_type} Dataset...")
    results = model.val(data=data_path)

    # è¾“å‡ºæ•´ä½“è¯„ä¼°æŒ‡æ ‡
    print(f"{dataset_type} Dataset - Overall mAP@0.5: {results['mAP_0.5']:.4f}")
    print(f"{dataset_type} Dataset - Overall mAP@0.5:0.95: {results['mAP_0.5:0.95']:.4f}")
    print(f"{dataset_type} Dataset - Overall Precision: {results['precision']:.4f}")
    print(f"{dataset_type} Dataset - Overall Recall: {results['recall']:.4f}")
    print(f"{dataset_type} Dataset - Overall F1 Score: {results['f1']:.4f}")

    # è¾“å‡ºæ¯ä¸ªç±»åˆ«çš„è¯„ä¼°æŒ‡æ ‡
    for idx, class_name in enumerate(results['names']):
        class_precision = results['per_class_precision'][idx]
        class_recall = results['per_class_recall'][idx]
        class_f1 = results['per_class_f1'][idx]
        class_ap = results['per_class_ap'][idx]
        print(f"Class: {class_name}")
        print(f"  Precision: {class_precision:.4f}")
        print(f"  Recall: {class_recall:.4f}")
        print(f"  F1 Score: {class_f1:.4f}")
        print(f"  AP@0.5: {class_ap:.4f}")

# ç¤ºä¾‹ç”¨æ³•ï¼šåˆ†åˆ«å¯¹éªŒè¯å’Œæµ‹è¯•æ•°æ®é›†è¿›è¡Œè¯„ä¼°
# å¦‚æœéªŒè¯é›†å’Œæµ‹è¯•é›†éƒ½åœ¨ dataset.yaml ä¸­å®šä¹‰ï¼Œå¯ä»¥ç›´æ¥ç”¨åŒä¸€ä¸ªé…ç½®æ–‡ä»¶è¿›è¡Œè¯„ä¼°ï¼Œ
# æ¨¡å‹å†…éƒ¨ä¼šæ ¹æ®é…ç½®æ–‡ä»¶ä¸­ç›¸åº”çš„ 'val' æˆ– 'test' å­—æ®µåŠ è½½å¯¹åº”æ•°æ®ã€‚

print("----- éªŒè¯é›†è¯„ä¼° -----")
evaluate_model(data_config_path, 'Validation')

print("\n----- æµ‹è¯•é›†è¯„ä¼° -----")
evaluate_model(data_config_path, 'Test')
è¯´æ˜ï¼š

åœ¨ä¸Šé¢çš„ä»£ç ä¸­ï¼Œdata_config_path æŒ‡å‘çš„æ˜¯æ•°æ®é›†é…ç½®æ–‡ä»¶ï¼ˆdataset.yamlï¼‰ï¼Œè¯¥æ–‡ä»¶ä¸­å·²ç»åŒ…å«äº†è®­ç»ƒã€éªŒè¯å’Œæµ‹è¯•é›†çš„å›¾åƒç›®å½•ä¿¡æ¯ä»¥åŠç±»åˆ«è®¾ç½®ã€‚
evaluate_model å‡½æ•°è°ƒç”¨ model.val(data=data_path)ï¼Œè¿™å‡è®¾æ‚¨çš„ YOLOv11 å®ç°æ”¯æŒç›´æ¥ä½¿ç”¨é…ç½®æ–‡ä»¶è¿›è¡Œè¯„ä¼°ï¼Œå¹¶æ ¹æ®é…ç½®æ–‡ä»¶åŠ è½½ç›¸åº”çš„æ•°æ®é›†ã€‚
æ ¹æ®å®é™…å®ç°ï¼Œå¦‚æœéœ€è¦åˆ†åˆ«æŒ‡å®šéªŒè¯é›†å’Œæµ‹è¯•é›†çš„è·¯å¾„ï¼Œå¯ä»¥è°ƒæ•´é…ç½®æ–‡ä»¶æˆ–åˆ†åˆ«ä¼ å…¥ä¸åŒçš„è·¯å¾„ã€‚


#########################################################




from ultralytics import YOLO  # ä½¿ç”¨å®˜æ–¹API
import torch
from tabulate import tabulate

# åŠ è½½å®˜æ–¹é¢„è®­ç»ƒæ¨¡å‹ (æ³¨æ„æ­£ç¡®æ¨¡å‹åç§°)
model = YOLO('yolov11n.pt')  # å®˜æ–¹æ¨¡å‹åä¸ºyolov11nè€Œéyolo11n
model.eval()

def evaluate_model(data_config, dataset_type='val'):
    """
    ä¼˜åŒ–åçš„å¤šåˆ†ç±»è¯„ä¼°å‡½æ•°ï¼ˆç¬¦åˆUltralyticsæ ‡å‡†ï¼‰
    
    å‚æ•°ï¼š
    - data_config: æ•°æ®é›†é…ç½®æ–‡ä»¶è·¯å¾„ (.yaml)
    - dataset_type: æ•°æ®é›†ç±»å‹ ('val' æˆ– 'test')
    """
    print(f"\n{'='*30} {dataset_type.upper()} è¯„ä¼° {'='*30}")
    
    # æ‰§è¡ŒéªŒè¯ï¼ˆæ·»åŠ å…³é”®å‚æ•°ï¼‰
    results = model.val(
        data=data_config,
        split=dataset_type,  # å®˜æ–¹ä½¿ç”¨splitå‚æ•°
        plots=True,          # ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
        save_json=True,      # ä¿å­˜JSONæ ¼å¼ç»“æœ
        conf=0.01,           # ç½®ä¿¡åº¦é˜ˆå€¼
        iou=0.6              # IoUé˜ˆå€¼
    )
    
    # å…¨å±€æŒ‡æ ‡è¾“å‡º
    print(f"\n[å…¨å±€æŒ‡æ ‡]")
    print(f"mAP@0.5:0.95 | {results.box.map:.4f} (COCOæ ‡å‡†)")
    print(f"mAP@0.5      | {results.box.map50:.4f}")
    print(f"Precision    | {results.box.precision.mean():.4f}")
    print(f"Recall       | {results.box.recall.mean():.4f}")
    print(f"æ¨ç†é€Ÿåº¦     | {results.speed['inference']:.2f} ms/å¼ ")

    # å¤šåˆ†ç±»è¯¦ç»†æŒ‡æ ‡ï¼ˆè¡¨æ ¼åŒ–è¾“å‡ºï¼‰
    print("\n[åˆ†ç±»åˆ«æŒ‡æ ‡]")
    table_data = []
    for idx, name in enumerate(results.names):
        row = [
            name,
            f"{results.box.ap50[idx]:.4f}",
            f"{results.box.ap75[idx]:.4f}",
            f"{results.box.ap[idx]:.4f}",
            f"{results.box.precision[idx]:.4f}",
            f"{results.box.recall[idx]:.4f}"
        ]
        table_data.append(row)
    
    print(tabulate(table_data,
                 headers=['ç±»åˆ«', 'AP50', 'AP75', 'AP50-95', 'Precision', 'Recall'],
                 tablefmt='github'))
    
    # å¯è§†åŒ–ä¿å­˜
    print("\nç”Ÿæˆå¯è§†åŒ–æ–‡ä»¶ï¼š")
    print(f"- æ··æ·†çŸ©é˜µ: runs/detect/val/confusion_matrix.png")
    print(f"- é¢„æµ‹ç¤ºä¾‹: runs/detect/val/val_batch_pred.jpg")
    print(f"- JSONç»“æœ: runs/detect/val/results.json")

# é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆç¤ºä¾‹ï¼‰
data_config_path = 'path/to/your/dataset.yaml'

# æ‰§è¡ŒéªŒè¯
if __name__ == "__main__":
    # éªŒè¯é›†è¯„ä¼°
    evaluate_model(data_config_path, 'val')
    
    # æµ‹è¯•é›†è¯„ä¼°ï¼ˆéœ€è¦é…ç½®æ–‡ä»¶ä¸­å®šä¹‰testè·¯å¾„ï¼‰
    evaluate_model(data_config_path, 'test')



ä¸»è¦æ”¹è¿›ç‚¹è¯´æ˜ï¼š
APIæ ‡å‡†åŒ–ï¼š
ä½¿ç”¨from ultralytics import YOLOæ›¿ä»£è‡ªå®šä¹‰å¯¼å…¥
ä¿®æ­£æ¨¡å‹åç§°yolov11n.ptï¼ˆå®˜æ–¹å‘½åè§„èŒƒï¼‰
ä½¿ç”¨splitå‚æ•°æ›¿ä»£è‡ªå®šä¹‰ç±»å‹åˆ¤æ–­
æŒ‡æ ‡è¾“å‡ºä¼˜åŒ–ï¼š
å¢åŠ AP75æŒ‡æ ‡è¾“å‡º
æ·»åŠ æ¨ç†é€Ÿåº¦æ˜¾ç¤º
ä½¿ç”¨è¡¨æ ¼åŒ–è¾“å‡ºåˆ†ç±»åˆ«æŒ‡æ ‡
ç¬¦åˆCOCOæ ‡å‡†æŒ‡æ ‡å‘½åï¼ˆbox.map / box.map50ï¼‰
å‚æ•°ä¼˜åŒ–ï¼š
æ·»åŠ save_json=Trueä¿å­˜å¯è§£æç»“æœ
è®¾ç½®åˆç†é»˜è®¤å€¼conf=0.01å’Œiou=0.6
è‡ªåŠ¨ç”Ÿæˆå¯è§†åŒ–æ–‡ä»¶è·¯å¾„æç¤º
å¤šåˆ†ç±»æ”¯æŒå¼ºåŒ–ï¼š
æ˜¾ç¤ºæ¯ä¸ªç±»åˆ«çš„AP50/AP75/AP50-95
åˆ†ç±»åˆ«ç²¾ç¡®ç‡å’Œå¬å›ç‡å•ç‹¬æ˜¾ç¤º
å…¼å®¹ä¸åŒæ•°æ®åˆ†å‰²ï¼ˆval/testï¼‰
ä½¿ç”¨å‰éœ€ç¡®ä¿ï¼š
bash
pip install ultralytics tabulate
æ³¨æ„ï¼šå®é™…ä½¿ç”¨æ—¶è¯·ç¡®ä¿ï¼š
dataset.yamlä¸­æ­£ç¡®å®šä¹‰testè·¯å¾„
æµ‹è¯•é›†æ ‡ç­¾æ–‡ä»¶ç¬¦åˆYOLOæ ¼å¼
æ¨¡å‹æ–‡ä»¶ä¸ä»»åŠ¡åŒ¹é…ï¼ˆåˆ†ç±»æ•°ä¸€è‡´ï¼‰
############################################






YOLOv11 å¤šåˆ†ç±»ç‰©ä½“æ£€æµ‹è¯„ä¼°å®Œæ•´æŒ‡å—
ä¸€ã€ç¯å¢ƒå‡†å¤‡
bash
# å®‰è£…æ ¸å¿ƒä¾èµ–
pip install ultralytics tabulate matplotlib torch
äºŒã€æ•°æ®é›†é…ç½®æ ‡å‡†
1. ç›®å½•ç»“æ„è§„èŒƒ
bash
datasets/
â””â”€â”€ defect_detection/
    â”œâ”€â”€ train/
    â”‚   â”œâ”€â”€ images/  # è®­ç»ƒé›†å›¾åƒ
    â”‚   â””â”€â”€ labels/  # YOLOæ ¼å¼æ ‡ç­¾
    â”œâ”€â”€ val/
    â”‚   â”œâ”€â”€ images/  # éªŒè¯é›†å›¾åƒ
    â”‚   â””â”€â”€ labels/
    â””â”€â”€ test/
        â”œâ”€â”€ images/  # æµ‹è¯•é›†å›¾åƒ
        â””â”€â”€ labels/
2. æ ‡ç­¾æ–‡ä»¶ç¤ºä¾‹
labels/train/image001.txt:
text
0 0.347656 0.489583 0.128906 0.239583
2 0.712891 0.581250 0.089844 0.166667
3. æ•°æ®é›†é…ç½®æ–‡ä»¶ (defect_config.yaml)
text
path: /projects/datasets/defect_detection
train: train/images
val: val/images
test: test/images

nc: 3
names:
  0: scratch
  1: dent
  2: crack
ä¸‰ã€è¯„ä¼°ä»£ç å®ç°
python
from ultralytics import YOLO
from tabulate import tabulate

def main():
    # åˆå§‹åŒ–æ¨¡å‹
    model = YOLO('yolov11n.pt')
    
    # æ‰§è¡Œè¯„ä¼°æµç¨‹
    run_evaluation(model, 'defect_config.yaml')

def run_evaluation(model, config_path):
    """å…¨æµç¨‹è¯„ä¼°å‡½æ•°"""
    # éªŒè¯é›†è¯„ä¼°
    print("\n" + "="*40)
    print("Starting Validation Evaluation")
    results_val = evaluate_model(model, config_path, 'val')
    
    # æµ‹è¯•é›†è¯„ä¼°
    print("\n" + "="*40)
    print("Starting Test Evaluation")
    results_test = evaluate_model(model, config_path, 'test')
    
    return results_val, results_test

def evaluate_model(model, data_config, dataset_type='val'):
    """æ¨¡å‹è¯„ä¼°æ ¸å¿ƒå‡½æ•°"""
    print(f"\n{'='*30} {dataset_type.upper()} EVALUATION {'='*30}")
    
    # æ‰§è¡ŒéªŒè¯æµç¨‹
    results = model.val(
        data=data_config,
        split=dataset_type,
        plots=True,
        save_json=True,
        conf=0.01,
        iou=0.6,
        device='cuda' if torch.cuda.is_available() else 'cpu'
    )
    
    # è¾“å‡ºè¯„ä¼°æŒ‡æ ‡
    print_metrics(results)
    
    return results

def print_metrics(results):
    """ç»“æ„åŒ–è¾“å‡ºè¯„ä¼°æŒ‡æ ‡"""
    # å…¨å±€æŒ‡æ ‡
    print("\n[Global Metrics]")
    print(f"mAP@0.5:0.95 | {results.box.map:.4f} (COCO Primary)")
    print(f"mAP@0.5      | {results.box.map50:.4f}")
    print(f"Precision    | {results.box.precision.mean():.4f} Â±{results.box.precision.std():.4f}")
    print(f"Recall       | {results.box.recall.mean():.4f} Â±{results.box.recall.std():.4f}")
    print(f"Inference Speed | {results.speed['inference']:.2f} ms/img")
    
    # åˆ†ç±»åˆ«æŒ‡æ ‡è¡¨æ ¼
    print("\n[Per-Class Metrics]")
    table_data = [
        [
            name,
            f"{results.box.ap50[idx]:.4f}",
            f"{results.box.ap75[idx]:.4f}",
            f"{results.box.ap[idx]:.4f}",
            f"{results.box.precision[idx]:.4f}",
            f"{results.box.recall[idx]:.4f}"
        ]
        for idx, name in enumerate(results.names)
    ]
    
    print(tabulate(table_data,
                 headers=['Class', 'AP50', 'AP75', 'AP50-95', 'Precision', 'Recall'],
                 tablefmt='github'))
    
    # è¾“å‡ºæ–‡ä»¶è·¯å¾„
    print("\nGenerated Files:")
    print(f"- æ··æ·†çŸ©é˜µ: runs/detect/{results.save_dir}/confusion_matrix.png")
    print(f"- é¢„æµ‹å¯è§†åŒ–: runs/detect/{results.save_dir}/val_batch_pred.jpg")
    print(f"- è¯¦ç»†ç»“æœ: runs/detect/{results.save_dir}/results.json")

if __name__ == "__main__":
    main()
å››ã€å…³é”®å‚æ•°è¯´æ˜
å‚æ•°	ç±»å‹	é»˜è®¤å€¼	è¯´æ˜
split	str	'val'	æ•°æ®é›†åˆ†å‰²ç±»å‹ (val/test)
plots	bool	True	ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
save_json	bool	True	ä¿å­˜JSONæ ¼å¼ç»“æœ
conf	float	0.01	æ£€æµ‹ç½®ä¿¡åº¦é˜ˆå€¼
iou	float	0.6	IoUé˜ˆå€¼
device	str	auto	è®¡ç®—è®¾å¤‡è‡ªåŠ¨é€‰æ‹©
äº”ã€æ‰§è¡Œä¸è¾“å‡ºè§£è¯»
1. è¿è¡Œå‘½ä»¤
bash
python evaluate.py
2. å…¸å‹è¾“å‡ºç¤ºä¾‹
text
============================== VAL EVALUATION =============================

[Global Metrics]
mAP@0.5:0.95 | 0.6723 (COCO Primary)
mAP@0.5      | 0.8521
Precision    | 0.7812 Â±0.032
Recall       | 0.6934 Â±0.041
Inference Speed | 4.23 ms/img

[Per-Class Metrics]
| Class    |   AP50 |   AP75 |   AP50-95 |   Precision |   Recall |
|----------|--------|--------|-----------|-------------|----------|
| scratch  | 0.8723 | 0.7021 |    0.6423 |      0.8023 |   0.7123 |
| dent     | 0.8345 | 0.6532 |    0.5934 |      0.7623 |   0.6834 |
| crack    | 0.8012 | 0.5921 |    0.5432 |      0.7321 |   0.6532 |
3. è¾“å‡ºæ–‡ä»¶è¯´æ˜
confusion_matrix.png: ç±»åˆ«æ··æ·†çŸ©é˜µ
val_batch_pred.jpg: å…¸å‹æ£€æµ‹ç»“æœå¯è§†åŒ–
results.json: åŒ…å«æ‰€æœ‰æŒ‡æ ‡çš„JSONæ–‡ä»¶
å…­ã€é«˜çº§é…ç½®å»ºè®®
å¤šGPUè¯„ä¼°åŠ é€Ÿï¼š
python
model.val(..., device=[0,1,2,3])  # ä½¿ç”¨4å—GPU
æ‰¹é‡å¤§å°ä¼˜åŒ–ï¼š
python
model.val(..., batch=64)  # æ ¹æ®æ˜¾å­˜è°ƒæ•´
ç‰¹å®šç±»åˆ«åˆ†æï¼š
python
# åœ¨print_metricså‡½æ•°ä¸­æ·»åŠ 
print(f"\nClass 'crack'è¯¦ç»†æŒ‡æ ‡:")
print(f"- æŸ¥å‡†ç‡: {results.box.precision[2]:.4f}")
print(f"- æ¼æ£€ç‡: {1 - results.box.recall[2]:.4f}")
æœ¬æŒ‡å—å®Œæ•´å®ç°äº†YOLOv11çš„è¯„ä¼°æµç¨‹ï¼ŒåŒ…å«å¤šåˆ†ç±»æ£€æµ‹çš„å…³é”®æŒ‡æ ‡åˆ†æï¼Œå¯æ»¡è¶³å·¥ä¸šçº§ç¼ºé™·æ£€æµ‹ã€å•†å“è¯†åˆ«ç­‰åœºæ™¯çš„è¯„ä¼°éœ€æ±‚ã€‚








