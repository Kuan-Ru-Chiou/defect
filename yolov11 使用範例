æ•°æ®é›†é…ç½®æ–‡ä»¶ç¤ºä¾‹ï¼ˆdataset.yamlï¼‰ï¼š
train: path/to/your/train/images  # è®­ç»ƒå›¾åƒæ–‡ä»¶å¤¹è·¯å¾„
val: path/to/your/val/images      # éªŒè¯å›¾åƒæ–‡ä»¶å¤¹è·¯å¾„

names:
  0: defect_type_1
  1: defect_type_2
  # æ·»åŠ æ›´å¤šç±»åˆ«



ç›®å½•ç»“æ„ç¤ºä¾‹ï¼š
datasets/
    my_dataset/
        images/
            train/  # è®­ç»ƒå›¾ç‰‡
            val/    # éªŒè¯å›¾ç‰‡
        labels/
            train/  # è®­ç»ƒæ ‡ç­¾ (YOLOæ ¼å¼)
            val/    # éªŒè¯æ ‡ç­¾ (YOLOæ ¼å¼)











########################yolov11 ä½¿ç”¨é æ¸¬å¤šç¨®é¡/æ•´é«”   ç¼ºé™·æƒ…æ³ sample code###########################

import torch
from yolov11 import YOLOv11  # å‡è®¾æœ‰ä¸€ä¸ª YOLOv11 çš„ Python å®ç°

# åŠ è½½é¢„è®­ç»ƒçš„ YOLOv11 æ¨¡å‹
model = YOLOv11(pretrained=True)
model.eval()

# å®šä¹‰éªŒè¯æ•°æ®é›†çš„è·¯å¾„
val_data_path = 'path/to/your/validation/dataset'  # æ›¿æ¢ä¸ºæ‚¨çš„éªŒè¯æ•°æ®é›†è·¯å¾„

# æ‰§è¡ŒéªŒè¯
results = model.val(data=val_data_path)

# è¾“å‡ºæ•´ä½“è¯„ä¼°æŒ‡æ ‡
print(f"Overall mAP@0.5: {results['mAP_0.5']:.4f}")
print(f"Overall mAP@0.5:0.95: {results['mAP_0.5:0.95']:.4f}")
print(f"Overall Precision: {results['precision']:.4f}")
print(f"Overall Recall: {results['recall']:.4f}")
print(f"Overall F1 Score: {results['f1']:.4f}")

# è¾“å‡ºæ¯ä¸ªç±»åˆ«çš„è¯„ä¼°æŒ‡æ ‡
for idx, class_name in enumerate(results['names']):
    class_precision = results['per_class_precision'][idx]
    class_recall = results['per_class_recall'][idx]
    class_f1 = results['per_class_f1'][idx]
    class_ap = results['per_class_ap'][idx]
    print(f"Class: {class_name}")
    print(f"  Precision: {class_precision:.4f}")
    print(f"  Recall: {class_recall:.4f}")
    print(f"  F1 Score: {class_f1:.4f}")
    print(f"  AP@0.5: {class_ap:.4f}")



æ³¨æ„äº‹é¡¹ï¼š

ç»“æœå­—å…¸ç»“æ„ï¼šä¸Šè¿°ä»£ç å‡è®¾ results å­—å…¸åŒ…å«ä»¥ä¸‹é”®ï¼š

'mAP_0.5'ï¼šæ•´ä½“ mAP@0.5 å€¼ã€‚
'mAP_0.5:0.95'ï¼šæ•´ä½“ mAP@0.5:0.95 å€¼ã€‚
'precision'ï¼šæ•´ä½“ç²¾åº¦ã€‚
'recall'ï¼šæ•´ä½“å¬å›ç‡ã€‚
'f1'ï¼šæ•´ä½“ F1 åˆ†æ•°ã€‚
'names'ï¼šç±»åˆ«åç§°åˆ—è¡¨ã€‚
'per_class_precision'ï¼šæ¯ä¸ªç±»åˆ«çš„ç²¾åº¦åˆ—è¡¨ã€‚
'per_class_recall'ï¼šæ¯ä¸ªç±»åˆ«çš„å¬å›ç‡åˆ—è¡¨ã€‚
'per_class_f1'ï¼šæ¯ä¸ªç±»åˆ«çš„ F1 åˆ†æ•°åˆ—è¡¨ã€‚
'per_class_ap'ï¼šæ¯ä¸ªç±»åˆ«çš„ AP@0.5 å€¼åˆ—è¡¨ã€‚
æ¨¡å‹å®ç°ï¼šç¡®ä¿æ‚¨ä½¿ç”¨çš„ YOLOv11 å®ç°çš„ val æ–¹æ³•è¿”å›çš„ results å­—å…¸åŒ…å«ä¸Šè¿°é”®ã€‚å¦‚æœæ²¡æœ‰ï¼Œæ‚¨å¯èƒ½éœ€è¦æŸ¥çœ‹æ¨¡å‹çš„æºç ï¼Œäº†è§£å¦‚ä½•æå–æ¯ä¸ªç±»åˆ«çš„è¯„ä¼°æŒ‡æ ‡ã€‚

è¯„ä¼°æŒ‡æ ‡è®¡ç®—ï¼šå¦‚æœæ¨¡å‹æœªæä¾›æ¯ä¸ªç±»åˆ«çš„æŒ‡æ ‡ï¼Œæ‚¨å¯èƒ½éœ€è¦æ‰‹åŠ¨è®¡ç®—ã€‚è¿™æ¶‰åŠå°†é¢„æµ‹ç»“æœä¸çœŸå®æ ‡ç­¾è¿›è¡Œæ¯”è¾ƒï¼Œè®¡ç®—æ¯ä¸ªç±»åˆ«çš„ TPã€FPã€FNï¼Œç„¶åæ ¹æ®è¿™äº›å€¼è®¡ç®—ç²¾åº¦ã€å¬å›ç‡å’Œ F1 åˆ†æ•°ã€‚è¿™å¯èƒ½éœ€è¦æ·±å…¥äº†è§£æ¨¡å‹çš„è¾“å‡ºæ ¼å¼å’Œè¯„ä¼°æµç¨‹ã€‚

é€šè¿‡ä¸Šè¿°ä¿®æ”¹ï¼Œæ‚¨çš„ä»£ç å°†èƒ½å¤Ÿè¾“å‡ºæ¯ä¸ªç¼ºé™·ç±»åˆ«çš„è¯„ä¼°æŒ‡æ ‡ï¼Œå¸®åŠ©æ‚¨æ›´ç»†è‡´åœ°è¯„ä¼°æ¨¡å‹åœ¨å„ä¸ªç±»åˆ«ä¸Šçš„æ€§èƒ½ã€‚




åœ¨ç›®æ ‡æ£€æµ‹ä»»åŠ¡ä¸­ï¼Œè¯„ä¼°æ¨¡å‹æ€§èƒ½çš„æŒ‡æ ‡ä¸»è¦åŒ…æ‹¬ç²¾ç¡®ç‡ï¼ˆPrecisionï¼‰ã€å¬å›ç‡ï¼ˆRecallï¼‰ã€F1 åˆ†æ•°ï¼ˆF1 Scoreï¼‰ã€å¹³å‡ç²¾åº¦ï¼ˆAPï¼‰å’Œå¹³å‡ç²¾åº¦å‡å€¼ï¼ˆmAPï¼‰ã€‚ç†è§£è¿™äº›æŒ‡æ ‡çš„è®¡ç®—å…¬å¼å’Œç›®çš„ï¼Œæœ‰åŠ©äºåˆ¤æ–­æ¨¡å‹çš„ä¼˜åŠ£ï¼Œå¹¶å‘ä»–äººæ¸…æ™°åœ°è§£é‡Šæ¨¡å‹æ€§èƒ½ã€‚

1. ç²¾ç¡®ç‡ï¼ˆPrecisionï¼‰

è®¡ç®—å…¬å¼ï¼š

Precision
=
ğ‘‡
ğ‘ƒ
ğ‘‡
ğ‘ƒ
+
ğ¹
ğ‘ƒ
Precision= 
TP+FP
TP
â€‹
 

å…¶ä¸­ï¼ŒTPï¼ˆTrue Positiveï¼‰è¡¨ç¤ºè¢«æ­£ç¡®æ£€æµ‹ä¸ºç›®æ ‡çš„æ•°é‡ï¼ŒFPï¼ˆFalse Positiveï¼‰è¡¨ç¤ºè¢«é”™è¯¯æ£€æµ‹ä¸ºç›®æ ‡çš„æ•°é‡ã€‚

ç›®çš„ï¼š

ç²¾ç¡®ç‡è¡¡é‡æ¨¡å‹é¢„æµ‹çš„å‡†ç¡®æ€§ï¼Œå³æ¨¡å‹é¢„æµ‹ä¸ºç›®æ ‡çš„å®ä¾‹ä¸­ï¼Œæœ‰å¤šå°‘æ˜¯çœŸæ­£çš„ç›®æ ‡ã€‚é«˜ç²¾ç¡®ç‡è¡¨ç¤ºæ¨¡å‹çš„è¯¯æŠ¥ç‡ä½ã€‚

2. å¬å›ç‡ï¼ˆRecallï¼‰

è®¡ç®—å…¬å¼ï¼š

Recall
=
ğ‘‡
ğ‘ƒ
ğ‘‡
ğ‘ƒ
+
ğ¹
ğ‘
Recall= 
TP+FN
TP
â€‹
 

å…¶ä¸­ï¼ŒFNï¼ˆFalse Negativeï¼‰è¡¨ç¤ºè¢«æ¼æ£€çš„ç›®æ ‡æ•°é‡ã€‚

ç›®çš„ï¼š

å¬å›ç‡è¡¡é‡æ¨¡å‹çš„æ£€æµ‹èƒ½åŠ›ï¼Œå³å®é™…å­˜åœ¨çš„ç›®æ ‡ä¸­ï¼Œæœ‰å¤šå°‘è¢«æ¨¡å‹æˆåŠŸæ£€æµ‹å‡ºæ¥ã€‚é«˜å¬å›ç‡è¡¨ç¤ºæ¨¡å‹çš„æ¼æ£€ç‡ä½ã€‚

3. F1 åˆ†æ•°ï¼ˆF1 Scoreï¼‰

è®¡ç®—å…¬å¼ï¼š

ğ¹
1
=
2
Ã—
Precision
Ã—
Recall
Precision
+
Recall
F1=2Ã— 
Precision+Recall
PrecisionÃ—Recall
â€‹
 

ç›®çš„ï¼š

F1 åˆ†æ•°æ˜¯ç²¾ç¡®ç‡å’Œå¬å›ç‡çš„è°ƒå’Œå¹³å‡ï¼Œæä¾›äº†ä¸¤è€…ä¹‹é—´çš„å¹³è¡¡è¯„ä¼°ã€‚å½“éœ€è¦åœ¨ç²¾ç¡®ç‡å’Œå¬å›ç‡ä¹‹é—´å–å¾—å¹³è¡¡æ—¶ï¼ŒF1 åˆ†æ•°æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„æŒ‡æ ‡ã€‚

4. å¹³å‡ç²¾åº¦ï¼ˆAPï¼‰

è®¡ç®—æ–¹æ³•ï¼š

AP æ˜¯ Precision-Recall æ›²çº¿ä¸‹çš„é¢ç§¯ã€‚é€šè¿‡æ”¹å˜æ£€æµ‹é˜ˆå€¼ï¼Œç»˜åˆ¶å‡ºä¸åŒçš„ç²¾ç¡®ç‡å’Œå¬å›ç‡ç»„åˆï¼Œå½¢æˆæ›²çº¿ï¼Œç„¶åè®¡ç®—è¯¥æ›²çº¿ä¸‹çš„é¢ç§¯å³ä¸º APã€‚

ç›®çš„ï¼š

AP è¡¡é‡æ¨¡å‹åœ¨ç‰¹å®šç±»åˆ«ä¸Šçš„æ£€æµ‹æ€§èƒ½ï¼Œç»¼åˆè€ƒè™‘äº†ä¸åŒé˜ˆå€¼ä¸‹çš„ç²¾ç¡®ç‡å’Œå¬å›ç‡ã€‚

5. å¹³å‡ç²¾åº¦å‡å€¼ï¼ˆmAPï¼‰

è®¡ç®—æ–¹æ³•ï¼š

mAP æ˜¯å¯¹æ‰€æœ‰ç±»åˆ«çš„ AP å–å¹³å‡å€¼ã€‚

ç›®çš„ï¼š

mAP æä¾›äº†æ¨¡å‹åœ¨æ‰€æœ‰ç±»åˆ«ä¸Šçš„æ€»ä½“æ£€æµ‹æ€§èƒ½ï¼Œæ˜¯è¯„ä¼°å¤šç±»åˆ«ç›®æ ‡æ£€æµ‹æ¨¡å‹çš„å…³é”®æŒ‡æ ‡ã€‚

å¦‚ä½•åˆ¤æ–­æ¨¡å‹çš„å¥½å

åœ¨è¯„ä¼°æ¨¡å‹æ€§èƒ½æ—¶ï¼Œåº”ç»¼åˆè€ƒè™‘ä¸Šè¿°æŒ‡æ ‡ï¼š

é«˜ç²¾ç¡®ç‡å’Œé«˜å¬å›ç‡ï¼šç†æƒ³æƒ…å†µä¸‹ï¼Œæ¨¡å‹åº”å…·æœ‰é«˜ç²¾ç¡®ç‡å’Œé«˜å¬å›ç‡ï¼Œå³è¯¯æŠ¥å’Œæ¼æ£€éƒ½å°‘ã€‚

F1 åˆ†æ•°ï¼šå½“éœ€è¦åœ¨ç²¾ç¡®ç‡å’Œå¬å›ç‡ä¹‹é—´å–å¾—å¹³è¡¡æ—¶ï¼Œå…³æ³¨ F1 åˆ†æ•°ã€‚

AP å’Œ mAPï¼šå¯¹äºå¤šç±»åˆ«æ£€æµ‹ä»»åŠ¡ï¼Œå…³æ³¨æ¯ä¸ªç±»åˆ«çš„ AP å’Œæ•´ä½“çš„ mAPï¼Œä»¥è¯„ä¼°æ¨¡å‹åœ¨å„ç±»åˆ«ä¸Šçš„æ€§èƒ½å’Œæ€»ä½“è¡¨ç°ã€‚

é€šè¿‡å…¨é¢åˆ†æè¿™äº›æŒ‡æ ‡ï¼Œå¯ä»¥æ›´å‡†ç¡®åœ°åˆ¤æ–­æ¨¡å‹çš„ä¼˜åŠ£ï¼Œå¹¶ä¸ºæ¨¡å‹çš„æ”¹è¿›æä¾›æŒ‡å¯¼ã€‚
############################################################################################################################








##########################################
import torch
from yolov11 import YOLOv11  # å‡è®¾æœ‰ä¸€ä¸ª YOLOv11 çš„ Python å®ç°

# åŠ è½½é¢„è®­ç»ƒçš„ YOLOv11 æ¨¡å‹
model = YOLOv11(pretrained=True)
model.eval()

# å®šä¹‰éªŒè¯å’Œæµ‹è¯•æ•°æ®é›†çš„è·¯å¾„
val_data_path = 'path/to/your/validation/dataset'  # æ›¿æ¢ä¸ºæ‚¨çš„éªŒè¯æ•°æ®é›†è·¯å¾„
test_data_path = 'path/to/your/test/dataset'       # æ›¿æ¢ä¸ºæ‚¨çš„æµ‹è¯•æ•°æ®é›†è·¯å¾„

def evaluate_model(data_path, dataset_type='Validation'):
    """
    ä½¿ç”¨æŒ‡å®šçš„æ•°æ®é›†è¯„ä¼°æ¨¡å‹æ€§èƒ½ã€‚

    å‚æ•°ï¼š
    - data_path: æ•°æ®é›†çš„è·¯å¾„
    - dataset_type: æ•°æ®é›†ç±»å‹ï¼ˆ'Validation' æˆ– 'Test'ï¼‰
    """
    print(f"Evaluating on {dataset_type} Dataset...")
    results = model.val(data=data_path)

    # è¾“å‡ºæ•´ä½“è¯„ä¼°æŒ‡æ ‡
    print(f"{dataset_type} Dataset - Overall mAP@0.5: {results['mAP_0.5']:.4f}")
    print(f"{dataset_type} Dataset - Overall mAP@0.5:0.95: {results['mAP_0.5:0.95']:.4f}")
    print(f"{dataset_type} Dataset - Overall Precision: {results['precision']:.4f}")
    print(f"{dataset_type} Dataset - Overall Recall: {results['recall']:.4f}")
    print(f"{dataset_type} Dataset - Overall F1 Score: {results['f1']:.4f}")

    # è¾“å‡ºæ¯ä¸ªç±»åˆ«çš„è¯„ä¼°æŒ‡æ ‡
    for idx, class_name in enumerate(results['names']):
        class_precision = results['per_class_precision'][idx]
        class_recall = results['per_class_recall'][idx]
        class_f1 = results['per_class_f1'][idx]
        class_ap = results['per_class_ap'][idx]
        print(f"Class: {class_name}")
        print(f"  Precision: {class_precision:.4f}")
        print(f"  Recall: {class_recall:.4f}")
        print(f"  F1 Score: {class_f1:.4f}")
        print(f"  AP@0.5: {class_ap:.4f}")

# å¯¹éªŒè¯æ•°æ®é›†è¿›è¡Œè¯„ä¼°
evaluate_model(val_data_path, 'Validation')

# å¯¹æµ‹è¯•æ•°æ®é›†è¿›è¡Œè¯„ä¼°
evaluate_model(test_data_path, 'Test')


æ³¨æ„äº‹é¡¹ï¼š

æ•°æ®é›†é…ç½®ï¼šç¡®ä¿ val_data_path å’Œ test_data_path åˆ†åˆ«æŒ‡å‘éªŒè¯å’Œæµ‹è¯•æ•°æ®é›†çš„é…ç½®æ–‡ä»¶ï¼ˆé€šå¸¸ä¸º .yaml æ ¼å¼ï¼‰ã€‚è¿™äº›é…ç½®æ–‡ä»¶åº”åŒ…å«æ•°æ®é›†çš„ç›¸å…³ä¿¡æ¯ï¼Œå¦‚å›¾åƒè·¯å¾„ã€æ ‡ç­¾è·¯å¾„å’Œç±»åˆ«åç§°ç­‰ã€‚

è¯„ä¼°æ–¹æ³•ï¼šä¸Šè¿°ä»£ç å‡è®¾ YOLOv11 ç±»æä¾›äº† val æ–¹æ³•ï¼Œè¯¥æ–¹æ³•å¯ä»¥æ¥å—æ•°æ®é›†é…ç½®æ–‡ä»¶çš„è·¯å¾„ï¼Œå¹¶è¿”å›åŒ…å«è¯„ä¼°æŒ‡æ ‡çš„ç»“æœå­—å…¸ã€‚å¦‚æœæ‚¨çš„å®ç°æœ‰æ‰€ä¸åŒï¼Œè¯·æ ¹æ®å®é™…æƒ…å†µè¿›è¡Œè°ƒæ•´ã€‚

æ€§èƒ½æŒ‡æ ‡ï¼šresults å­—å…¸åº”åŒ…å«æ•´ä½“å’Œæ¯ä¸ªç±»åˆ«çš„è¯„ä¼°æŒ‡æ ‡ï¼Œå¦‚ mAPã€Precisionã€Recallã€F1 Score ç­‰ã€‚å¦‚æœæŸäº›æŒ‡æ ‡ä¸å¯ç”¨ï¼Œè¯·æ ¹æ®æ‚¨çš„éœ€æ±‚å’Œæ¨¡å‹å®ç°è¿›è¡Œç›¸åº”çš„ä¿®æ”¹ã€‚

é€šè¿‡ä¸Šè¿°ä»£ç ï¼Œæ‚¨å¯ä»¥å¯¹éªŒè¯å’Œæµ‹è¯•æ•°æ®é›†è¿›è¡Œè¯„ä¼°ï¼Œå¹¶è¾“å‡ºæ¨¡å‹åœ¨ä¸åŒæ•°æ®é›†ä¸Šçš„æ€§èƒ½æŒ‡æ ‡ã€‚è¿™æœ‰åŠ©äºå…¨é¢äº†è§£æ¨¡å‹çš„è¡¨ç°ï¼Œå¹¶ä¸ºè¿›ä¸€æ­¥çš„ä¼˜åŒ–æä¾›å‚è€ƒã€‚
##########################################################################################################







#####################################################################################################

1. æ•°æ®é›†ç›®å½•ç»“æ„ç¤ºä¾‹
å‡è®¾æ‚¨çš„æ•°æ®é›†å­˜æ”¾åœ¨ä¸€ä¸ªæ ¹ç›®å½•ä¸‹ï¼Œç›®å½•ç»“æ„å¦‚ä¸‹ï¼š


dataset/
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ train/     # è®­ç»ƒå›¾åƒ
â”‚   â”œâ”€â”€ val/       # éªŒè¯å›¾åƒ
â”‚   â””â”€â”€ test/      # æµ‹è¯•å›¾åƒ
â””â”€â”€ labels/
    â”œâ”€â”€ train/     # è®­ç»ƒæ ‡ç­¾
    â”œâ”€â”€ val/       # éªŒè¯æ ‡ç­¾
    â””â”€â”€ test/      # æµ‹è¯•æ ‡ç­¾
images/ æ–‡ä»¶å¤¹ä¸­å­˜æ”¾æ‰€æœ‰å›¾åƒæ–‡ä»¶ã€‚

train/ ç”¨äºè®­ç»ƒçš„å›¾åƒã€‚
val/ ç”¨äºéªŒè¯çš„å›¾åƒã€‚
test/ ç”¨äºæµ‹è¯•çš„å›¾åƒã€‚
labels/ æ–‡ä»¶å¤¹ä¸­å­˜æ”¾å›¾åƒå¯¹åº”çš„æ ‡ç­¾æ–‡ä»¶ã€‚

æ¯ä¸ªæ ‡ç­¾æ–‡ä»¶çš„æ–‡ä»¶åä¸å¯¹åº”å›¾åƒç›¸åŒï¼ˆä½†æ‰©å±•åä¸º .txtï¼‰ï¼Œæ–‡ä»¶å†…å®¹é‡‡ç”¨ YOLO æ ¼å¼ã€‚
2. æ ‡ç­¾æ–‡ä»¶æ ¼å¼è¯´æ˜
æ¯ä¸ªæ ‡ç­¾æ–‡ä»¶é‡‡ç”¨ YOLO æ ¼å¼ï¼Œä¸€è¡Œå¯¹åº”å›¾åƒä¸­çš„ä¸€ä¸ªç›®æ ‡ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š


<class_id> <x_center> <y_center> <width> <height>
å…¶ä¸­ï¼š
<class_id>ï¼šç›®æ ‡ç±»åˆ«çš„ç´¢å¼•ï¼ˆæ•´æ•°ï¼‰ï¼Œå¯¹åº”é…ç½®æ–‡ä»¶ä¸­ names åˆ—è¡¨çš„ç´¢å¼•ï¼ˆä» 0 å¼€å§‹ï¼‰ã€‚
<x_center> å’Œ <y_center>ï¼šè¾¹ç•Œæ¡†ä¸­å¿ƒç‚¹çš„å½’ä¸€åŒ–åæ ‡ï¼ˆç›¸å¯¹äºå›¾åƒå®½åº¦å’Œé«˜åº¦ï¼Œå–å€¼èŒƒå›´ 0ï½1ï¼‰ã€‚
<width> å’Œ <height>ï¼šè¾¹ç•Œæ¡†çš„å½’ä¸€åŒ–å®½åº¦å’Œé«˜åº¦ï¼ˆç›¸å¯¹äºå›¾åƒå°ºå¯¸ï¼Œå–å€¼èŒƒå›´ 0ï½1ï¼‰ã€‚
ç¤ºä¾‹ï¼š
å‡è®¾æœ‰ä¸€å¼ éªŒè¯å›¾åƒ image1.jpgï¼Œå¯¹åº”çš„æ ‡ç­¾æ–‡ä»¶ image1.txt å†…å®¹å¦‚ä¸‹ï¼š

0 0.5 0.5 0.2 0.3
1 0.7 0.8 0.1 0.1
è¡¨ç¤ºå›¾åƒä¸­æœ‰ä¸¤ä¸ªç›®æ ‡ï¼Œç¬¬ä¸€ä¸ªç›®æ ‡ç±»åˆ«ä¸º 0ï¼Œä¸­å¿ƒåœ¨å›¾åƒæ­£ä¸­å¤®ï¼Œå®½åº¦ä¸ºå›¾åƒå®½åº¦çš„ 20%ã€é«˜åº¦ä¸º 30%ï¼›ç¬¬äºŒä¸ªç›®æ ‡ç±»åˆ«ä¸º 1ï¼Œä¸­å¿ƒä½äºå›¾åƒå®½åº¦ 70% å’Œé«˜åº¦ 80% çš„ä½ç½®ï¼Œè¾¹ç•Œæ¡†å°ºå¯¸ä¸ºå›¾åƒå°ºå¯¸çš„ 10%ã€‚

3. æ•°æ®é›†é…ç½®æ–‡ä»¶ï¼ˆdataset.yamlï¼‰
åˆ›å»ºä¸€ä¸ªåä¸º dataset.yaml çš„æ–‡ä»¶ï¼Œç”¨äºæŒ‡å®šæ•°æ®é›†æ ¹ç›®å½•ã€å„å­ç›®å½•åŠç±»åˆ«ä¿¡æ¯ã€‚ä¾‹å¦‚ï¼š

# æ•°æ®é›†é…ç½®æ–‡ä»¶

# å›¾åƒå’Œæ ‡ç­¾çš„æ ¹ç›®å½•ï¼ˆè¯·æ›¿æ¢ä¸ºæ‚¨çš„å®é™…è·¯å¾„ï¼‰
path: path/to/your/dataset

# è®­ç»ƒã€éªŒè¯å’Œæµ‹è¯•å›¾åƒçš„å­ç›®å½•ï¼ˆç›¸å¯¹äº pathï¼‰
train: images/train
val: images/val
test: images/test

# ç±»åˆ«æ•°ï¼ˆè¯·æ›¿æ¢ä¸ºæ‚¨çš„ç±»åˆ«æ•°é‡ï¼‰
nc: 3

# ç±»åˆ«åç§°åˆ—è¡¨ï¼ˆæŒ‰ç´¢å¼•é¡ºåºå¯¹åº”æ ‡ç­¾ä¸­çš„ class_idï¼‰
names:
  0: defect_type_1
  1: defect_type_2
  2: defect_type_3
è¯·ç¡®ä¿å°† path/to/your/dataset æ›¿æ¢ä¸ºæ‚¨çš„æ•°æ®é›†æ ¹ç›®å½•å®é™…è·¯å¾„ã€‚

4. è¯„ä¼°ä»£ç ç¤ºä¾‹
ä¸‹é¢çš„ä»£ç ä½¿ç”¨æ‚¨æä¾›çš„è¯„ä¼°ä»£ç ï¼Œå¹¶æ¼”ç¤ºå¦‚ä½•åˆ©ç”¨æ•°æ®é›†é…ç½®æ–‡ä»¶ï¼ˆä¾‹å¦‚ dataset.yamlï¼‰å¯¹éªŒè¯é›†å’Œæµ‹è¯•é›†è¿›è¡Œè¯„ä¼°ï¼š




import torch
from yolov11 import YOLOv11  # å‡è®¾æœ‰ä¸€ä¸ª YOLOv11 çš„ Python å®ç°

# åŠ è½½é¢„è®­ç»ƒçš„ YOLOv11 æ¨¡å‹
model = YOLOv11(pretrained=True)
model.eval()

# å®šä¹‰æ•°æ®é›†é…ç½®æ–‡ä»¶çš„è·¯å¾„ï¼ˆåŒ…å«éªŒè¯å’Œæµ‹è¯•é›†çš„é…ç½®ä¿¡æ¯ï¼‰
data_config_path = 'path/to/your/dataset.yaml'  # æ›¿æ¢ä¸ºæ‚¨çš„æ•°æ®é›†é…ç½®æ–‡ä»¶è·¯å¾„

def evaluate_model(data_path, dataset_type='Validation'):
    """
    ä½¿ç”¨æŒ‡å®šçš„æ•°æ®é›†è¯„ä¼°æ¨¡å‹æ€§èƒ½ã€‚

    å‚æ•°ï¼š
    - data_path: æ•°æ®é›†é…ç½®æ–‡ä»¶çš„è·¯å¾„
    - dataset_type: æ•°æ®é›†ç±»å‹ï¼ˆ'Validation' æˆ– 'Test'ï¼‰
    """
    print(f"Evaluating on {dataset_type} Dataset...")
    results = model.val(data=data_path)

    # è¾“å‡ºæ•´ä½“è¯„ä¼°æŒ‡æ ‡
    print(f"{dataset_type} Dataset - Overall mAP@0.5: {results['mAP_0.5']:.4f}")
    print(f"{dataset_type} Dataset - Overall mAP@0.5:0.95: {results['mAP_0.5:0.95']:.4f}")
    print(f"{dataset_type} Dataset - Overall Precision: {results['precision']:.4f}")
    print(f"{dataset_type} Dataset - Overall Recall: {results['recall']:.4f}")
    print(f"{dataset_type} Dataset - Overall F1 Score: {results['f1']:.4f}")

    # è¾“å‡ºæ¯ä¸ªç±»åˆ«çš„è¯„ä¼°æŒ‡æ ‡
    for idx, class_name in enumerate(results['names']):
        class_precision = results['per_class_precision'][idx]
        class_recall = results['per_class_recall'][idx]
        class_f1 = results['per_class_f1'][idx]
        class_ap = results['per_class_ap'][idx]
        print(f"Class: {class_name}")
        print(f"  Precision: {class_precision:.4f}")
        print(f"  Recall: {class_recall:.4f}")
        print(f"  F1 Score: {class_f1:.4f}")
        print(f"  AP@0.5: {class_ap:.4f}")

# ç¤ºä¾‹ç”¨æ³•ï¼šåˆ†åˆ«å¯¹éªŒè¯å’Œæµ‹è¯•æ•°æ®é›†è¿›è¡Œè¯„ä¼°
# å¦‚æœéªŒè¯é›†å’Œæµ‹è¯•é›†éƒ½åœ¨ dataset.yaml ä¸­å®šä¹‰ï¼Œå¯ä»¥ç›´æ¥ç”¨åŒä¸€ä¸ªé…ç½®æ–‡ä»¶è¿›è¡Œè¯„ä¼°ï¼Œ
# æ¨¡å‹å†…éƒ¨ä¼šæ ¹æ®é…ç½®æ–‡ä»¶ä¸­ç›¸åº”çš„ 'val' æˆ– 'test' å­—æ®µåŠ è½½å¯¹åº”æ•°æ®ã€‚

print("----- éªŒè¯é›†è¯„ä¼° -----")
evaluate_model(data_config_path, 'Validation')

print("\n----- æµ‹è¯•é›†è¯„ä¼° -----")
evaluate_model(data_config_path, 'Test')
è¯´æ˜ï¼š

åœ¨ä¸Šé¢çš„ä»£ç ä¸­ï¼Œdata_config_path æŒ‡å‘çš„æ˜¯æ•°æ®é›†é…ç½®æ–‡ä»¶ï¼ˆdataset.yamlï¼‰ï¼Œè¯¥æ–‡ä»¶ä¸­å·²ç»åŒ…å«äº†è®­ç»ƒã€éªŒè¯å’Œæµ‹è¯•é›†çš„å›¾åƒç›®å½•ä¿¡æ¯ä»¥åŠç±»åˆ«è®¾ç½®ã€‚
evaluate_model å‡½æ•°è°ƒç”¨ model.val(data=data_path)ï¼Œè¿™å‡è®¾æ‚¨çš„ YOLOv11 å®ç°æ”¯æŒç›´æ¥ä½¿ç”¨é…ç½®æ–‡ä»¶è¿›è¡Œè¯„ä¼°ï¼Œå¹¶æ ¹æ®é…ç½®æ–‡ä»¶åŠ è½½ç›¸åº”çš„æ•°æ®é›†ã€‚
æ ¹æ®å®é™…å®ç°ï¼Œå¦‚æœéœ€è¦åˆ†åˆ«æŒ‡å®šéªŒè¯é›†å’Œæµ‹è¯•é›†çš„è·¯å¾„ï¼Œå¯ä»¥è°ƒæ•´é…ç½®æ–‡ä»¶æˆ–åˆ†åˆ«ä¼ å…¥ä¸åŒçš„è·¯å¾„ã€‚


#########################################################




from ultralytics import YOLO  # ä½¿ç”¨å®˜æ–¹API
import torch
from tabulate import tabulate

# åŠ è½½å®˜æ–¹é¢„è®­ç»ƒæ¨¡å‹ (æ³¨æ„æ­£ç¡®æ¨¡å‹åç§°)
model = YOLO('yolov11n.pt')  # å®˜æ–¹æ¨¡å‹åä¸ºyolov11nè€Œéyolo11n
model.eval()

def evaluate_model(data_config, dataset_type='val'):
    """
    ä¼˜åŒ–åçš„å¤šåˆ†ç±»è¯„ä¼°å‡½æ•°ï¼ˆç¬¦åˆUltralyticsæ ‡å‡†ï¼‰
    
    å‚æ•°ï¼š
    - data_config: æ•°æ®é›†é…ç½®æ–‡ä»¶è·¯å¾„ (.yaml)
    - dataset_type: æ•°æ®é›†ç±»å‹ ('val' æˆ– 'test')
    """
    print(f"\n{'='*30} {dataset_type.upper()} è¯„ä¼° {'='*30}")
    
    # æ‰§è¡ŒéªŒè¯ï¼ˆæ·»åŠ å…³é”®å‚æ•°ï¼‰
    results = model.val(
        data=data_config,
        split=dataset_type,  # å®˜æ–¹ä½¿ç”¨splitå‚æ•°
        plots=True,          # ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
        save_json=True,      # ä¿å­˜JSONæ ¼å¼ç»“æœ
        conf=0.01,           # ç½®ä¿¡åº¦é˜ˆå€¼
        iou=0.6              # IoUé˜ˆå€¼
    )
    
    # å…¨å±€æŒ‡æ ‡è¾“å‡º
    print(f"\n[å…¨å±€æŒ‡æ ‡]")
    print(f"mAP@0.5:0.95 | {results.box.map:.4f} (COCOæ ‡å‡†)")
    print(f"mAP@0.5      | {results.box.map50:.4f}")
    print(f"Precision    | {results.box.precision.mean():.4f}")
    print(f"Recall       | {results.box.recall.mean():.4f}")
    print(f"æ¨ç†é€Ÿåº¦     | {results.speed['inference']:.2f} ms/å¼ ")

    # å¤šåˆ†ç±»è¯¦ç»†æŒ‡æ ‡ï¼ˆè¡¨æ ¼åŒ–è¾“å‡ºï¼‰
    print("\n[åˆ†ç±»åˆ«æŒ‡æ ‡]")
    table_data = []
    for idx, name in enumerate(results.names):
        row = [
            name,
            f"{results.box.ap50[idx]:.4f}",
            f"{results.box.ap75[idx]:.4f}",
            f"{results.box.ap[idx]:.4f}",
            f"{results.box.precision[idx]:.4f}",
            f"{results.box.recall[idx]:.4f}"
        ]
        table_data.append(row)
    
    print(tabulate(table_data,
                 headers=['ç±»åˆ«', 'AP50', 'AP75', 'AP50-95', 'Precision', 'Recall'],
                 tablefmt='github'))
    
    # å¯è§†åŒ–ä¿å­˜
    print("\nç”Ÿæˆå¯è§†åŒ–æ–‡ä»¶ï¼š")
    print(f"- æ··æ·†çŸ©é˜µ: runs/detect/val/confusion_matrix.png")
    print(f"- é¢„æµ‹ç¤ºä¾‹: runs/detect/val/val_batch_pred.jpg")
    print(f"- JSONç»“æœ: runs/detect/val/results.json")

# é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆç¤ºä¾‹ï¼‰
data_config_path = 'path/to/your/dataset.yaml'

# æ‰§è¡ŒéªŒè¯
if __name__ == "__main__":
    # éªŒè¯é›†è¯„ä¼°
    evaluate_model(data_config_path, 'val')
    
    # æµ‹è¯•é›†è¯„ä¼°ï¼ˆéœ€è¦é…ç½®æ–‡ä»¶ä¸­å®šä¹‰testè·¯å¾„ï¼‰
    evaluate_model(data_config_path, 'test')



ä¸»è¦æ”¹è¿›ç‚¹è¯´æ˜ï¼š
APIæ ‡å‡†åŒ–ï¼š
ä½¿ç”¨from ultralytics import YOLOæ›¿ä»£è‡ªå®šä¹‰å¯¼å…¥
ä¿®æ­£æ¨¡å‹åç§°yolov11n.ptï¼ˆå®˜æ–¹å‘½åè§„èŒƒï¼‰
ä½¿ç”¨splitå‚æ•°æ›¿ä»£è‡ªå®šä¹‰ç±»å‹åˆ¤æ–­
æŒ‡æ ‡è¾“å‡ºä¼˜åŒ–ï¼š
å¢åŠ AP75æŒ‡æ ‡è¾“å‡º
æ·»åŠ æ¨ç†é€Ÿåº¦æ˜¾ç¤º
ä½¿ç”¨è¡¨æ ¼åŒ–è¾“å‡ºåˆ†ç±»åˆ«æŒ‡æ ‡
ç¬¦åˆCOCOæ ‡å‡†æŒ‡æ ‡å‘½åï¼ˆbox.map / box.map50ï¼‰
å‚æ•°ä¼˜åŒ–ï¼š
æ·»åŠ save_json=Trueä¿å­˜å¯è§£æç»“æœ
è®¾ç½®åˆç†é»˜è®¤å€¼conf=0.01å’Œiou=0.6
è‡ªåŠ¨ç”Ÿæˆå¯è§†åŒ–æ–‡ä»¶è·¯å¾„æç¤º
å¤šåˆ†ç±»æ”¯æŒå¼ºåŒ–ï¼š
æ˜¾ç¤ºæ¯ä¸ªç±»åˆ«çš„AP50/AP75/AP50-95
åˆ†ç±»åˆ«ç²¾ç¡®ç‡å’Œå¬å›ç‡å•ç‹¬æ˜¾ç¤º
å…¼å®¹ä¸åŒæ•°æ®åˆ†å‰²ï¼ˆval/testï¼‰
ä½¿ç”¨å‰éœ€ç¡®ä¿ï¼š
bash
pip install ultralytics tabulate
æ³¨æ„ï¼šå®é™…ä½¿ç”¨æ—¶è¯·ç¡®ä¿ï¼š
dataset.yamlä¸­æ­£ç¡®å®šä¹‰testè·¯å¾„
æµ‹è¯•é›†æ ‡ç­¾æ–‡ä»¶ç¬¦åˆYOLOæ ¼å¼
æ¨¡å‹æ–‡ä»¶ä¸ä»»åŠ¡åŒ¹é…ï¼ˆåˆ†ç±»æ•°ä¸€è‡´ï¼‰
############################################






YOLOv11 å¤šåˆ†ç±»ç‰©ä½“æ£€æµ‹è¯„ä¼°å®Œæ•´æŒ‡å—
ä¸€ã€ç¯å¢ƒå‡†å¤‡
bash
# å®‰è£…æ ¸å¿ƒä¾èµ–
pip install ultralytics tabulate matplotlib torch
äºŒã€æ•°æ®é›†é…ç½®æ ‡å‡†
1. ç›®å½•ç»“æ„è§„èŒƒ
bash
datasets/
â””â”€â”€ defect_detection/
    â”œâ”€â”€ train/
    â”‚   â”œâ”€â”€ images/  # è®­ç»ƒé›†å›¾åƒ
    â”‚   â””â”€â”€ labels/  # YOLOæ ¼å¼æ ‡ç­¾
    â”œâ”€â”€ val/
    â”‚   â”œâ”€â”€ images/  # éªŒè¯é›†å›¾åƒ
    â”‚   â””â”€â”€ labels/
    â””â”€â”€ test/
        â”œâ”€â”€ images/  # æµ‹è¯•é›†å›¾åƒ
        â””â”€â”€ labels/
2. æ ‡ç­¾æ–‡ä»¶ç¤ºä¾‹
labels/train/image001.txt:
text
0 0.347656 0.489583 0.128906 0.239583
2 0.712891 0.581250 0.089844 0.166667
3. æ•°æ®é›†é…ç½®æ–‡ä»¶ (defect_config.yaml)
text
path: /projects/datasets/defect_detection
train: train/images
val: val/images
test: test/images

nc: 3
names:
  0: scratch
  1: dent
  2: crack
ä¸‰ã€è¯„ä¼°ä»£ç å®ç°
python
from ultralytics import YOLO
from tabulate import tabulate

def main():
    # åˆå§‹åŒ–æ¨¡å‹
    model = YOLO('yolov11n.pt')
    
    # æ‰§è¡Œè¯„ä¼°æµç¨‹
    run_evaluation(model, 'defect_config.yaml')

def run_evaluation(model, config_path):
    """å…¨æµç¨‹è¯„ä¼°å‡½æ•°"""
    # éªŒè¯é›†è¯„ä¼°
    print("\n" + "="*40)
    print("Starting Validation Evaluation")
    results_val = evaluate_model(model, config_path, 'val')
    
    # æµ‹è¯•é›†è¯„ä¼°
    print("\n" + "="*40)
    print("Starting Test Evaluation")
    results_test = evaluate_model(model, config_path, 'test')
    
    return results_val, results_test

def evaluate_model(model, data_config, dataset_type='val'):
    """æ¨¡å‹è¯„ä¼°æ ¸å¿ƒå‡½æ•°"""
    print(f"\n{'='*30} {dataset_type.upper()} EVALUATION {'='*30}")
    
    # æ‰§è¡ŒéªŒè¯æµç¨‹
    results = model.val(
        data=data_config,
        split=dataset_type,
        plots=True,
        save_json=True,
        conf=0.01,
        iou=0.6,
        device='cuda' if torch.cuda.is_available() else 'cpu'
    )
    
    # è¾“å‡ºè¯„ä¼°æŒ‡æ ‡
    print_metrics(results)
    
    return results

def print_metrics(results):
    """ç»“æ„åŒ–è¾“å‡ºè¯„ä¼°æŒ‡æ ‡"""
    # å…¨å±€æŒ‡æ ‡
    print("\n[Global Metrics]")
    print(f"mAP@0.5:0.95 | {results.box.map:.4f} (COCO Primary)")
    print(f"mAP@0.5      | {results.box.map50:.4f}")
    print(f"Precision    | {results.box.precision.mean():.4f} Â±{results.box.precision.std():.4f}")
    print(f"Recall       | {results.box.recall.mean():.4f} Â±{results.box.recall.std():.4f}")
    print(f"Inference Speed | {results.speed['inference']:.2f} ms/img")
    
    # åˆ†ç±»åˆ«æŒ‡æ ‡è¡¨æ ¼
    print("\n[Per-Class Metrics]")
    table_data = [
        [
            name,
            f"{results.box.ap50[idx]:.4f}",
            f"{results.box.ap75[idx]:.4f}",
            f"{results.box.ap[idx]:.4f}",
            f"{results.box.precision[idx]:.4f}",
            f"{results.box.recall[idx]:.4f}"
        ]
        for idx, name in enumerate(results.names)
    ]
    
    print(tabulate(table_data,
                 headers=['Class', 'AP50', 'AP75', 'AP50-95', 'Precision', 'Recall'],
                 tablefmt='github'))
    
    # è¾“å‡ºæ–‡ä»¶è·¯å¾„
    print("\nGenerated Files:")
    print(f"- æ··æ·†çŸ©é˜µ: runs/detect/{results.save_dir}/confusion_matrix.png")
    print(f"- é¢„æµ‹å¯è§†åŒ–: runs/detect/{results.save_dir}/val_batch_pred.jpg")
    print(f"- è¯¦ç»†ç»“æœ: runs/detect/{results.save_dir}/results.json")

if __name__ == "__main__":
    main()
å››ã€å…³é”®å‚æ•°è¯´æ˜
å‚æ•°	ç±»å‹	é»˜è®¤å€¼	è¯´æ˜
split	str	'val'	æ•°æ®é›†åˆ†å‰²ç±»å‹ (val/test)
plots	bool	True	ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
save_json	bool	True	ä¿å­˜JSONæ ¼å¼ç»“æœ
conf	float	0.01	æ£€æµ‹ç½®ä¿¡åº¦é˜ˆå€¼
iou	float	0.6	IoUé˜ˆå€¼
device	str	auto	è®¡ç®—è®¾å¤‡è‡ªåŠ¨é€‰æ‹©
äº”ã€æ‰§è¡Œä¸è¾“å‡ºè§£è¯»
1. è¿è¡Œå‘½ä»¤
bash
python evaluate.py
2. å…¸å‹è¾“å‡ºç¤ºä¾‹
text
============================== VAL EVALUATION =============================

[Global Metrics]
mAP@0.5:0.95 | 0.6723 (COCO Primary)
mAP@0.5      | 0.8521
Precision    | 0.7812 Â±0.032
Recall       | 0.6934 Â±0.041
Inference Speed | 4.23 ms/img

[Per-Class Metrics]
| Class    |   AP50 |   AP75 |   AP50-95 |   Precision |   Recall |
|----------|--------|--------|-----------|-------------|----------|
| scratch  | 0.8723 | 0.7021 |    0.6423 |      0.8023 |   0.7123 |
| dent     | 0.8345 | 0.6532 |    0.5934 |      0.7623 |   0.6834 |
| crack    | 0.8012 | 0.5921 |    0.5432 |      0.7321 |   0.6532 |
3. è¾“å‡ºæ–‡ä»¶è¯´æ˜
confusion_matrix.png: ç±»åˆ«æ··æ·†çŸ©é˜µ
val_batch_pred.jpg: å…¸å‹æ£€æµ‹ç»“æœå¯è§†åŒ–
results.json: åŒ…å«æ‰€æœ‰æŒ‡æ ‡çš„JSONæ–‡ä»¶
å…­ã€é«˜çº§é…ç½®å»ºè®®
å¤šGPUè¯„ä¼°åŠ é€Ÿï¼š
python
model.val(..., device=[0,1,2,3])  # ä½¿ç”¨4å—GPU
æ‰¹é‡å¤§å°ä¼˜åŒ–ï¼š
python
model.val(..., batch=64)  # æ ¹æ®æ˜¾å­˜è°ƒæ•´
ç‰¹å®šç±»åˆ«åˆ†æï¼š
python
# åœ¨print_metricså‡½æ•°ä¸­æ·»åŠ 
print(f"\nClass 'crack'è¯¦ç»†æŒ‡æ ‡:")
print(f"- æŸ¥å‡†ç‡: {results.box.precision[2]:.4f}")
print(f"- æ¼æ£€ç‡: {1 - results.box.recall[2]:.4f}")
æœ¬æŒ‡å—å®Œæ•´å®ç°äº†YOLOv11çš„è¯„ä¼°æµç¨‹ï¼ŒåŒ…å«å¤šåˆ†ç±»æ£€æµ‹çš„å…³é”®æŒ‡æ ‡åˆ†æï¼Œå¯æ»¡è¶³å·¥ä¸šçº§ç¼ºé™·æ£€æµ‹ã€å•†å“è¯†åˆ«ç­‰åœºæ™¯çš„è¯„ä¼°éœ€æ±‚ã€‚






ç¬¬äºŒéƒ¨åˆ†ï¼šå·®å¼‚å›¾è®¡ç®—

metadata, proc_ref, proc_test, proc_diff, max_pos, min_pos = get_diff_map(ref, test, fn_id, selected_lot_id, is_median_ref, int(max_features), int(max_shift), ransac_reproj_thres
###############################




###############################lrf å›å®¶ä½œæ¥­#############################################
def get_lrf_file(data_dir, selected_lot_id):
    if os.path.exists(os.path.join(data_dir, selected_lot_id, f"{selected_lot_id}_ADD.lrf")):
        lrf_file = os.path.join(data_dir, selected_lot_id, f"{selected_lot_id}_ADD.lrf")
    elif os.path.exists(os.path.join(data_dir, selected_lot_id, f"{selected_lot_id}_Classified.lrf")):
        lrf_file = os.path.join(data_dir, selected_lot_id, f"{selected_lot_id}_Classified.lrf")
    elif os.path.exists(os.path.join(data_dir, selected_lot_id, f"{selected_lot_id}_classified.lrf")):
        lrf_file = os.path.join(data_dir, selected_lot_id, f"{selected_lot_id}_classified.lrf")
    elif os.path.exists(os.path.join(data_dir, selected_lot_id, f"{selected_lot_id}.lrf")):
        lrf_file = os.path.join(data_dir, selected_lot_id, f"{selected_lot_id}.lrf")
    else:
        lrf_file = None

    return lrf_file

def read_lrf_file(file_path):
    with open(file_path, 'r') as file:
        content = file.read()
    return content

def detect_defect_list(content):
    pattern = re.compile(r'\[DefectList\]\s+DefectDataColumn.*?DefectDataList\s+\d+\s+(.*?)\s+(?=\[|$)', re.DOTALL)
    match = pattern.search(content)
    if match:
        # logger.debug("DefectList found in the LRF file.")
        return match.group(1)
    # logger.debug("No DefectList found in the LRF file.")
    return None

def extract_no_and_classtype(defect_data):
    # logger.debug(f"defect_data: {defect_data}")

    lines = defect_data.strip().split('\n')
    results = []
    for line in lines:
        parts = line.split()
        if len(parts) >= 9:
            no = parts[0]
            classtype = parts[8]
            results.append((no, classtype))
    # logger.debug(f"results: {results}")
    return results

def get_defect_list(lrf_path):
    # if data_type == "old_data":
    file_path = lrf_path
    content = read_lrf_file(file_path)
    defect_data = detect_defect_list(content)
    image_list = []
    defect_type = []
    if defect_data:
        results = extract_no_and_classtype(defect_data)
        for no, classtype in results:
            # if classtype == '0' or classtype == '1':
            image_list.append(no)
            defect_type.append(classtype)
    # logger.info(f"image_list:{image_list}")
    return image_list, defect_type 




[DefectList]
DefectDataColumn No X Y W H Kind Ch PixelCount ClassType U/L ShfitDir KindBits MaskToMask Block SubBlock StripeNo Label ChgDiff Comment;
DefectDataList 2518
         1 -65575.3190  48572.2706      2.5000      0.8996 0000000000008c8c 00600000 254   0   2   0 0d000000000d00000008011881100f00000000000000000000000000000000000000000000000000   1   0  -1   0       -1     -999 
         2 -65509.8190  13637.9665      1.2000      0.8496 0000000000000b08 00000060 185   0   2   0 00000000000000c40008011881100f00000000000000000000000000000000000000000000000000   1   0  -1   0       -1     -999 
         3 -65505.8690  45174.8051      0.5000      0.1999 0000000000004b00 00000030  17   0   2   0 0080000000c004c40008011000000000000000000000000000000000000000000000000000000000   1   0  -1   0       -1     -999 

        2514  63532.3185  -7693.8569      0.3250      0.1499 0000000000000b00 02000000   6   0   2   0 0000000000800c040008000000000000000000000000000000000000000000000000000000000000   1   0  -1 1076       -1     -999 
        2515  63758.7310   9989.8003      0.7500      0.5997 000000000000000b 10000000  11  10   2   0 00000000000000330000000081100100000000000000000000000000000000000000000000000000   1   0  -1 1078       -1     -999 
        2516  64450.4435  14399.3323      1.0750      0.7496 0000000000000b0b 00000020  60   0   2   0 00000000000000f70008211081100f00000000000000000000000000000000000000000000000000   1   0  -1 1083       -1     -999 
        2517  64592.7935  38925.8217      2.6250      0.9495 0000000000004b4b 60000000 403   0   2   0 00b0000000c004f70008011881100f00000000000000000000000000000000000000000000000000   1   0  -1 1085       -1     -999 
        2518  64941.1060  42573.1883      0.3500      0.4998 0000000000000100 0000000c  21  10   2   0 00000000000004040000000000000000000000000000000000000000000000000000000000000000   1   0  -1 1087       -1     -999

######################################labeling config

interfaces = [
  "panel",
  "update",
  "controls",
  "side-column",
  "completions:menu",
  "completions:add-new",
  "completions:delete",
  "predictions:menu",
],

user = {
  'pk': 1,
  'firstName': "Labeler",
  'lastName': "",
},
###############################json function

interfaces = [
  "panel",
  "update",
  "controls",
  "side-column",
  "completions:menu",
  "completions:add-new",
  "completions:delete",
  "predictions:menu",
],

user = {
  'pk': 1,
  'firstName': "Labeler",
  'lastName': "",
},

################## image processor
from PIL import Image
import base64
from io import BytesIO
import numpy as np
import json
import cv2
from alignment.alignment import load_defect_pair, get_diff_map
import matplotlib.pyplot as plt
# Function to convert a NumPy array to a Base64 encoded string

def numpy_to_base64(img_array):
    pil_img = Image.fromarray(img_array)
    buffer = BytesIO()
    pil_img.save(buffer, format="JPEG")
    return base64.b64encode(buffer.getvalue()).decode("utf-8")


# Function to load images from a JSON file line by line and save into a dictionary
def load_images_from_json(json_file):
    images = {}
    with open(json_file, 'r') as f:
        for line in f:
            data = json.loads(line)
            lot_id = data['lot_id']
            images[lot_id] = data
    return images

def apply_colormap(np_array, colormap, vmin=None, vmax=None):
    # norm_array = (np_array - np_array.min()) / (np_array.max() - np_array.min())
    if vmin and vmax:
        norm_array = (np_array - vmin) / (vmax - vmin)
    else:
        norm_array = np_array
    colormap_func = plt.get_cmap(colormap)
    colored_array = colormap_func(norm_array)
    return (colored_array[:, :, :3] * 255).astype(np.uint8)

# Define a 2x2 convolution kernel
def conv_kernel(kernel_size):
    return np.ones((kernel_size, kernel_size), dtype=np.float32) / (kernel_size ** 2)

def get_image_pair_for_studio_input(data_dir, selected_lot_id, selected_image_id, selected_image_type, vmin_level, max_features, max_shift, ransac_reproj_threshold, selected_alignment_method, conv_kernel_size):
    img_dir = f"{data_dir}/{selected_lot_id}/{selected_lot_id}/Images/InstantReview{selected_image_type}"
    fn_id = selected_image_id
    ref, test, is_median_ref = load_defect_pair(img_dir, fn_id)
    metadata, proc_ref, proc_test, proc_diff, max_pos, min_pos = \
        get_diff_map(ref, test, fn_id, selected_lot_id, is_median_ref, int(max_features), int(max_shift), ransac_reproj_threshold, method=selected_alignment_method)
    print(f"max_pos:{metadata['max_pos']}")
    print(f"min_pos:{metadata['min_pos']}")

    ref_colored = apply_colormap(proc_ref, 'gray')
    test_colored = apply_colormap(proc_test, 'gray')
    diff_colored = apply_colormap(proc_diff, 'seismic', vmin_level, -vmin_level)
    conv_diff_image = cv2.filter2D(diff_colored, -1, conv_kernel(int(conv_kernel_size)))
    img1_base64 = numpy_to_base64(ref_colored)
    img2_base64 = numpy_to_base64(test_colored)
    img3_base64 = numpy_to_base64(diff_colored)
    img4_base64 = numpy_to_base64(conv_diff_image)
    return [img1_base64, img2_base64, img4_base64], metadata

##############inference ########################################


def load_image_as_numpy(image_path):
    img = Image.open(image_path).convert('RGB')  # Ensure image is in RGB format
    return np.array(img)

def preprocess_image(img_np):
    if img_np.ndim == 2:  # If the image is grayscale, convert to RGB
        img_np = np.stack((img_np,) * 3, axis=-1)
    elif img_np.shape[2] == 4:  # If the image has an alpha channel, remove it
        img_np = img_np[:, :, :3]
    return img_np

def inference(img_np, ckpt="/home/hubert007/Code/label_tool/labeling/runs/detect/train3/weights/best.pt"):
    # Load the finetuned model checkpoint
    model = YOLO(ckpt)
    
    # Preprocess the image
    img_np = preprocess_image(img_np)
    
    # Perform object detection
    results = model(img_np)
    # print(results['precision'])
    # print(results['recall'])

    # logger.info(f"inference results: {results}")
    # Extract bounding box information
    if results and len(results[0].boxes) > 0:
        boxs_and_labels = []
        # logger.debug(f"cls length: {len(results[0].boxes.cls)}")
        # logger.debug(f"cls shape: {results[0].boxes.cls.shape}")
        for i in range(len(results[0].boxes.cls)):

            # logger.info(f"Detected boxs: {results[0].boxes}")

            box = results[0].boxes  # Assuming we take the first detected box
            label = box.cls[i]
            x1, y1, x2, y2 = box.xyxy[i]
            width = x2 - x1
            height = y2 - y1
            boxs_and_labels.append((x1, y1, width, height, label))
        return boxs_and_labels
    else:
        return None

# Example usage
if __name__ == "__main__":
    image_path = "/mnt/fs0/dataset/Layer_M/N3_M0-16_20240920_145106/N3_M0-16_20240920_145106/Images/InstantReviewT/1411L.png"
    np_image = load_image_as_numpy(image_path)
    bbox = inference(np_image)
    # print('test result', bbox[0][0], bbox[0][1], bbox[0][2], bbox[0][3], bbox[0][4])  #ok  (x1, y1, width, height, label)

    
    if bbox:
        print(f"Top-left: ({bbox[0][0]}, {bbox[0][1]}), Width: {bbox[0][2]}, Height: {bbox[0][3]}, label: {bbox[0][4]}")
    else:
        print("No bounding box detected.")


######################################fine tune
from ultralytics import YOLO
import os
import argparse
from loguru import logger
import yaml


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--epochs', type=int, default=200, help='number of epochs')
    parser.add_argument('--imgsz', type=int, default=256, help='image size')
    parser.add_argument('--exp_name', type=str, default=None, help='name of your experiment')
    parser.add_argument('--dataset_path', type=str, required=True, help='dataset path')
    args = parser.parse_args()



    # Create the directory if it doesn't exist
    os.makedirs('prelabel/model_based/YOLO/train_settings', exist_ok=True)

    # Define the content of the YAML file
    yaml_content = {
        'path': args.dataset_path,
        'train': 'train/images',
        'val': 'val/images',
        'test': 'test/images',
        'nc': 1,
        'names': {
            0: 'defect'
        }
    }

    # Write the content to the YAML file
    with open(f'prelabel/model_based/YOLO/train_settings/{args.exp_name}.yaml', 'w') as yaml_file:
        yaml.dump(yaml_content, yaml_file, default_flow_style=False)


    # Load a model
    model = YOLO("yolo11n.pt")  # load a pretrained model (recommended for training)

    train_results = model.train(data=f"prelabel/model_based/YOLO/train_settings/{args.exp_name}.yaml", epochs=args.epochs, imgsz=args.imgsz, name=args.exp_name)




    # Export the model to ONNX format
    path = model.export(format="onnx")  # return path to exported model

if __name__ == "__main__":
    main()



#########  dataset#################################################


import shutil
from sklearn.model_selection import train_test_split
import json
import os
from PIL import Image
import numpy as np
from torchvision.utils import save_image
import torch
import cv2
import re
import sqlite3
from PIL import Image, ImageDraw
from alignment.alignment import load_defect_pair, get_diff_map
from frontend.image_processor import numpy_to_base64, load_images_from_json, apply_colormap, conv_kernel
import argparse
from loguru import logger
from tqdm import tqdm
import albumentations as A
from albumentations.pytorch import ToTensorV2

def get_augmentation_pipeline(aug_params):
    """
    Create albumentations augmentation pipeline.
    We use "albumentations" because it can handle the augmentations of bounding boxes. For example, when we rotate the image,
    the bounding boxes should also be rotated.
    :param aug_params: dict of augmentation parameters
    :return: albumentations.Compose object with augmentation pipeline
    """
    return A.Compose([
        A.RandomRotate90(p=aug_params.get('rotation_prob', 0.5)),
        A.HorizontalFlip(p=aug_params.get('flip_prob', 0.5)),
        A.VerticalFlip(p=aug_params.get('flip_prob', 0.5)),
        A.Affine(
            scale=aug_params.get('scale', (1.0, 1.2)),
            translate_percent=(0.0, 0.0),
            p=1.0
        ),
        # A.ColorJitter(
        #     brightness=aug_params.get('brightness', 0.2),
        #     contrast=aug_params.get('contrast', 0.2),
        #     p=1.0
        # ),
        ToTensorV2()
    ], bbox_params=A.BboxParams(format='yolo', label_fields=['category_ids']))


def process_and_augment_images(image_array, bounding_boxes, aug_params, img_path, original=False):
    """
    augment the images and bounding boxes.
    """
    # Ensure the image is in RGB format
    if image_array.shape[2] == 4:  # If the image has an alpha channel
        image_array = cv2.cvtColor(image_array, cv2.COLOR_BGRA2RGB)
    else:
        image_array = cv2.cvtColor(image_array, cv2.COLOR_BGR2RGB)

    # Prepare bounding boxes and labels
    bboxes = []
    category_ids = []
    for bbox in bounding_boxes:
        x_center = (bbox['x']+bbox['width']/2) / image_array.shape[1]
        y_center = (bbox['y']+bbox['height']/2) / image_array.shape[0]
        width = bbox['width'] / image_array.shape[1]
        height = bbox['height'] / image_array.shape[0]
        x_center = min(1.0, max(0.0, x_center))
        y_center = min(1.0, max(0.0, y_center))
        width = min(1.0, max(0.0, width))
        height = min(1.0, max(0.0, height))

        label = bbox['label']
        
        if label == "Defect_right" or label == "Defect_left":
            category_ids.append(0)
        elif label == "4D":
            return None
        
        bboxes.append([x_center, y_center, width, height])

    # Apply augmentations
    if original == True:
        return bboxes, category_ids
    try:
        transform = get_augmentation_pipeline(aug_params)
        augmented = transform(image=image_array, bboxes=bboxes, category_ids=category_ids)
        return augmented['image'], augmented['bboxes'], augmented['category_ids']
    except:
        logger.debug(f"error on {img_path}")
        return None

    # return augmented['image'], augmented['bboxes'], augmented['category_ids']

def check_image_variants(image_path):
    """
    Get the base path and file name without extension (1070L.png ,1070U.png ....)
    """
    logger.info(f"Checking image variants for {image_path}")
    base_path, file_name = os.path.split(image_path)
    file_name_no_ext = os.path.splitext(file_name)[0]
    
    # Define the variants
    variants = ['L', 'R', 'U', 'D']
    
    # Initialize a dictionary to store the paths of existing variants
    # Check for each variant
    for variant in variants:
        variant_path = os.path.join(base_path, f"{file_name_no_ext}{variant}.png")
        if os.path.exists(variant_path):
            return variant_path
        

    
def db_to_metadata(db_file, metadata_file, masked_image_output=None):
    """
    Convert SQLite database to metadata JSON file.
    """
    # Connect to SQLite database
    conn = sqlite3.connect(db_file)
    cursor = conn.cursor()

    # Query to retrieve all rows from the results_table
    cursor.execute('SELECT image_path, results_json FROM results_table')
    rows = cursor.fetchall()

    # Create output directory if it doesn't exist
    if masked_image_output:
        output_dir = masked_image_output
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)

    # Initialize a list to store metadata
    metadata_list = []

    for row in rows:
        img_path, results_json = row
        split_img_path = img_path.split(', ')
        data_dir = split_img_path[0]
        lot_id = split_img_path[1]
        image_id = split_img_path[2]
        results = json.loads(results_json)
        # logger.debug(f"img_path: {img_path}")
        # Check if 'areas' key exists in the JSON
        if 'areas' in results:
            t_boxes = []
            rt_boxes = []
            areas = results['areas']
            for area_key, area_value in areas.items():
                if area_value['object'] == 'image3' or area_value['object'] == 'image6':
                    label = area_value['results'][0]['value']['rectanglelabels'][0]
                    x = area_value['x']
                    y = area_value['y']
                    width = area_value['width']
                    height = area_value['height']
                    if area_value['object'] == 'image3':
                    # Append metadata to the list
                        t_boxes.append(
                            {"x": x, "y": y, "width": width, "height": height, "label": label} 
                        )
                    else:
                        rt_boxes.append(
                            {"x": x, "y": y, "width": width, "height": height, "label": label} 
                        )

            metadata_list.append({
                "image_path": f"{data_dir}/{lot_id}/{lot_id}/Images/InstantReviewT/{image_id}.png",
                "bounding_box": t_boxes,
            })
            metadata_list.append({
                "image_path": f"{data_dir}/{lot_id}/{lot_id}/Images/InstantReviewRt/{image_id}.png",
                "bounding_box": rt_boxes,
            })

    # Write metadata to a JSON file
    with open(metadata_file, 'w') as json_file:
        json.dump(metadata_list, json_file, indent=4)

    # Close the database connection
    conn.close()
    # json_to_text('metadata.json')

def create_dataset(db_file ,json_file, dataset_dir, image_size=256, diff_map=False, aug_params = None, use_background = False, max_augment_factor = 8):

    print(f"diff_map: {diff_map}")
    # Create dataset directories
    train_images_dir = os.path.join(dataset_dir, 'train/images')
    train_labels_dir = os.path.join(dataset_dir, 'train/labels')
    val_images_dir = os.path.join(dataset_dir, 'val/images')
    val_labels_dir = os.path.join(dataset_dir, 'val/labels')
    test_images_dir = os.path.join(dataset_dir, 'test/images')
    test_labels_dir = os.path.join(dataset_dir, 'test/labels')
    
    os.makedirs(train_images_dir, exist_ok=True)
    os.makedirs(train_labels_dir, exist_ok=True)
    os.makedirs(val_images_dir, exist_ok=True)
    os.makedirs(val_labels_dir, exist_ok=True)
    os.makedirs(test_images_dir, exist_ok=True)
    os.makedirs(test_labels_dir, exist_ok=True)

    # Load JSON data
    db_to_metadata(db_file, json_file)
    with open(json_file, 'r') as f:
        data = json.load(f)
    
    # Split data into train and validation sets
    # First, split the data into train+val and test sets
    train_val_data, test_data = train_test_split(data, test_size=0.1, random_state=42)

    # Then, split the train+val data into train and val sets
    train_data, val_data = train_test_split(train_val_data, test_size=0.2222, random_state=42)  # 0.2222 is approximately 2/9

    # Now you have train_data (70%), val_data (20%), and test_data (10%)
    
    def process_data(data, images_dir, labels_dir, data_type):
        for item in tqdm(data, desc=f"Processing {data_type} data"):
            image_path = item['image_path']
            if diff_map:
                max_features = 1000
                max_shift = 10
                ransac_reproj_threshold = 0.20
                image_dir = os.path.dirname(image_path)
                # the lot_id doesn't matter here, it just affects the metadata created below, which won't be used in this case.
                selected_lot_id = "DummyVariable"
                vmin_level = -0.60
                conv_kernel_size = 2
                
                # Extract the filename
                filename = os.path.basename(image_path)
                if 'InstantReviewT' in image_path:
                    image_type = "T"
                elif 'InstantReviewRt' in image_path:
                    image_type = "Rt"

                # Extract the number part of the filename using regular expressions
                image_id = re.search(r'\d+', filename).group()

                ref, test, is_median_ref = load_defect_pair(image_dir, image_id)

                """
                I think there's a bottleneck here. When the image isn't able to be aligned with correlate, the correlation alignment function outputs an error which
                takes a makes the progress bar stuck for a while. This is worth checking out when optimizing the dataset pipeline. 
                """

                # Here we use Correlate for all images because it can handle broader cases than SIFT.
                try:
                    metadata, proc_ref, proc_test, proc_diff, max_pos, min_pos = \
                        get_diff_map(ref, test, image_id, selected_lot_id, is_median_ref, int(max_features), int(max_shift), ransac_reproj_threshold, method="Correlate")
                except:
                    metadata, proc_ref, proc_test, proc_diff, max_pos, min_pos = \
                        get_diff_map(ref, test, image_id, selected_lot_id, is_median_ref, int(max_features), int(max_shift), ransac_reproj_threshold, method="SIFT")                  
                #save proc_diff as png image
                diff_colored = apply_colormap(proc_diff, 'seismic', vmin_level, -vmin_level)
                conv_diff_image = cv2.filter2D(diff_colored, -1, conv_kernel(int(conv_kernel_size)))
                diff_image_png = Image.fromarray(conv_diff_image)

                # Save as PNG
                
                label_file = f"{image_type}_{image_id}_diff.txt"
                label_path = os.path.join(labels_dir, label_file)             
                # remove last filename from image_path

                
                #Start augmentation
                bounding_boxes = item['bounding_box']

                #before augmentation, add original image and label into dataset
                
                if len(bounding_boxes) == 0:
                    if use_background == True:
                        continue
                    with open(label_path, "w") as f:
                        pass
                        
                else:
                    try:
                        aug_bboxes, aug_labels = process_and_augment_images(conv_diff_image, bounding_boxes, aug_params, image_path, original=True)
                    except:
                        continue
                    for box, label in zip(aug_bboxes, aug_labels):
                        with open(label_path, "a") as f:
                            f.write(f"{label} {box[0]} {box[1]} {box[2]} {box[3]}\n")
                diff_image_png.save(os.path.join(images_dir, f"{image_type}_{image_id}_diff.png"))

                num_of_augments = np.random.randint(1, max_augment_factor)
                
                for i in range(1, num_of_augments+1):
                    #random vmin level [-1.70, -0.30]
                    vmin_level = torch.FloatTensor(1).uniform_(-1.70, -0.30).item()
                    diff_colored = apply_colormap(proc_diff, 'seismic', vmin_level, -vmin_level)

                    #apply random convolution kernel
                    conv_kernel_size = torch.randint(1, 4, (1,)).item()
                    conv_diff_image = cv2.filter2D(diff_colored, -1, conv_kernel(int(conv_kernel_size)))

                    #apply albumentation's augmentations.
                    try:
                        aug_image, aug_bboxes, aug_labels = process_and_augment_images(conv_diff_image, bounding_boxes, aug_params, image_path)
                    except:
                        continue
                    png_path = os.path.join(images_dir, f"{image_type}_{image_id}_diff_{str(i)}.png")
                    label_path = os.path.join(labels_dir, f"{image_type}_{image_id}_diff_{str(i)}.txt")

                    np_image = aug_image.permute(1, 2, 0).cpu().numpy()
                    
                    # Convert the NumPy array to a PIL image
                    pil_image = Image.fromarray(np_image)
                    
                    # Save the PIL image
                    pil_image.save(png_path)
                    if len(aug_bboxes) == 0:
                        if use_background == False:
                            continue
                        label = 'None'
                        with open(label_path, 'w') as f:
                            pass
                    else:
                        for bbox, label in zip(aug_bboxes, aug_labels):
                            with open(label_path, 'a') as f:
                                f.write(f"{label} {bbox[0]} {bbox[1]} {bbox[2]} {bbox[3]}\n")
            else:
                # Copy image to the dataset directory
                shutil.copy(image_path, images_dir)
                
                # Create label file
                image_name = os.path.basename(image_path)
                label_file = os.path.splitext(image_name)[0] + '.txt'
                label_path = os.path.join(labels_dir, label_file)

    
    # Process train and validation data


    process_data(train_data, train_images_dir, train_labels_dir, "train")
    process_data(val_data, val_images_dir, val_labels_dir, "val")
    process_data(test_data, test_images_dir, test_labels_dir, "test")


def dataset_checker(dataset_path):
    # Directories to check
    directories = ['train', 'val', 'test']
    
    missing_labels = []
    empty_labels = []

    for directory in directories:
        image_dir = os.path.join(dataset_path, directory, 'images')
        label_dir = os.path.join(dataset_path, directory, 'labels')
        
        # Get list of image files
        image_files = [f for f in os.listdir(image_dir) if f.endswith('.png')]
        
        for image_file in image_files:
            label_file = os.path.splitext(image_file)[0] + '.txt'
            label_path = os.path.join(label_dir, label_file)
            
            if not os.path.exists(label_path):
                print(f"no label at {image_file}")
                missing_labels.append(os.path.join(directory, 'images', image_file))
            else:
                with open(label_path, 'r') as f:
                    content = f.read().strip()
                    if not content:
                        print(f"empty label at {label_file}")
                        empty_labels.append(os.path.join(directory, 'labels', label_file))
    
    # return missing_labels, empty_labels



def main():
    parser = argparse.ArgumentParser(description="Create YOLO dataset from .db file")
    parser.add_argument("--db_file" , type=str, help="Path to the .db file")
    parser.add_argument("--json_metadata", type=str, help="Path to the JSON metadata file")
    parser.add_argument("--dataset_path", type=str, help="Path to the dataset directory")
    parser.add_argument("--use_diff_map", type=bool, default=True, help="Use diff map as image for the dataset")
    parser.add_argument("--max_augment_factor", type=int, default=8, help="Max number of augmentation data on each image")
    parser.add_argument("--use_background", action='store_true', default=False, help="Use background images for the dataset")
    args = parser.parse_args()

    aug_params = {
        'rotation_prob': 0.5,
        'flip_prob': 0.5,
        'scale': (1.0, 1.2),
        'brightness': 0.2,
        'contrast': 0.2
    }
    create_dataset(args.db_file, args.json_metadata, args.dataset_path, diff_map=args.use_diff_map, aug_params=aug_params, use_background=args.use_background, max_augment_factor=args.max_augment_factor)


if __name__ == "__main__":
    main()
    # dataset_checker("/home/hubert007/Code/label_tool/labeling/toggle_labelstudio/model_based/YOLO/datasets/m_layer_aug_fix")



######yolo prelabel training
from prelabel.model_based.YOLO.inference import inference


def YOLO_prelabel(t_np_image, rt_np_image, model_path, annotations):
        t_bbox = inference(t_np_image, model_path)
        if t_bbox != None:
            for box in t_bbox:
                x = box[0]
                y = box[1]
                width = box[2]
                height = box[3]
                label = box[4]
                for i in range(1, 4):
                    annotation = {
                        'from_name': f'label_image{i}',
                        'to_name': f'image{i}',
                        'type': 'rectanglelabels',
                        'value': {
                            'rectanglelabels': ['Defect_right'],
                            'x': x.item()*100/256,
                            'y': y.item()*100/256,
                            'width': width.item()*100/256,
                            'height': height.item()*100/256,
                        }
                    }       
                    annotations.append(annotation)       
        rt_bbox = inference(rt_np_image, model_path)
        if rt_bbox != None:
            for box in rt_bbox:
                x = box[0]
                y = box[1]
                width = box[2]
                height = box[3]
                label = box[4]
                # The main diference is here: it is using a different range for the loop (image 4,5,6)
                for i in range(4, 7):
                    annotation = {
                        'from_name': f'label_image{i}',
                        'to_name': f'image{i}',
                        'type': 'rectanglelabels',
                        'value': {
                            'rectanglelabels': ['Defect_right'],
                            'x': x.item()*100/256,
                            'y': y.item()*100/256,
                            'width': width.item()*100/256,
                            'height': height.item()*100/256,
                        }
                    }       
                    annotations.append(annotation)      
                return annotations


# YOLO prelabeler training


## Prepare dataset
**Run commands under /toggle_labelstudio**

After finishing labeling, you will get .db file under /toggle_labelstudio.
Convert that .db file into YOLO training format by running the following command:
```bash
python -m prelabel.model_based.YOLO.dataset --db_file example.db --json_metadata example.json --dataset_path dataset_path
```
* `db_file`: .db file path.
* `json_metadata`: desired metadata json file path (will create for you).
* `dataset_path`: output dataset directory (will create for you).

## Train model

### run finetune

```bash
python -m prelabel.model_based.YOLO.finetune --epochs 200 --imgsz 256 --exp_name "experiment name" --dataset_path "dataset_path"
```
Other arguments will be added later(TODO)

###################################################prelabel.py

import cv2
import numpy as np
import base64
from PIL import Image
from io import BytesIO
from prelabel.model_based.YOLO.api import YOLO_prelabel
from prelabel.rule_based.minmax.api import minmax_prelabel
from loguru import logger

def base64_to_numpy(base64_str):
    img_data = base64.b64decode(base64_str)
    img = Image.open(BytesIO(img_data))
    return np.array(img)

def extract_annotations(existing_labels):
    """
    This function extracts the bounding boxes from "existing_labels", which is the dictionary that "st_labelstudio" returns after submit.
    It is quite important to study how "existing_labels" is structured if you want to add new annotation types.
    "polygonlabels" is deprecated currently since the database doesn't handle that format, but as long as you 
    understand "existing_labels" format, you can add it back.
    """
    annotations = []
    if 'areas' in existing_labels:
        # areas describe all the bounded areas (bounding box, polygon..)
        for area_id, area_data in existing_labels['areas'].items():
            if 'results' in area_data:
                for result in area_data['results']:
                    annotation = {
                        "id": result["id"],
                        "from_name": result['from_name'],
                        "to_name": result['to_name'],
                        "type": result['type']
                    }
                    if annotation["type"] == "polygonlabels":
                        annotation["value"] = {
                            "polygonlabels": result['value']['polygonlabels'],
                            "points": [[point['relativeX'], point['relativeY']] for point in area_data['points']],
                        }
                    elif annotation["type"] == "rectanglelabels":
                        annotation["value"] = {
                            "rectanglelabels": result['value']['rectanglelabels'],
                            # converting absolute pixel values into percentage
                            "x": area_data['x']*100/256,
                            "y": area_data['y']*100/256,
                            "width": area_data['width']*100/256,
                            "height": area_data['height']*100/256,
                            "rotation": area_data['rotation'],
                        }
                    annotations.append(annotation)
    return annotations

def generate_prelabels(metadatas, crop_size, method="minmax", model_path=None, t_image=None, rt_image=None, label_type="rectangle"):
    """
    Call your prelabel logics here.
    You can call/define any prelabel method as long as the list "annotations" contains 6 elements each with the following format:
    {
        'from_name': f'label_image{i}',
        'to_name': f'image{i}',
        'type': 'rectanglelabels',
        'value': {
            'rectanglelabels': ['Defect_right'],
            'x': x coord of bounding box's TOP LEFT in PERCENTAGE [0, 100],
            'y': y coord of bounding box's TOP LEFT in PERCENTAGE [0, 100],
            'width': bounding box width in PERCENTAGE [0, 100],
            'height': bounding box height in PERCENTAGE [0, 100],
        }
    } 

    Basically you have to return six bounding boxes for i is from 1~6, representing 6 images (t_ref, t_test, t_diff, rt_ref, rt_test, rt_diff).
    Then these annotations will be rendered onto UI.
    """
    
    annotations = []
    if method == "YOLO":
        # why does YOLO only take in 2 images? Because we only predict on the diff map. t_image is the t_diffmap vice versa.
        t_np_image = base64_to_numpy(t_image)
        rt_np_image = base64_to_numpy(rt_image)
        YOLO_prelabel(t_np_image, rt_np_image, model_path, annotations)
   
    elif method == "minmax":
        # metadatas contains the min/max point, which is acquired from SIFT's alignment functions.
        # crop_size is the size of the bounding box to bound the min/max point. It can be toggled on sidebar.
        minmax_prelabel(metadatas, crop_size, annotations)
    return annotations

def task_generator(images, crop_size, metadatas=None, method="minmax", model_path=None, label_type="rectangle", existing_labels=None):
    """
    This is the MAIN function that handles our customize logic and pass it in to labelstudio as "predictions". 
    Be aware that both "existing labels" and "prelabel predictions" are passed in as "predictions".
    I didn't use "completions", you can ignore that, also you can disable its UI in the UI settings (gear icon).
    """
    task = {
        'completions': [],
        'predictions': [],
        'id': 1,
        'data': {
            'image1': f"data:image/jpeg;base64,{images[0]}",
            'image2': f"data:image/jpeg;base64,{images[1]}",
            'image3': f"data:image/jpeg;base64,{images[2]}",
            'image4': f"data:image/jpeg;base64,{images[3]}",
            'image5': f"data:image/jpeg;base64,{images[4]}",
            'image6': f"data:image/jpeg;base64,{images[5]}"
        }
    }
    if existing_labels:
        annotations = extract_annotations(existing_labels)
        task['predictions'].append({
            'model_version': 'existing_labels',
            'result': annotations
        })
    else:
        print("no labels found, generating prelabels...")
        annotations = generate_prelabels(metadatas, crop_size, method=method, model_path=model_path, t_image=images[2], rt_image=images[5], label_type=label_type)
        task['predictions'].append({
            'model_version': 'prelabeling',
            'result': annotations
        })

    return task


######export_json_and_mask

import sqlite3
import json
from PIL import Image, ImageDraw
import os
from tqdm import tqdm
import argparse

def check_image_variants(image_path):
    # Get the base path and file name without extension
    base_path, file_name = os.path.split(image_path)
    file_name_no_ext = os.path.splitext(file_name)[0]
    
    # Define the variants
    variants = ['L', 'R', 'U', 'D']
    
    # Initialize a dictionary to store the paths of existing variants
    # Check for each variant
    for variant in variants:
        variant_path = os.path.join(base_path, f"{file_name_no_ext}{variant}.png")
        if os.path.exists(variant_path):
            return variant_path
    
def process_db_and_create_masked_images(db_file, output_dir):
    # Connect to SQLite database
    conn = sqlite3.connect(db_file)
    cursor = conn.cursor()

    # Query to retrieve all rows from the results_table
    cursor.execute('SELECT image_path, results_json FROM results_table')
    rows = cursor.fetchall()

    # Create output directory if it doesn't exist
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    # Initialize a list to store metadata
    metadata_list = []
    for row in tqdm(rows, desc=f"Processing images"):
        img_info, results_json = row
        dataset_dir, lot_id, image_id = img_info.replace(" ","").split(',')
        results = json.loads(results_json)
        img_path = os.path.join(dataset_dir, f"{lot_id}/{lot_id}/Images")
        # Check if 'areas' key exists in the JSON
        if 'areas' in results:
            areas = results['areas']
            for area_key, area_value in areas.items():
                if area_value['object'] == 'image3' or area_value['object'] == 'image6':
                    if area_value['object'] == 'image3':
                        full_img_path = os.path.join(img_path, f"InstantReviewT/{image_id}.png")
                    else:
                        full_img_path = os.path.join(img_path, f"InstantReviewRt/{image_id}.png")
                    """
                    If it comes from the right, the defect image is "fn_id.png", if left, it would be "fn_idL.png" or "fn_idU.png" ... etc.
                    """
                    if area_value['results'][0]['value']['rectanglelabels'][0] == "Defect_left":
                        full_img_path = check_image_variants(full_img_path)
                    x = area_value['x']
                    y = area_value['y']
                    width = area_value['width']
                    height = area_value['height']

                    # Open the image
                    img = Image.open(full_img_path).convert("RGBA")
                    masked_img = Image.new("RGBA", img.size, (0, 0, 0, 255))
                    draw = ImageDraw.Draw(masked_img)

                    # Draw the bounding box on the masked image (make it transparent)
                    draw.rectangle([x, y, x + width, y + height], fill=(0, 0, 0, 0))

                    # Composite the original image with the masked image
                    final_img = Image.alpha_composite(img, masked_img)

                    # Save the final masked image
                    output_path = os.path.join(output_dir, f"{lot_id}_{os.path.basename(full_img_path)}")
                    final_img.save(output_path)
                    
                    # Append metadata to the list
                    metadata_list.append({
                        "image_path": full_img_path,
                        "bounding_box": {
                            "x": x,
                            "y": y,
                            "width": width,
                            "height": height
                        }
                    })

    # Write metadata to a JSON file
    with open(os.path.join(output_dir, 'metadata.json'), 'w') as json_file:
        json.dump(metadata_list, json_file, indent=4)

    # Close the database connection
    conn.close()

def main():
    parser = argparse.ArgumentParser(description="Process a SQLite database and create masked images.")
    parser.add_argument('--db_path', type=str, help='Path to the SQLite database file')
    parser.add_argument('--output_dir', type=str, help='Output directory for the masked images')
    args = parser.parse_args()
    process_db_and_create_masked_images(args.db_path, args.output_dir)


if __name__ == "__main__":
    main()



########################################metadata.json
[
    {
        "image_path": "/mnt/fs0/x9u_detection_result/N3_M0-16_20240920_145106/N3_M0-16_20240920_145106/Images/InstantReviewT/771L.png",
        "bounding_box": {
            "x": 137,
            "y": 111,
            "width": 54,
            "height": 23
        }
    },
    {
        "image_path": "/mnt/fs0/x9u_detection_result/N3_M0-16_20240920_145106/N3_M0-16_20240920_145106/Images/InstantReviewT/822L.png",
        "bounding_box": {
            "x": 124,
            "y": 118,
            "width": 12,
            "height": 15
        }
    },]
#################################alightment.py

"""
This file is modified from inspection_sift.py by Carl.
I've removed some functions since the app doesn't use it. 
The most important functions are "load_defect_pair" and "get_diff_map"
"""




import numpy as np
import cv2
import matplotlib.pyplot as plt
import math
import json
import glob
import os
from loguru import logger
from alignment.SIFT.sift import align_images_sift
from alignment.correlation.correlation import align_images_corr



def normalize_images(ref, test):
    """Normalize images using OpenCV functions."""
    # Convert to float32 for processing
    ref_f = ref.astype(np.float32)
    test_f = test.astype(np.float32)

    # Apply CLAHE (Contrast Limited Adaptive Histogram Equalization)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
    ref_eq = clahe.apply((ref_f * 255).astype(np.uint8)) / 255.0
    test_eq = clahe.apply((test_f * 255).astype(np.uint8)) / 255.0

    # Normalize to zero mean and unit variance
    ref_norm = cv2.normalize(ref_eq, None, 0, 1, cv2.NORM_MINMAX)
    test_norm = cv2.normalize(test_eq, None, 0, 1, cv2.NORM_MINMAX)

    return ref_norm, test_norm

def load_defect_pair(img_path, defect_no):
    """
    This function finds the test and reference image from the dataset directory. (currently from "/mnt/fs0/dataset/Layer_M")
    It handles the suffixes(L, U, Up, Lp ...)
    """
    test = None
    ref_U = None
    ref_L = None
    ref_Up = None
    ref_Lp = None

    images = glob.glob(f'{img_path}/{str(defect_no)}*')
    for image in images:
        if image == f'{img_path}/{str(defect_no)}.png':
            test = image
        elif image == f'{img_path}/{str(defect_no)}U.png':
            ref_U = image
        elif image == f'{img_path}/{str(defect_no)}L.png':
            ref_L = image
        elif image == f'{img_path}/{str(defect_no)}L_p.png':
            ref_Lp = image
        elif image == f'{img_path}/{str(defect_no)}U_p.png':
            ref_Up = image

    if test is None:
        raise ValueError(f'{defect_no}: No Test Image')

    test = cv2.imread(test, cv2.IMREAD_GRAYSCALE)/255

    # Create list to store all available images for median filtering
    all_images = [test]

    ref_u_img = None
    ref_l_img = None
    ref_up_img = None
    ref_lp_img = None
    if ref_U is not None:
        ref_u_img = cv2.imread(ref_U, cv2.IMREAD_GRAYSCALE)/255
        all_images.append(ref_u_img)

    if ref_L is not None:
        ref_l_img = cv2.imread(ref_L, cv2.IMREAD_GRAYSCALE)/255
        all_images.append(ref_l_img)

    if ref_Up is not None:
        ref_up_img = cv2.imread(ref_Up, cv2.IMREAD_GRAYSCALE)/255
        all_images.append(ref_up_img)

    if ref_Lp is not None:
        ref_lp_img = cv2.imread(ref_Lp, cv2.IMREAD_GRAYSCALE)/255
        all_images.append(ref_lp_img)

    # Only use median if we have more than 3 images, otherwise use ref_U as reference
    if len(all_images) > 3:
        reference = np.median(np.stack(all_images), axis=0)
        is_median_ref = True
    else:
        is_median_ref = False
        if ref_u_img is not None:
            reference = ref_u_img
        elif ref_l_img is not None:
            reference = ref_l_img
        elif ref_lp_img is not None:
            reference = ref_lp_img
        elif ref_up_img is not None:
            reference = ref_up_img
        else:
            raise ValueError(f'{defect_no}: No reference image available')

    return reference, test, is_median_ref

def get_diff_map(ref, test, defect_no, lot_id, is_median_ref, max_features=1000, max_shift=10, ransacReprojThreshold=0.0, method="SIFT"):
    """
    input:
    ref : numpy.ndarray, shape(256, 256), grayscale [0,1]
    test : numpy.ndarray, shape(256, 256), grayscale [0,1]

    This function gets you the difference map and its metadata
    You can add your own alignment methods here. As long as you return the following:
    1.aligned_ref : numpy.ndarray, shape(256, 256), grayscale [0,1]
    2.aligned_test : numpy.ndarray, shape(256, 256), grayscale [0,1]
    3.translation : [translation_x, translation_y]  negative means left/up, positive means right/down
    """
    assert(ref.shape == test.shape)

    # logger.debug(f"ref type:{type(ref)}")
    # logger.debug(f"ref shape:{ref.shape}")
    # logger.debug(f"ref:{ref}")
    # logger.debug(f"test type:{type(test)}")
    # logger.debug(f"test shape:{test.shape}")
    # logger.debug(F"test:{test}")
    # Align images using SIFT
    if method == "SIFT":
        if ransacReprojThreshold > 0.0:
            #use RANSAC to filter feature point outliers
            aligned_ref, aligned_test, translation = align_images_sift(ref, test, max_features=max_features, max_shift=max_shift, RANSAC=True, ransacReprojThreshold=ransacReprojThreshold)
        else:
            aligned_ref, aligned_test, translation = align_images_sift(ref, test, max_features=max_features, max_shift=max_shift, RANSAC=False)

        # Convert translation to regular Python float
        translation = [float(translation[0]), float(translation[1])]

    elif method == "Correlate":
        aligned_ref, aligned_test, translation = align_images_corr(ref, test)


    # Normalize images
    processed_ref, processed_test = normalize_images(aligned_ref, aligned_test)
    processed_diff = processed_ref - processed_test
    # Calculate RMSE and max absolute difference
    rmse = float(np.sqrt(np.mean((processed_ref - processed_test) ** 2)))
    max_diff = float(max(abs(np.max(processed_diff)), abs(np.min(processed_diff))))

    def get_ceiling_floor(translation):
        if translation < 0:
            return -max_shift-2+int(math.floor(translation))
        else:
            return max_shift+2+int(math.ceil(translation))
    int_translation = [get_ceiling_floor(t) for t in translation]
    # Define the region of interest excluding the translation area
    roi_start = [max(0, int_translation[0], -int_translation[0]), max(0, int_translation[1], -int_translation[1])]
    roi_end = [min(processed_diff.shape[0], processed_diff.shape[0] + int_translation[0], processed_diff.shape[0] - int_translation[0]),
            min(processed_diff.shape[1], processed_diff.shape[1] + int_translation[1], processed_diff.shape[1] - int_translation[1])]

    # Extract the region of interest

    roi_diff = processed_diff[roi_start[0]:roi_end[0], roi_start[1]:roi_end[1]]

    # Find max/min positions within the region of interest
    max_pos = [int(x) for x in np.unravel_index(roi_diff.argmax(), roi_diff.shape)]
    min_pos = [int(x) for x in np.unravel_index(roi_diff.argmin(), roi_diff.shape)]
    # x,y coord will be swapped because of the way numpy unravels indices
    max_pos = [max_pos[1], max_pos[0]]
    min_pos = [min_pos[1], min_pos[0]]
    # Adjust positions to the original image coordinates
    max_pos = [max_pos[0] + roi_start[0], max_pos[1] + roi_start[1]]
    min_pos = [min_pos[0] + roi_start[0], min_pos[1] + roi_start[1]]

    # Create metadata dictionary with Python native types
    metadata = {
        'lot_id': lot_id,
        'defect_no': int(defect_no),
        'translation': translation,
        'max_difference': float(np.max(processed_diff)),
        'min_difference': float(np.min(processed_diff)),
        'abs_max_difference': max_diff,
        'rmse': rmse,
        'max_pos': max_pos,
        'min_pos': min_pos,
        'is_median_ref': is_median_ref  # Include the median reference flag
    }

    return metadata, processed_ref, processed_test, processed_diff, max_pos, min_pos




#####backend###########################################combine_db.py

import sqlite3
import json

def save_json_to_sqlite(img_path, results_raw, db_path):
    json_string = json.dumps(results_raw)
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    cursor.execute('SELECT results_json FROM results_table WHERE image_path = ?', (img_path,))
    existing_entry = cursor.fetchone()
    if existing_entry:
        existing_json_string = existing_entry[0]
        if existing_json_string == json_string:
            print("Same img_path and same results_raw. No update needed.")
        else:
            cursor.execute('UPDATE results_table SET results_json = ? WHERE image_path = ?', (json_string, img_path))
            print("Same img_path but different results_raw. Updated the entry.")
    else:
        cursor.execute('INSERT INTO results_table (image_path, results_json) VALUES (?, ?)', (img_path, json_string))
        print("New img_path. Inserted a new entry.")
    conn.commit()
    conn.close()
    print("Connection closed")

def fetch_results(image_path, db_path):
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    cursor.execute('SELECT results_json FROM results_table WHERE image_path = ?', (image_path,))
    result = cursor.fetchone()
    conn.close()
    if result:
        return json.loads(result[0])
    return None

def combine_databases(db1_path, db2_path, combined_db_path):
    conn1 = sqlite3.connect(db1_path)
    conn2 = sqlite3.connect(db2_path)
    cursor1 = conn1.cursor()
    cursor2 = conn2.cursor()
    combined_conn = sqlite3.connect(combined_db_path)
    combined_cursor = combined_conn.cursor()
    combined_cursor.execute('''
        CREATE TABLE IF NOT EXISTS results_table (
            image_path TEXT PRIMARY KEY,
            results_json TEXT
        )
    ''')
    cursor1.execute('SELECT image_path, results_json FROM results_table')
    entries1 = cursor1.fetchall()
    cursor2.execute('SELECT image_path, results_json FROM results_table')
    entries2 = cursor2.fetchall()
    combined_entries = {}
    for img_path, results_json in entries1:
        combined_entries[img_path] = results_json
    for img_path, results_json in entries2:
        if img_path not in combined_entries:
            combined_entries[img_path] = results_json
    for img_path, results_json in combined_entries.items():
        combined_cursor.execute('INSERT INTO results_table (image_path, results_json) VALUES (?, ?)', (img_path, results_json))
    combined_conn.commit()
    conn1.close()
    conn2.close()
    combined_conn.close()

# Example usage
db1_path = '/home/hubert007/Code/label_tool/labeling/toggle_labelstudio/new_m_layer.db'
db2_path = '/home/hubert007/Code/label_tool/labeling/toggle_labelstudio/combined_YOLO.db'
combined_db_path = '/home/hubert007/Code/label_tool/labeling/toggle_labelstudio/megamind.db'

combine_databases(db1_path, db2_path, combined_db_path)

print(f"Combined database created at {combined_db_path}")



########dbview.py
import sqlite3
import pandas as pd

# Connect to the database
conn = sqlite3.connect('backend/db_files/the_regional_dataset.db')

# Read the data into a DataFrame
df = pd.read_sql_query("SELECT image_path, results_json FROM results_table", conn)

# Adjust display settings
pd.set_option('display.max_colwidth', 80)
# Display the DataFrame
print(df)


############sqlite_functions.py
import json
import sqlite3


def save_json_to_sqlite(img_path, results_raw, db_path):
    # Convert results_raw to JSON string
    json_string = json.dumps(results_raw)

    # Connect to SQLite database
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()

    # Check if an entry with the same img_path already exists
    cursor.execute('SELECT results_json FROM results_table WHERE image_path = ?', (img_path,))
    existing_entry = cursor.fetchone()

    if existing_entry:
        # Compare existing results_raw with the new one
        existing_json_string = existing_entry[0]
        if existing_json_string == json_string:
            print("Same img_path and same results_raw. No update needed.")
        else:
            # Update the existing entry with the new results_raw
            cursor.execute('UPDATE results_table SET results_json = ? WHERE image_path = ?', (json_string, img_path))
            print("Same img_path but different results_raw. Updated the entry.")
    else:
        # Insert a new entry
        cursor.execute('INSERT INTO results_table (image_path, results_json) VALUES (?, ?)', (img_path, json_string))
        print("New img_path. Inserted a new entry.")

    # Commit changes and close the connection
    conn.commit()
    conn.close()
    print("Connection closed")


def fetch_results(image_path, db_path):
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    cursor.execute('SELECT results_json FROM results_table WHERE image_path = ?', (image_path,))
    result = cursor.fetchone()
    conn.close()
    if result:
        return json.loads(result[0])
    return None


def round_to_closest_integer(db_file):
    # Connect to SQLite database
    conn = sqlite3.connect(db_file)
    cursor = conn.cursor()

    # Query to retrieve all rows from the results_table
    cursor.execute('SELECT image_path, results_json FROM results_table')
    rows = cursor.fetchall()

    # Iterate over each row
    for row in rows:
        img_path, results_json = row
        results = json.loads(results_json)

        # Check if 'areas' key exists in the JSON
        if 'areas' in results:
            areas = results['areas']
            for area_key, area_value in areas.items():
                if area_value['object'] == 'image3':
                    # Round x, y, width, and height to the closest integer
                    area_value['x'] = round(area_value['x'])
                    area_value['y'] = round(area_value['y'])
                    area_value['width'] = round(area_value['width'])
                    area_value['height'] = round(area_value['height'])

        # Update the row with the modified JSON
        cursor.execute('UPDATE results_table SET results_json = ? WHERE image_path = ?', (json.dumps(results), img_path))

    # Commit the changes and close the database connection
    conn.commit()
    conn.close()

if __name__ == "__main__":
    db_file = "/home/hubert007/Code/label_tool/labeling/toggle_labelstudio/example.db"
    round_to_closest_integer(db_file)




#####frontend####################### image process.py
from PIL import Image
import base64
from io import BytesIO
import numpy as np
import json
import cv2
from alignment.alignment import load_defect_pair, get_diff_map
import matplotlib.pyplot as plt
# Function to convert a NumPy array to a Base64 encoded string

def numpy_to_base64(img_array):
    pil_img = Image.fromarray(img_array)
    buffer = BytesIO()
    pil_img.save(buffer, format="JPEG")
    return base64.b64encode(buffer.getvalue()).decode("utf-8")


# Function to load images from a JSON file line by line and save into a dictionary
def load_images_from_json(json_file):
    images = {}
    with open(json_file, 'r') as f:
        for line in f:
            data = json.loads(line)
            lot_id = data['lot_id']
            images[lot_id] = data
    return images

def apply_colormap(np_array, colormap, vmin=None, vmax=None):
    # norm_array = (np_array - np_array.min()) / (np_array.max() - np_array.min())
    if vmin and vmax:
        norm_array = (np_array - vmin) / (vmax - vmin)
    else:
        norm_array = np_array
    colormap_func = plt.get_cmap(colormap)
    colored_array = colormap_func(norm_array)
    return (colored_array[:, :, :3] * 255).astype(np.uint8)

# Define a 2x2 convolution kernel
def conv_kernel(kernel_size):
    return np.ones((kernel_size, kernel_size), dtype=np.float32) / (kernel_size ** 2)

def get_image_pair_for_studio_input(data_dir, selected_lot_id, selected_image_id, selected_image_type, vmin_level, max_features, max_shift, ransac_reproj_threshold, selected_alignment_method, conv_kernel_size):
    img_dir = f"{data_dir}/{selected_lot_id}/{selected_lot_id}/Images/InstantReview{selected_image_type}"
    fn_id = selected_image_id
    ref, test, is_median_ref = load_defect_pair(img_dir, fn_id)
    metadata, proc_ref, proc_test, proc_diff, max_pos, min_pos = \
        get_diff_map(ref, test, fn_id, selected_lot_id, is_median_ref, int(max_features), int(max_shift), ransac_reproj_threshold, method=selected_alignment_method)
    print(f"max_pos:{metadata['max_pos']}")
    print(f"min_pos:{metadata['min_pos']}")

    ref_colored = apply_colormap(proc_ref, 'gray')
    test_colored = apply_colormap(proc_test, 'gray')
    diff_colored = apply_colormap(proc_diff, 'seismic', vmin_level, -vmin_level)
    conv_diff_image = cv2.filter2D(diff_colored, -1, conv_kernel(int(conv_kernel_size)))
    img1_base64 = numpy_to_base64(ref_colored)
    img2_base64 = numpy_to_base64(test_colored)
    img3_base64 = numpy_to_base64(diff_colored)
    img4_base64 = numpy_to_base64(conv_diff_image)
    return [img1_base64, img2_base64, img4_base64], metadata




#########json_functions.py
import json
import copy

def save_results_to_json(results_raw):
    with open('results.json', 'w') as f:
        json.dump(results_raw, f, indent=4)

def sync_labels_across_3images(results_raw):
    """
    Syncs labels across three images by replicating 'image3' entries to 'image1' and 'image2'.

    Args:
        results_raw (dict): Dictionary containing areas information.

    Returns:
        dict: Updated dictionary with synchronized labels.
    """

    # Filter image3 entries
    image3_entries = [area for area in results_raw['areas'].values() if area['object'] == 'image3']

    # Create new list of areas with only the replicated image3 entries as image1, image2 and image3
    areas_list = []
    

    for entry in image3_entries:
        # Create image3 copy
        image3_copy = copy.deepcopy(entry)
        # image3_copy['results'][0]['value']['rectangles'][0] = image3_copy['results']['width']*image3_copy['results']['height']
        areas_list.append(image3_copy)

        # Create image2 copy
        image2_copy = copy.deepcopy(entry)
        image2_copy['object'] = 'image2'
        image2_copy['results'][0]['from_name'] = 'label_image2'
        image2_copy['results'][0]['to_name'] = 'image2'
        image2_copy['results'][0]['id'] = f"image2{entry['results'][0]['id']}"
        areas_list.append(image2_copy)

        # Create image1 copy
        image1_copy = copy.deepcopy(entry)
        image1_copy['object'] = 'image1'
        image1_copy['results'][0]['from_name'] = 'label_image1'
        image1_copy['results'][0]['to_name'] = 'image1'
        image1_copy['results'][0]['id'] = f"image1{entry['results'][0]['id']}"
        areas_list.append(image1_copy)


    # Filter image3 entries
    image6_entries = [area for area in results_raw['areas'].values() if area['object'] == 'image6']


    

    for entry in image6_entries:
        # Create image3 copy
        image6_copy = copy.deepcopy(entry)
        # image3_copy['results'][0]['value']['rectangles'][0] = image3_copy['results']['width']*image3_copy['results']['height']
        areas_list.append(image6_copy)

        # Create image5 copy
        image5_copy = copy.deepcopy(entry)
        image5_copy['object'] = 'image5'
        image5_copy['results'][0]['from_name'] = 'label_image5'
        image5_copy['results'][0]['to_name'] = 'image5'
        image5_copy['results'][0]['id'] = f"image5{entry['results'][0]['id']}"
        areas_list.append(image5_copy)

        # Create image4 copy
        image4_copy = copy.deepcopy(entry)
        image4_copy['object'] = 'image4'
        image4_copy['results'][0]['from_name'] = 'label_image4'
        image4_copy['results'][0]['to_name'] = 'image4'
        image4_copy['results'][0]['id'] = f"image4{entry['results'][0]['id']}"
        areas_list.append(image4_copy)

    # Update results_raw dictionary
    results_raw['areas'] = dict(enumerate(areas_list))

    return results_raw

def get_area_size(results_raw):
    image3_entries = [area for area in results_raw['areas'].values() if area['object'] == 'image3']
    size_list = []
    for entry in image3_entries:
        size_list.append(float(entry['width'])*float(entry['height'])*10000/(256**2))
    return size_list



#########label_config.py
# poly_rec_config = """
# <View>
#   <Header value="Select label and click the image to start"/>
#   <View>
#     <View style="display: flex;">
#       <View style="width: 33%; margin-right: 1%;">
#         <Image name="image1" value="$image1"/>
#         <PolygonLabels name="label1_image1" toName="image1">
#           <Label value="Poly_Defect" background="green"/>
#         </PolygonLabels>
#         <RectangleLabels name="label2_image1" toName="image1">
#           <Label value="Rec_Defect" background="blue"/>
#         </RectangleLabels>
#       </View>
#       <View style="width: 33%; margin-right: 1%;">
#         <Image name="image2" value="$image2"/>
#         <PolygonLabels name="label1_image2" toName="image2">
#           <Label value="Poly_Defect" background="green"/>
#         </PolygonLabels>
#         <RectangleLabels name="label2_image2" toName="image2">
#           <Label value="Rec_Defect" background="blue"/>
#         </RectangleLabels>
#       </View>
#       <View style="width: 33%;">
#         <Image name="image3" value="$image3"/>
#         <PolygonLabels name="label1_image3" toName="image3">
#           <Label value="Poly_Defect" background="green"/>
#         </PolygonLabels>
#         <RectangleLabels name="label2_image3" toName="image3">
#           <Label value="Rec_Defect" background="blue"/>
#         </RectangleLabels>
#       </View>
#     </View>
#   </View>

# </View>
# """

config = """
<View>
  <Header value="Select label and click the image to start"/>
  <View>
    <View style="display: flex;">
      <View style="width: 33%; margin-right: 1%;">
        <Image name="image1" value="$image1" brightnessControl="true" contrastControl="true" zoomControl="true"/>
        <RectangleLabels name="label_image1" toName="image1">
          <Label value="Defect_left" background="blue"/>
          <Label value="Defect_right" background="red"/>
          <Label value="4D" background="green"/>
        </RectangleLabels>
      </View>
      <View style="width: 33%; margin-right: 1%;">
        <Image name="image2" value="$image2" brightnessControl="true" contrastControl="true" zoomControl="true"/>
        <RectangleLabels name="label_image2" toName="image2">
          <Label value="Defect_left" background="blue"/>
          <Label value="Defect_right" background="red"/>
          <Label value="4D" background="green"/>
        </RectangleLabels>
      </View>
      <View style="width: 33%;">
        <Image name="image3" value="$image3" brightnessControl="true" contrastControl="true" zoomControl="true"/>
        <RectangleLabels name="label_image3" toName="image3">
          <Label value="Defect_left" background="blue"/>
          <Label value="Defect_right" background="red"/>
          <Label value="4D" background="green"/>
        </RectangleLabels>
      </View>
    </View>
  </View>

</View>
"""


two_row_config="""
<View>
  <Header value="Select label and click the image to start"/>
  <View>
    <Header value="Category: T"/>
    <View style="display: flex;">
      <View style="width: 33%; margin-right: 1%;">
        <Image name="image1" value="$image1" brightnessControl="true" contrastControl="true" zoomControl="true"/>
        <RectangleLabels name="label_image1" toName="image1">
          <Label value="Defect_left" background="blue"/>
          <Label value="Defect_right" background="red"/>
          <Label value="4D" background="green"/>
        </RectangleLabels>
      </View>
      <View style="width: 33%; margin-right: 1%;">
        <Image name="image2" value="$image2" brightnessControl="true" contrastControl="true" zoomControl="true"/>
        <RectangleLabels name="label_image2" toName="image2">
          <Label value="Defect_left" background="blue"/>
          <Label value="Defect_right" background="red"/>
          <Label value="4D" background="green"/>
        </RectangleLabels>
      </View>
      <View style="width: 33%;">
        <Image name="image3" value="$image3" brightnessControl="true" contrastControl="true" zoomControl="true"/>
        <RectangleLabels name="label_image3" toName="image3">
          <Label value="Defect_left" background="blue"/>
          <Label value="Defect_right" background="red"/>
          <Label value="4D" background="green"/>
        </RectangleLabels>
      </View>
    </View>
    <Header value="Category: Rt"/>
    <View style="display: flex; margin-top: 1%;">
      <View style="width: 33%; margin-right: 1%;">
        <Image name="image4" value="$image4" brightnessControl="true" contrastControl="true" zoomControl="true"/>
        <RectangleLabels name="label_image4" toName="image4">
          <Label value="Defect_left" background="blue"/>
          <Label value="Defect_right" background="red"/>
          <Label value="4D" background="green"/>
        </RectangleLabels>
      </View>
      <View style="width: 33%; margin-right: 1%;">
        <Image name="image5" value="$image5" brightnessControl="true" contrastControl="true" zoomControl="true"/>
        <RectangleLabels name="label_image5" toName="image5">
          <Label value="Defect_left" background="blue"/>
          <Label value="Defect_right" background="red"/>
          <Label value="4D" background="green"/>
        </RectangleLabels>
      </View>
      <View style="width: 33%;">
        <Image name="image6" value="$image6" brightnessControl="true" contrastControl="true" zoomControl="true"/>
        <RectangleLabels name="label_image6" toName="image6">
          <Label value="Defect_left" background="blue"/>
          <Label value="Defect_right" background="red"/>
          <Label value="4D" background="green"/>
        </RectangleLabels>
      </View>
    </View>
  </View>
</View>
"""


interfaces = [
  "panel",
  "update",
  "controls",
  "side-column",
  "completions:menu",
  "completions:add-new",
  "completions:delete",
  "predictions:menu",
],

user = {
  'pk': 1,
  'firstName': "Labeler",
  'lastName': "",
},

######app.py
import streamlit as st
from streamlit_labelstudio import st_labelstudio
import cv2
from alignment.alignment import load_defect_pair, get_diff_map
from frontend.image_processor import numpy_to_base64, load_images_from_json, get_image_pair_for_studio_input, apply_colormap, conv_kernel
from frontend.label_config import config, interfaces, user, two_row_config
from prelabel.prelabel import task_generator
from frontend.read_lrf import get_defect_list, get_lrf_file
from backend.sqlite_functions import save_json_to_sqlite, fetch_results
from frontend.json_functions import save_results_to_json, sync_labels_across_3images, get_area_size
import sqlite3
import os
import traceback
import argparse
from loguru import logger

# modify the .db filename if you want a fresh start (will create file for you)
db_path = "backend/db_files/the_regional_dataset.db"
# pass in trained model checkpoint (currently only supports YOLO)
model_path = "/home/hubert007/Code/label_tool/labeling/runs/detect/megamind_nojit_vmin_fix/weights/best.pt"

st.set_page_config(layout='wide')

# Initialize session state for results_raw and image index
if 'previous_results_raw' not in st.session_state:
    st.session_state.previous_results_raw = None
if 'image_index' not in st.session_state:
    st.session_state.image_index = 0
if 'lot_index' not in st.session_state:
    st.session_state.lot_index = 0

# Function to check if results_raw has changed
def has_results_raw_changed(current_results_raw):
    previous_results_raw = st.session_state.previous_results_raw
    if previous_results_raw != current_results_raw:
        st.session_state.previous_results_raw = current_results_raw
        return True
    return False


conn = sqlite3.connect(db_path)
cursor = conn.cursor()
cursor.execute('''
CREATE TABLE IF NOT EXISTS results_table (
    id INTEGER PRIMARY KEY,
    image_path TEXT,
    results_json TEXT
)
''')
conn.commit()
conn.close()


# Sidebar for directory-like structure
st.sidebar.title('Image Directory')

data_dir = "/mnt/fs0/dataset/Layer_M"  
items = os.listdir(data_dir)

# Filter out only directories
lot_ids = [item for item in items if os.path.isdir(os.path.join(data_dir, item)) and item != 'log']
lot_ids.sort()
try:
    selected_lot_id = st.sidebar.selectbox('Select Lot ID', lot_ids, index=st.session_state.lot_index)
except:
    selected_lot_id = st.sidebar.selectbox('Select Lot ID', lot_ids, index=0)
# selected_image_type = st.sidebar.selectbox('Select Image Type', ["T", "Rt"], index=0)

lrf_file = get_lrf_file(data_dir, selected_lot_id)


# logger.debug(f"lrf_file: {lrf_file}")
defect_images_id_list, defect_type = get_defect_list(lrf_file)



# Skip to the next image_id when the button is clicked
if st.sidebar.button('Previous Image'):
    st.session_state.image_index -= 1
    if st.session_state.image_index < 0:
        st.session_state.lot_index = (st.session_state.lot_index - 1) % len(lot_ids)
        selected_lot_id = lot_ids[st.session_state.lot_index]
        lrf_file = get_lrf_file(data_dir, selected_lot_id)
        defect_images_id_list, defect_type = get_defect_list(lrf_file)
        st.session_state.image_index = len(defect_images_id_list) - 1

# Go to the previous image_id when the button is clicked
if st.sidebar.button('Next Image'):
    st.session_state.image_index += 1
    if st.session_state.image_index >= len(defect_images_id_list):
        st.session_state.image_index = 0
        st.session_state.lot_index = (st.session_state.lot_index + 1) % len(lot_ids)
        selected_lot_id = lot_ids[st.session_state.lot_index]
        lrf_file = get_lrf_file(data_dir, selected_lot_id)
        defect_images_id_list, defect_type = get_defect_list(lrf_file)

# logger.debug(f"image_id_list:{defect_images_id_list}")
try:
    selected_image_id = st.sidebar.selectbox('Select Image ID', defect_images_id_list, index=st.session_state.image_index)
except:
    selected_image_id = '1'
# try:
st.session_state.image_index = defect_images_id_list.index(selected_image_id)
# except:
#     st.session_state.image_index = 1
st.write(f"defect type : {defect_type[st.session_state.image_index]}")

prelabel_methods = ['minmax', 'YOLO']
selected_prelabel_method = st.sidebar.selectbox('Select prelabel method', prelabel_methods, index=0)

alignment_methods = ['SIFT', 'Correlate']
selected_alignment_method = st.sidebar.selectbox('Select alignment method', alignment_methods, index=0)

# Slider for saturation adjustment
vmin_level = st.sidebar.slider('vmin_level', -2.0, 0.0, -0.5)
max_features = st.sidebar.slider('max_features', 20.0, 1000.0, 1000.0, 20.0)
max_shift = st.sidebar.slider('max_shift', 0.0, 20.0, 10.0)
ransac_reproj_threshold = st.sidebar.slider('ransac_reproj_threshold', 0.0, 0.3, 0.10, 0.01)
crop_size = st.sidebar.slider('crop_size', 1.0, 30.0, 15.0, 1.0)
conv_kernel_size = st.sidebar.slider('conv_kernel_size', 1.0, 10.0, 2.0, 1.0)


T_images, T_metadata = get_image_pair_for_studio_input(data_dir, selected_lot_id, selected_image_id, "T", vmin_level, max_features, max_shift, ransac_reproj_threshold, selected_alignment_method, conv_kernel_size)
Rt_images, Rt_metadata = get_image_pair_for_studio_input(data_dir, selected_lot_id, selected_image_id, "Rt", vmin_level, max_features, max_shift, ransac_reproj_threshold, selected_alignment_method, conv_kernel_size)

images_base64 = [T_images[0], T_images[1], T_images[2], Rt_images[0], Rt_images[1], Rt_images[2]]
metadatas = [T_metadata, Rt_metadata]

config = two_row_config

img_path = f"{data_dir}, {selected_lot_id}, {selected_image_id}"
existing_labels = fetch_results(img_path, db_path)
if not existing_labels:
    results_raw = st_labelstudio(config, interfaces, user, task_generator(images_base64, crop_size, metadatas=metadatas, method=selected_prelabel_method, model_path=model_path))
else:
    print("Labels already exist. Using existing Labels.")
    st.write("Using existing labels.")
    results_raw = st_labelstudio(config, interfaces, user, task_generator(images_base64, crop_size, method=selected_prelabel_method, existing_labels=existing_labels))
if results_raw is not None and has_results_raw_changed(results_raw):
    results_raw = sync_labels_across_3images(results_raw)
    # save_results_to_json(results_raw)
    # st.write(f"label areas:{get_area_size(results_raw)}")
    save_json_to_sqlite(img_path, results_raw, db_path)
    st.session_state.image_index += 1
    if st.session_state.image_index >= len(defect_images_id_list):
        st.session_state.image_index = 0
        st.session_state.lot_index = (st.session_state.lot_index + 1) % len(lot_ids)
        selected_lot_id = lot_ids[st.session_state.lot_index]
        lrf_file = get_lrf_file(data_dir, selected_lot_id)
        defect_images_id_list, defect_type = get_defect_list(lrf_file)    
    st.rerun()






####YOLO prelabeler training

Prepare dataset
Run commands under /toggle_labelstudio
After finishing labeling, you will get .db file under /toggle_labelstudio.
Convert that .db file into YOLO training format by running the following command:

python -m model_based.YOLO.dataset --db_file example.db --json_metadata example.json --dataset_path dataset_path --use_diff_map

Train model

run finetune

python -m model_based.YOLO.finetune --epochs 200 --imgsz 256 --exp_name "experiment name" --dataset_path "dataset_path"
Other arguments will be added later(TODO)




######Toggle Label Studio

Quickstart

install dependencies

python -m venv venv
source venv/bin/activate
pip install -r requirements.txt

run the script

streamlit run app.py
This will load the False Negatives images classified by FF (just for demo).

You can toggle around visualization paramters on the left.
Click on Predictions to see the rule-based predictions(using min/max diff on diff map).
Edit these predictions if necessary by clicking again on Predictions.
Only edit on Diff Map (3rd image) for now. Edits on the image1,2 won't be saved.
Click on Submit to save annotations to backend.




# Toggle Label Studio

## Overview
This is a app that allows labeling data on the difference map and exporting them as json.

## Quickstart
### install dependencies
Use **python 3.10.0** to reproduce.
```bash
cd toggle_labelstudio
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

### run the script
```bash
streamlit run app.py
```

* Click on top-right settings. Disable completion panel (it has no functionality)
* You can toggle around visualization paramters on the left.
* Click on **Predictions** to see the rule-based predictions(using min/max diff on diff map).
* Edit these predictions if necessary by clicking on the small icon next Predictions.
* Only edit on **Diff Map** for now. Edits on the grayscale images won't be saved.
* Click on **Submit** to save annotations to backend (will create a .db file for you locally under `toggle_labelstudio/`).  


bugs:<br>
* If you edit a label on the diffmap and save it, the changes on test and ref will only be displayed after you leave and return to the page (next page, then prev page).<br>

* The update button is a button to edit an label **right after** submit. The button doesn't work right now. Use the trick in mentioned in 1. to edit existing labels.<br> 

### Export data
in `app.py`, you can see your .db file path.<br>
```
# modify the .db filename if you want a fresh start (will create file for you)
db_path = "backend/db_files/this_bug_weird.db"
# pass in trained model checkpoint (currently only supports YOLO)
model_path = "/home/hubert007/Code/label_tool/labeling/runs/detect/megamind_nojit_vmin_fix/weights/best.pt"
```
Your just labeled data will be saved locally at `backend/db_files`

go to `export/` and run 
```
python export_json_and_mask.py --db_path "your_db_path.db" --output_dir "desired_output_path"
```

### Train YOLO
go read `prelabel/model_based/YOLO/README.md`

The current best model is under `/home/hubert007/Code/label_tool/labeling/runs/detect/megamind_nojit_vmin_fix`.

You can see all the metrics and checkpoints in the above folder.

It's traing config is here : `/home/hubert007/Code/label_tool/labeling/toggle_labelstudio/prelabel/model_based/YOLO/train_settings/megamind_nojit_vmin_fix.yaml` with 200 epochs.

I currently have a more high-qulatiy labeled dataset of 225 images in `/home/hubert007/Code/label_tool/labeling/toggle_labelstudio/backend/db_files/the_regional_dataset.db`

## Develop guide

### `Frontend`

#### `app.py`
The frontend is written with **Streamlit**, and basically all packed in `app.py`. 

Change .db path and YOLO's .ckpt path in `app.py` to point to your own .db file and YOLO's .ckpt file.

##### `Labelstudio Component`
The main labelstudio functionality comes from the repo [deneland/streamlit-labelstudio](https://github.com/deneland/streamlit-labelstudio). It creates a Streamlit component `st_labelstudio` that can be used to interact with Label Studio.

The only usage of this is in `app.py` where we use it to create a label studio instance and pass it the data.

This component takes in the following 4 parameters:
* `config`: The UI configuration of our labeling task. The Rt, T display is defined there. The annotation type is also defined there.
* `interfaces`: Which built-in interfaces to use for the labeling task.
* `user`: Who's labeling? (I think this isn't very important, but it's required by Label Studio.)
* `task`: **Important.** This is where we pass in the data that we want to label. In app.py we pass in a task_generator function. The diff-map logic is defined there. 

The component returns a dictionary after **submit** is pushed. The format of that dictionary is crucial with **extracting labels**. Please print out this dictionary and understand what it contains.

Currently, all code assumes the images are 256x256 pixels, if dynamic image size is needed, search for all 256 in the code base and replace it with variables.

##### `frontend/`<br>
Just contains some helper functions to convert data format.

### `backend/`
The current backend just stores the whole "annotation dictionary" mentioned above into sqlite3.
The schema looks like this:
```
index                       image_path                                              results_json
0    /mnt/fs0/dataset/Layer_M, F12_TMPD98_7M0A-R_20240503_170022, 1    {"id": "k8kst", "pk": null, "selecte...
1    /mnt/fs0/dataset/Layer_M, F12_TMPD98_7M0A-R_20240503_170022, 2    {"id": "xmbtL", "pk": null, "selecte...
2    /mnt/fs0/dataset/Layer_M, F12_TMPD98_7M0A-R_20240503_170022, 3    {"id": "ApHt7", "pk": null, "selecte...
3    /mnt/fs0/dataset/Layer_M, F12_TMPD98_7M0A-R_20240503_170022, 4    {"id": "aI2sc", "pk": null, "selecte...
```
`image_path` isn't the exact absolute path, it is a string composing 3 elements:<br>
1. dataset root directory
2. lot id
3. image id

`results_json` is the dictionary mentioned in `frontend`. I just store the whole dictionary into a json string.

You can run `backend/dbview.py` to print out a certain .db's contents.


### `alignment/`
The main functionalities of alignment is defined in `alignment/alignment.py`. The file itself is quite self-explanatory. <br>
You can add your custom alignment methods as long as you return with the spec described in the comments.

### `prelabel/`
The main functionalities of prelabeling is defined in `prelabel/prelabel.py`, also self-explanatory. <br>
You can easily add in other prelabeling methods by defining and swapping out the api.

### `export/`
Currently, it only contains one python file `mask_image.py`, whose <br>
inputs:<br>
1. .db file path
2. output directory

outputs:
1. metadata.json
2. cropped out mask of each defect

#### Model training pipeline.
go read `toggle_labelstudio/prelabel/model_based/YOLO/README.md`

### TODO bug fix
#### `app.py` 

1. Sometimes when choosing new id, you have to click twice. I think this is related to the session_state : image_index.

2. The **update** button is not working. I think if you go to the [streamlit_labelstudio/frontend/src/index.tsx](https://github.com/deneland/streamlit-labelstudio/blob/master/streamlit_labelstudio/frontend/src/index.tsx) you'll see the following code:
```
function onRender(event: Event): void {
  const data = (event as CustomEvent<RenderData>).detail
  
  var ls = new LabelStudio('label-studio', {
    config: data.args["config"],
    interfaces: data.args["interfaces"][0],
    user: data.args["user"][0],
    task: data.args["task"],
    
    onLabelStudioLoad: function(ls) {
      var c = ls.completionStore.addCompletion({
        userGenerate: true
      });
      ls.completionStore.selectCompletion(c.id);
    },
    
    onSubmitCompletion: function(ls, completion) {
      console.log(ls)
      completion = JSON.parse(JSON.stringify(completion));
      Streamlit.setComponentValue(completion)
    },
    
    
  });
  
  // We tell Streamlit to update our frameHeight after each render event, in
  // case it has changed. (This isn't strictly necessary for the example
  // because our height stays fixed, but this is a low-cost function, so
  // there's no harm in doing it redundantly.)
  Streamlit.setFrameHeight()
}
```
Maybe if we add in something like `onUpdateCompletion` to handle when a user updates their completion, we can activate the update button.

3. The app currently cannot handle cases where both test and ref contain the same defect. That defect won't be shown on the diff map. 
Here are some cases that cannot be handled.
```
            lot_id                           image_id 
F12_TMPD98_7M0A-R_20240503_170022               75
F12_TMPD98_7M0A-R_20240503_170022               76  
F12_TMPD98_7M0A-R_20240503_170022               78  
```

4. Here are just some cases where I cannot find the defect.
```
F12_TMPD98_7M0A-R_20240503_170022               91
F12_TMPD98_7M0A-R_20240503_170022               166
F12_TMPD98_7M0A-R_20240503_170022               186
F12_TMPD98_7M0A-R_20240503_170022               197
F12_TMPD98_7M0A-R_20240503_170022               198
F12_TMPD98_7M0A-R_20240503_170022               199

Currently "the_regional_dataset.db" only labeled to id 224.

```

5. Some cases can't be aligned with either SIFT or Correlation.
```
F12_TMPD98_7M0A-R_20240503_170022               207
F12_TMPD98_7M0A-R_20240503_170022               209
F12_TMPD98_7M0A-R_20240503_170022               211
F12_TMPD98_7M0A-R_20240503_170022               212
F12_TMPD98_7M0A-R_20240503_170022               222
F12_TMPD98_7M0A-R_20240503_170022               223
```

6. The current metadata only saves the image_path, bounding_boxes. However, we didn't save the toggle settings that were used during labeling. We need to add this information to the metadata so that we can reproduce the labeling states exactly.
<br>
<br>


#### `toggle_labelstudio/prelabel/model_based/YOLO/dataset.py`
1. The function `process_and_augment_images` seems to turn my red diffmaps into blue. It still trains well, but I think it's a bug in these lines:
```
    # Ensure the image is in RGB format
    if image_array.shape[2] == 4:  # If the image has an alpha channel
        image_array = cv2.cvtColor(image_array, cv2.COLOR_BGRA2RGB)
    else:
        image_array = cv2.cvtColor(image_array, cv2.COLOR_BGR2RGB)
```
I think the R and B channel are swapped. I'm not sure if this is a bug or just a misunderstanding of how OpenCV handles color channels.











1. æ•´ä½“æ¦‚è§ˆ
è¿™ä»½ä»£ç ä¸»è¦ç”¨äºç¼ºé™·æ£€æµ‹ä¸æ ‡æ³¨ï¼ŒåŒ…å«ä»¥ä¸‹å‡ ä¸ªå¤§æ¨¡å—ï¼š

ç¼ºé™·æ–‡ä»¶è¯»å–ä¸è§£æ
è¯»å–å­˜å‚¨ç¼ºé™·ä¿¡æ¯çš„æ–‡ä»¶ï¼ˆ.lrf æ ¼å¼ï¼‰ï¼Œæå–å‡ºæ¯ä¸ªç¼ºé™·çš„ç¼–å·ä¸åˆ†ç±»ä¿¡æ¯ã€‚

å›¾åƒåŠ è½½ã€é¢„å¤„ç†ä¸å·®åˆ†è®¡ç®—
è¯»å–å›¾åƒï¼ˆæµ‹è¯•å›¾ä¸å‚è€ƒå›¾ï¼‰ï¼Œå¯¹å›¾åƒè¿›è¡Œé…å‡†ã€å¯¹é½ä»¥åŠå·®åˆ†ï¼ˆdiff mapï¼‰è®¡ç®—ï¼Œå¹¶å°†å¤„ç†ç»“æœè½¬æ¢ä¸ºä¾¿äºå‰ç«¯å±•ç¤ºçš„æ ¼å¼ï¼ˆä¾‹å¦‚ Base64 ç¼–ç ï¼‰ã€‚

ç¼ºé™·é…å‡†ä¸å¯¹é½ï¼ˆAlignment æ¨¡å—ï¼‰
åˆ©ç”¨ SIFT æˆ– Correlation æ–¹æ³•å¯¹å›¾åƒè¿›è¡Œé…å‡†ï¼Œè®¡ç®—å‡ºå‚è€ƒå›¾ä¸æµ‹è¯•å›¾ä¹‹é—´çš„å¹³ç§»ã€å·®å¼‚ä¿¡æ¯ï¼Œä»¥åŠæœ€å¤§ã€æœ€å°å·®åˆ†ç‚¹ï¼ˆç”¨æ¥è¾…åŠ©é¢„æ ‡æ³¨ï¼‰ã€‚

é¢„æ ‡æ³¨ï¼ˆPrelabelingï¼‰ä¸æ¨æ–­
é€šè¿‡å·²è®­ç»ƒå¥½çš„ YOLO æ¨¡å‹å¯¹å›¾åƒè¿›è¡Œç›®æ ‡æ£€æµ‹ï¼Œå¾—åˆ°ç¼ºé™·å€™é€‰æ¡†ï¼›æˆ–ä½¿ç”¨åŸºäºå·®åˆ†å›¾çš„æœ€å°/æœ€å¤§å€¼ä½ç½®ç”Ÿæˆé¢„è®¾è¾¹ç•Œæ¡†ï¼ˆminmax æ–¹æ³•ï¼‰ã€‚

æ•°æ®é›†æ„å»ºä¸å›¾åƒå¢å¼º
å°†æ ‡æ³¨æ•°æ®ä»æ•°æ®åº“æˆ– JSON ä¸­æå–å‡ºæ¥ï¼ŒæŒ‰ç…§æ¯”ä¾‹åˆ’åˆ†æˆè®­ç»ƒã€éªŒè¯ã€æµ‹è¯•é›†ï¼ŒåŒæ—¶åˆ©ç”¨ albumentations è¿›è¡Œå›¾åƒå¢å¼ºï¼ˆæ—‹è½¬ã€ç¿»è½¬ã€ç¼©æ”¾ç­‰ï¼‰ã€‚

å‰ç«¯ç•Œé¢ä¸æ ‡æ³¨äº¤äº’
åˆ©ç”¨ Streamlit ç»“åˆ Label Studio çš„ç»„ä»¶æ„å»ºå‰ç«¯æ ‡æ³¨ç•Œé¢ï¼ŒåŠ è½½å›¾åƒã€é¢„æ ‡æ³¨ä¿¡æ¯ï¼Œå¹¶å°†ç”¨æˆ·çš„ä¿®æ”¹ç»“æœä¿å­˜åˆ°æ•°æ®åº“ä¸­ã€‚

æ•°æ®åº“æ“ä½œä¸ç»“æœåŒæ­¥
å¯¹æ ‡æ³¨ç»“æœè¿›è¡Œå­˜å‚¨ã€æ›´æ–°ä»¥åŠåˆå¹¶æ“ä½œï¼Œä¿è¯æ•°æ®çš„ä¸€è‡´æ€§ï¼ŒåŒæ—¶å°†é¢„æ ‡æ³¨ç»“æœåŒæ­¥åˆ°å„ä¸ªå›¾åƒè§†å›¾ä¸­ï¼ˆä¾‹å¦‚ image1ã€image2ã€image3ï¼‰ã€‚




2. å„æ¨¡å—è¯¦ç»†è§£æ
2.1 ç¼ºé™·æ–‡ä»¶è¯»å–ä¸è§£æ
ä¸»è¦å‡½æ•°ï¼š

get_lrf_file(data_dir, selected_lot_id)
æ ¹æ®æ•°æ®ç›®å½•ä¸é€‰æ‹©çš„æ‰¹æ¬¡ï¼ˆlotï¼‰IDï¼ŒæŸ¥æ‰¾å¯¹åº”çš„ .lrf æ–‡ä»¶ã€‚ç”±äºæ–‡ä»¶å‘½åå¯èƒ½æœ‰å¤šç§æ ¼å¼ï¼ˆå¦‚ _ADD.lrfã€_Classified.lrfã€æˆ–ç›´æ¥ .lrfï¼‰ï¼Œå‡½æ•°ä¾æ¬¡åˆ¤æ–­å„ä¸ªå¯èƒ½çš„æ–‡ä»¶è·¯å¾„ï¼Œè¿”å›å­˜åœ¨çš„é‚£ä¸ªè·¯å¾„ã€‚

read_lrf_file(file_path)
ç®€å•åœ°ä»¥æ–‡æœ¬æ¨¡å¼è¯»å–æŒ‡å®šæ–‡ä»¶çš„å†…å®¹ã€‚

detect_defect_list(content)
ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æŸ¥æ‰¾æ–‡æœ¬ä¸­ â€œ[DefectList]â€ æ ‡ç­¾å¼€å§‹çš„éƒ¨åˆ†ï¼Œå¹¶æå–å‡ºç¼ºé™·æ•°æ®åˆ—è¡¨æ‰€åœ¨çš„æ®µè½ã€‚

extract_no_and_classtype(defect_data)
å°†æå–å‡ºçš„ç¼ºé™·æ•°æ®æŒ‰è¡Œæ‹†åˆ†ï¼Œæ¯ä¸€è¡Œæ ¹æ®ç©ºæ ¼åˆ†éš”åï¼Œæå–ç¬¬ä¸€åˆ—ï¼ˆç¼ºé™·ç¼–å·ï¼‰å’Œç¬¬ä¹åˆ—ï¼ˆç¼ºé™·åˆ†ç±»ç±»å‹ï¼‰ã€‚è¿”å›ä¸€ä¸ªç¼–å·ä¸åˆ†ç±»ç±»å‹çš„å…ƒç»„åˆ—è¡¨ã€‚

get_defect_list(lrf_path)
ç»¼åˆè°ƒç”¨ä¸Šé¢å‡ ä¸ªå‡½æ•°ï¼šè¯»å–æ–‡ä»¶å†…å®¹ â†’ æ£€æµ‹ç¼ºé™·æ•°æ®æ®µ â†’ æå–ç¼–å·å’Œç±»å‹ï¼Œå¹¶æœ€ç»ˆè¿”å›ä¸€ä¸ªåŒ…å«å›¾åƒç¼–å·åˆ—è¡¨å’Œå¯¹åº”ç¼ºé™·ç±»å‹çš„å…ƒç»„ã€‚

ã€æ€»ç»“ã€‘
è¿™éƒ¨åˆ†ä»£ç ä¸»è¦è´Ÿè´£è§£æå­˜æ”¾ç¼ºé™·ä¿¡æ¯çš„æ–‡ä»¶ï¼Œæå–å‡ºæ¯ä¸ªç¼ºé™·åœ¨å›¾åƒä¸­çš„æ ‡è¯†ï¼ˆä¾‹å¦‚ç¼ºé™·ç¼–å·ï¼‰ä»¥åŠå®ƒçš„åˆ†ç±»ï¼Œç”¨äºåç»­å›¾åƒåŠ è½½å’Œæ ‡æ³¨å±•ç¤ºã€‚




2.2 å›¾åƒå¤„ç†ä¸é¢„å¤„ç†
å…³é”®åŠŸèƒ½ä¸å‡½æ•°ï¼š

å›¾åƒè½¬æ¢ä¸ç¼–ç 

numpy_to_base64(img_array)ï¼šå°† NumPy æ•°ç»„å½¢å¼çš„å›¾åƒè½¬æ¢ä¸º PIL å›¾ç‰‡ï¼Œç„¶åä¿å­˜ä¸º JPEG æ ¼å¼ï¼Œé€šè¿‡ BytesIO è½¬æ¢ä¸º Base64 ç¼–ç å­—ç¬¦ä¸²ï¼Œæ–¹ä¾¿åœ¨å‰ç«¯ï¼ˆå¦‚ HTML ä¸­ï¼‰å±•ç¤ºå›¾åƒã€‚
åŠ è½½ä¸é¢œè‰²æ˜ å°„

load_images_from_json(json_file)ï¼šæŒ‰è¡Œè¯»å– JSON æ–‡ä»¶ï¼Œå°†å›¾åƒä¿¡æ¯å­˜å‚¨åœ¨å­—å…¸ä¸­ï¼ˆä¸€èˆ¬ç”¨äºåŠ è½½é¢„å¤„ç†å¥½çš„å›¾åƒå…ƒæ•°æ®ï¼‰ã€‚
apply_colormap(np_array, colormap, vmin, vmax)ï¼šå¯¹ä¼ å…¥çš„ç°åº¦æˆ–å·®åˆ†å›¾åƒåº”ç”¨é¢œè‰²æ˜ å°„ã€‚ä¾‹å¦‚ï¼Œå°†ç°åº¦å›¾ç”¨â€œgrayâ€æ˜ å°„ï¼Œå°†å·®åˆ†å›¾ç”¨â€œseismicâ€æ˜ å°„ï¼Œå¹¶æ ¹æ® vmin ä¸ vmax å‚æ•°å¯¹æ•°å€¼èŒƒå›´åšå½’ä¸€åŒ–ï¼Œè¿”å› RGB æ ¼å¼çš„å›¾åƒæ•°ç»„ã€‚
å·ç§¯æ ¸å®šä¹‰

conv_kernel(kernel_size)ï¼šç”Ÿæˆä¸€ä¸ªå¤§å°ä¸º kernel_size çš„å‡å€¼å·ç§¯æ ¸ï¼Œç”¨äºå›¾åƒå¹³æ»‘æ“ä½œï¼Œå¸¸è§äºå¯¹å·®åˆ†å›¾è¿›è¡Œå·ç§¯å¤„ç†ä»¥å¢å¼ºå±€éƒ¨ç‰¹å¾ã€‚
ç”Ÿæˆå‰ç«¯è¾“å…¥å›¾åƒå¯¹

get_image_pair_for_studio_input(...)ï¼š
æ ¹æ®ä¼ å…¥çš„æ•°æ®ç›®å½•ã€é€‰ä¸­çš„ lot ID å’Œå›¾åƒç¼–å·ï¼Œå®šä½å­˜æ”¾æµ‹è¯•å›¾å’Œå‚è€ƒå›¾çš„æ–‡ä»¶å¤¹ã€‚
è°ƒç”¨ load_defect_pairï¼ˆåœ¨ alignment æ¨¡å—ä¸­ï¼‰è·å¾—å‚è€ƒå›¾å’Œæµ‹è¯•å›¾ï¼Œå¹¶ç¡®å®šæ˜¯å¦ä½¿ç”¨ä¸­ä½å›¾ä½œä¸ºå‚è€ƒã€‚
ä½¿ç”¨ get_diff_map è®¡ç®—å‡ºä¸¤å¹…å›¾åƒä¹‹é—´çš„å·®åˆ†å›¾ï¼ŒåŒæ—¶å¾—åˆ°ä¸€äº›å…ƒæ•°æ®ï¼ˆä¾‹å¦‚æœ€å¤§å·®å¼‚ç‚¹å’Œæœ€å°å·®å¼‚ç‚¹çš„ä½ç½®ï¼‰ã€‚
å¯¹é…å‡†åçš„å‚è€ƒå›¾ã€æµ‹è¯•å›¾å’Œå·®åˆ†å›¾åº”ç”¨é¢œè‰²æ˜ å°„ï¼Œå†å¯¹å·®åˆ†å›¾åšå·ç§¯æ»¤æ³¢å¤„ç†ã€‚
å°†è¿™äº›å›¾åƒè½¬æ¢æˆ Base64 å­—ç¬¦ä¸²ï¼Œè¿”å›ç»™å‰ç«¯æ˜¾ç¤ºï¼ŒåŒæ—¶è¿”å›åŒ…å«å¯¹é½ä¸å·®åˆ†ä¿¡æ¯çš„å…ƒæ•°æ®ã€‚
ã€æ€»ç»“ã€‘
è¿™ä¸€æ¨¡å—ä¸»è¦å®ç°å›¾åƒçš„è¯»å–ã€é¢„å¤„ç†å’Œè½¬æ¢ï¼Œä»¥ä¾¿åç»­ç¼ºé™·æ£€æµ‹å’Œå‰ç«¯æ ‡æ³¨ç•Œé¢çš„å±•ç¤ºã€‚å…³é”®æ­¥éª¤åœ¨äºè®¡ç®—â€œå·®åˆ†å›¾â€ï¼Œå¸®åŠ©çªå‡ºæ˜¾ç¤ºç¼ºé™·åŒºåŸŸã€‚



2.3 ç¼ºé™·é…å‡†ä¸å·®åˆ†è®¡ç®—ï¼ˆAlignment æ¨¡å—ï¼‰
æ ¸å¿ƒå‡½æ•°ï¼š

load_defect_pair(img_path, defect_no)
æ ¹æ®ç»™å®šçš„å›¾åƒç›®å½•ä¸ç¼ºé™·ç¼–å·ï¼Œä»å¤šä¸ªå¯èƒ½çš„åç¼€ï¼ˆä¾‹å¦‚ â€œLâ€, â€œUâ€, â€œL_pâ€, â€œU_pâ€ï¼‰ä¸­å¯»æ‰¾å¯¹åº”çš„å‚è€ƒå›¾å’Œæµ‹è¯•å›¾ã€‚

å¦‚æœæµ‹è¯•å›¾åªæœ‰ä¸€å¼ ï¼Œåˆ™å°†å…¶ä½œä¸ºä¸»è¦å›¾åƒï¼›å¦‚æœæœ‰å¤šå¼ å‚è€ƒå›¾ï¼ˆä¾‹å¦‚å·¦å³ä¸¤ä¸ªæ–¹å‘ï¼‰ï¼Œåˆ™ä¼šæ ¹æ®å›¾åƒæ•°é‡å†³å®šæ˜¯å¦ä½¿ç”¨ä¸­ä½å›¾ä½œä¸ºå‚è€ƒå›¾ã€‚
get_diff_map(ref, test, defect_no, lot_id, is_median_ref, max_features, max_shift, ransacReprojThreshold, method)

æ ¹æ®é€‰æ‹©çš„æ–¹æ³•ï¼ˆSIFT æˆ– Correlateï¼‰å¯¹å‚è€ƒå›¾å’Œæµ‹è¯•å›¾è¿›è¡Œå¯¹é½ï¼ˆå›¾åƒé…å‡†ï¼‰ã€‚
å¯¹å¯¹é½åçš„å›¾åƒè¿›è¡Œå½’ä¸€åŒ–å¤„ç†ï¼Œè®¡ç®—å‡ºä¸¤å¹…å›¾åƒçš„å·®åˆ†å›¾ã€‚
åœ¨å›¾åƒçš„ ROI åŒºåŸŸå†…æ‰¾åˆ°å·®åˆ†æœ€å¤§çš„ç‚¹ä¸æœ€å°çš„ç‚¹ï¼Œè¿™é€šå¸¸å¯¹åº”ç¼ºé™·åŒºåŸŸã€‚
åŒæ—¶è®¡ç®— RMSEï¼ˆå‡æ–¹æ ¹è¯¯å·®ï¼‰ã€æœ€å¤§ç»å¯¹å·®åˆ†ç­‰æŒ‡æ ‡ï¼Œç”Ÿæˆä¸€ä¸ªåŒ…å«æ‰€æœ‰è¿™äº›ä¿¡æ¯çš„å…ƒæ•°æ®å­—å…¸ã€‚
ã€æ€»ç»“ã€‘
è¿™ä¸€éƒ¨åˆ†æ˜¯æ•´ä¸ªç¼ºé™·åˆ†æçš„æ ¸å¿ƒï¼Œé€šè¿‡å›¾åƒå¯¹é½ä¸å·®åˆ†è®¡ç®—ï¼Œå¯ä»¥è‡ªåŠ¨å®šä½å‡ºå›¾åƒä¸­çš„å¼‚å¸¸åŒºåŸŸï¼Œä»è€Œè¾…åŠ©åç»­çš„æ ‡æ³¨ä¸æ£€æµ‹å·¥ä½œã€‚



2.4 æ¨æ–­ä¸é¢„æ ‡æ³¨
ä¸»è¦æµç¨‹ï¼š

YOLO æ¨¡å‹æ¨æ–­

inference(img_np, ckpt)ï¼š
åŠ è½½é¢„è®­ç»ƒæˆ– fine-tune åçš„ YOLO æ¨¡å‹ã€‚
å¯¹è¾“å…¥å›¾åƒï¼ˆå¯èƒ½ç»è¿‡é¢„å¤„ç†è½¬æ¢ä¸º RGB æ ¼å¼ï¼‰è¿›è¡Œç›®æ ‡æ£€æµ‹ã€‚
éå†æ£€æµ‹åˆ°çš„è¾¹ç•Œæ¡†ï¼Œæå–å‡ºè¾¹ç•Œæ¡†çš„åæ ‡ï¼ˆx1, y1, x2, y2ï¼‰ã€å®½åº¦ã€é«˜åº¦ä»¥åŠç±»åˆ«æ ‡ç­¾ï¼Œæ„æˆé¢„æ ‡æ³¨æ•°æ®ã€‚
é¢„æ ‡æ³¨é€»è¾‘

åœ¨ YOLO_prelabel ä¸­ï¼Œå°†é€šè¿‡ YOLO æ¨æ–­å¾—åˆ°çš„è¾¹ç•Œæ¡†è½¬æ¢æˆç¬¦åˆ Label Studio æ ‡æ³¨æ ¼å¼çš„æ•°æ®ï¼ˆä»¥ç™¾åˆ†æ¯”è¡¨ç¤ºä½ç½®ä¸å°ºå¯¸ï¼‰ï¼Œå¹¶ä¸ºä¸åŒè§†å›¾ï¼ˆä¾‹å¦‚ image1~image6ï¼‰ç”Ÿæˆç›¸åº”çš„é¢„æ ‡æ³¨ä¿¡æ¯ã€‚
åŒæ—¶ï¼Œä»£ç ä¸­è¿˜æ”¯æŒå¦ä¸€ç§é¢„æ ‡æ³¨æ–¹æ³•ï¼ˆminmaxï¼‰ï¼Œå³åˆ©ç”¨å·®åˆ†å›¾ä¸­çš„æœ€å¤§/æœ€å°ç‚¹ä½ç½®ç”Ÿæˆå›ºå®šå¤§å°çš„ç¼ºé™·åŒºåŸŸã€‚
ã€æ€»ç»“ã€‘
è¿™ä¸€æ¨¡å—åˆ©ç”¨æ·±åº¦å­¦ä¹ æ¨¡å‹å’Œè§„åˆ™æ–¹æ³•ä¸ºå›¾åƒè‡ªåŠ¨ç”Ÿæˆç¼ºé™·å€™é€‰æ¡†ï¼Œå‡å°‘äººå·¥æ ‡æ³¨çš„å·¥ä½œé‡ï¼Œä¹Ÿä¸ºåç»­æ¨¡å‹çš„è®­ç»ƒæä¾›åˆå§‹æ•°æ®ã€‚



2.5 æ•°æ®é›†æ„å»ºä¸å›¾åƒå¢å¼º
ä¸»è¦åŠŸèƒ½ï¼š

æ•°æ®åº“ä¸å…ƒæ•°æ®è½¬æ¢

db_to_metadataï¼šä» SQLite æ•°æ®åº“ä¸­æå–åŸå§‹æ ‡æ³¨ä¿¡æ¯ï¼Œè½¬æ¢æˆ JSON æ ¼å¼çš„å…ƒæ•°æ®æ–‡ä»¶ã€‚
æ•°æ®é›†åˆ›å»º

create_datasetï¼š
æ ¹æ®æä¾›çš„æ•°æ®åº“ä¸ JSON æ–‡ä»¶ï¼Œå°†æ•°æ®åˆ’åˆ†ä¸ºè®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†ï¼ˆä¾‹å¦‚ 70%/20%/10%ï¼‰ã€‚
é’ˆå¯¹æ¯ä¸ªå›¾åƒï¼Œè°ƒç”¨ get_diff_map åŠå›¾åƒå¢å¼ºå‡½æ•°å¯¹å›¾åƒè¿›è¡Œé¢„å¤„ç†ï¼Œå¹¶ä¿å­˜ä¸º PNG æ–‡ä»¶ï¼›åŒæ—¶ç”Ÿæˆå¯¹åº”çš„æ ‡æ³¨æ–‡æœ¬æ–‡ä»¶ã€‚
å›¾åƒå¢å¼ºéƒ¨åˆ†é‡‡ç”¨ albumentations åº“è¿›è¡Œæ—‹è½¬ã€ç¿»è½¬ã€ä»¿å°„å˜æ¢ç­‰æ“ä½œï¼Œä»¥æ‰©å……æ•°æ®é›†ï¼Œå¢åŠ æ¨¡å‹çš„é²æ£’æ€§ã€‚
æ•°æ®é›†æ£€æŸ¥

dataset_checkerï¼šæ‰«ææ•°æ®é›†ç›®å½•ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰å›¾åƒå¯¹åº”çš„æ ‡æ³¨æ–‡ä»¶ç¼ºå¤±æˆ–ä¸ºç©ºï¼Œå¸®åŠ©æ’æŸ¥æ•°æ®å‡†å¤‡è¿‡ç¨‹ä¸­çš„é—®é¢˜ã€‚
ã€æ€»ç»“ã€‘
è¿™ä¸€æ¨¡å—ä¸»è¦è´Ÿè´£å°†æ ‡æ³¨æ•°æ®è½¬æ¢ä¸º YOLO æ¨¡å‹è®­ç»ƒæ‰€éœ€è¦çš„æ ¼å¼ï¼Œå¹¶é€šè¿‡æ•°æ®å¢å¼ºæ¥ä¸°å¯Œè®­ç»ƒæ ·æœ¬ï¼Œç¡®ä¿æ¨¡å‹è®­ç»ƒæ—¶å…·æœ‰è¶³å¤Ÿçš„å¤šæ ·æ€§ã€‚




2.6 å‰ç«¯æ ‡æ³¨ä¸äº¤äº’ï¼ˆä½¿ç”¨ Label Studio ä¸ Streamlitï¼‰
ä¸»è¦éƒ¨åˆ†ï¼š

å‰ç«¯å±•ç¤º

åˆ©ç”¨ Streamlit æ„å»º Web åº”ç”¨ï¼ˆapp.pyï¼‰ï¼Œåœ¨ä¾§è¾¹æ ä¸­æä¾›ç›®å½•é€‰æ‹©ï¼ˆä¾‹å¦‚ lot IDã€å›¾åƒç¼–å·ï¼‰ï¼ŒåŠ¨æ€åŠ è½½å¯¹åº”çš„å›¾åƒåŠé¢„æ ‡æ³¨ä¿¡æ¯ã€‚
å›¾åƒä»¥ Base64 ç¼–ç çš„å½¢å¼ä¼ ç»™å‰ç«¯ç»„ä»¶ï¼Œæ–¹ä¾¿åœ¨ç½‘é¡µä¸­ç›´æ¥æ˜¾ç¤ºã€‚
Label Studio ç»„ä»¶é›†æˆ

é€šè¿‡ st_labelstudio ç»„ä»¶ï¼ˆåŸºäº deneland/streamlit-labelstudioï¼‰ï¼Œæ„å»ºäº¤äº’å¼æ ‡æ³¨ç•Œé¢ã€‚
æ ‡æ³¨ç•Œé¢é…ç½®ï¼ˆå¦‚ configã€interfacesã€user ç­‰ï¼‰å®šä¹‰äº†å¦‚ä½•å±•ç¤ºå›¾åƒï¼ˆå¦‚åˆ†ä¸ºå·¦å³æˆ–ä¸¤è¡Œæ˜¾ç¤ºï¼‰ã€æ ‡æ³¨ç±»å‹ï¼ˆçŸ©å½¢æ ‡æ³¨ã€æ ‡ç­¾é¢œè‰²ç­‰ï¼‰ã€‚
ç”¨æˆ·åœ¨ç•Œé¢ä¸Šå¯ä»¥ä¿®æ”¹é¢„æ ‡æ³¨ä¿¡æ¯ï¼Œæœ€ç»ˆç‚¹å‡»æäº¤åï¼Œå°†æ ‡æ³¨æ•°æ®ä»¥ JSON æ ¼å¼è¿”å›å¹¶ä¿å­˜åˆ° SQLite æ•°æ®åº“ä¸­ã€‚
é¢„æ ‡æ³¨ç»“æœåŒæ­¥

sync_labels_across_3imagesï¼šå°†ä¸€ä¸ªè§†å›¾ï¼ˆä¾‹å¦‚ image3ï¼‰çš„æ ‡æ³¨ä¿¡æ¯å¤åˆ¶åŒæ­¥åˆ°å…¶ä»–è§†å›¾ï¼ˆä¾‹å¦‚ image1ã€image2ï¼‰ï¼Œç¡®ä¿å‰ç«¯å±•ç¤ºæ—¶å„ä¸ªå›¾åƒçš„æ ‡æ³¨ä¿æŒä¸€è‡´ã€‚
ã€æ€»ç»“ã€‘
å‰ç«¯éƒ¨åˆ†ä¸»è¦æ˜¯ä¸ç”¨æˆ·äº¤äº’ï¼ŒåŠ è½½å›¾åƒå’Œé¢„æ ‡æ³¨ã€æ˜¾ç¤ºæ ‡æ³¨ç•Œé¢ã€æ•è·ç”¨æˆ·ä¿®æ”¹åè¿”å›çš„æ•°æ®ï¼Œå¹¶å°†è¿™äº›æ•°æ®ä¿å­˜åˆ°åç«¯æ•°æ®åº“ä¸­ã€‚



2.7 æ•°æ®åº“æ“ä½œä¸å…¶ä»–è¾…åŠ©æ¨¡å—
ä¸»è¦åŠŸèƒ½ï¼š

æ•°æ®åº“è¯»å†™ä¸åˆå¹¶

æä¾›äº† save_json_to_sqliteã€fetch_resultsã€combine_databases ç­‰å‡½æ•°ï¼Œç”¨äºå­˜å‚¨ã€æŸ¥è¯¢å’Œåˆå¹¶æ ‡æ³¨ç»“æœã€‚
è¿™äº›å‡½æ•°ä¿è¯åŒä¸€å›¾åƒå¤šæ¬¡æ ‡æ³¨æ—¶ä¸ä¼šé‡å¤å†™å…¥ï¼ŒåŒæ—¶æ”¯æŒæ›´æ–°å·²æœ‰æ•°æ®ã€‚
å¯¼å‡ºä¸åå¤„ç†

export_json_and_mask.pyï¼šä»æ•°æ®åº“ä¸­æå–æ•°æ®ï¼Œç”Ÿæˆæœ€ç»ˆçš„ JSON å…ƒæ•°æ®æ–‡ä»¶ï¼Œå¹¶å¯¹å›¾åƒè¿›è¡Œé®ç½©å¤„ç†ï¼ˆå°†ç¼ºé™·åŒºåŸŸé€æ˜åŒ–æˆ–çªå‡ºæ˜¾ç¤ºï¼‰ï¼Œæ–¹ä¾¿åç»­ä½¿ç”¨ã€‚
å…¶ä»–è¾…åŠ©å‡½æ•°

å¦‚ check_image_variants ç”¨äºå¤„ç†ä¸åŒåç¼€å›¾åƒï¼ˆä¾‹å¦‚å·¦ã€å³ã€ä¸Šã€ä¸‹ï¼‰çš„æŸ¥æ‰¾ï¼Œç¡®ä¿åœ¨å­˜åœ¨å¤šç§ç‰ˆæœ¬çš„å›¾åƒæ—¶èƒ½æ­£ç¡®é€‰å–ã€‚
ã€æ€»ç»“ã€‘
è¿™ä¸€éƒ¨åˆ†ç¡®ä¿æ•´ä¸ªç³»ç»Ÿçš„æ•°æ®èƒ½å¤Ÿç¨³å®šå­˜å‚¨ã€æ›´æ–°å’Œå¯¼å‡ºï¼ŒåŒæ—¶ä¸ºåç»­æ¨¡å‹è®­ç»ƒå’Œç»“æœå±•ç¤ºæä¾›å¿…è¦çš„æ”¯æ’‘ã€‚




3. æµç¨‹å›¾ç¤ºä¸å·¥ä½œåŸç†
æ•°æ®è¯»å–

ç³»ç»Ÿä»æ•°æ®ç›®å½•ä¸­è¯»å– .lrf æ–‡ä»¶ï¼Œé€šè¿‡æ­£åˆ™è§£ææå–ç¼ºé™·ç¼–å·å’Œç±»å‹ã€‚
å›¾åƒé…å‡†ä¸å·®åˆ†è®¡ç®—

æ ¹æ®ç¼ºé™·ç¼–å·åŠ è½½æµ‹è¯•å›¾å’Œå‚è€ƒå›¾ï¼Œåˆ©ç”¨ SIFT æˆ– Correlation å¯¹å›¾åƒè¿›è¡Œé…å‡†ï¼Œå¯¹é½åè®¡ç®—å·®åˆ†å›¾ï¼Œå¹¶å¾—åˆ°æœ€å¤§/æœ€å°å·®åˆ†ç‚¹ä½ç½®ç­‰å…ƒæ•°æ®ã€‚
é¢„æ ‡æ³¨ç”Ÿæˆ

åˆ©ç”¨é¢„è®­ç»ƒ YOLO æ¨¡å‹ï¼ˆæˆ– minmax è§„åˆ™ï¼‰å¯¹å›¾åƒè¿›è¡Œç¼ºé™·æ£€æµ‹ï¼Œç”Ÿæˆåˆæ­¥çš„è¾¹ç•Œæ¡†é¢„æ ‡æ³¨ï¼Œè½¬æ¢æˆ Label Studio æ‰€éœ€çš„æ ¼å¼ã€‚
å‰ç«¯å±•ç¤ºä¸äººå·¥æ ‡æ³¨

å‰ç«¯ä½¿ç”¨ Streamlit ä¸ Label Studio ç»„ä»¶å±•ç¤ºå›¾åƒå’Œé¢„æ ‡æ³¨ï¼Œç”¨æˆ·å¯ä»¥è¿›è¡Œä¿®æ”¹æˆ–ç¡®è®¤ï¼Œç„¶åæäº¤æ ‡æ³¨ç»“æœã€‚
æ•°æ®å­˜å‚¨ä¸æ•°æ®é›†æ„å»º

æäº¤åçš„æ ‡æ³¨ç»“æœå­˜å…¥ SQLite æ•°æ®åº“ï¼ŒåŒæ—¶å¯ä»¥åˆ©ç”¨è¿™äº›æ•°æ®æ„å»ºç”¨äºè®­ç»ƒ YOLO æ¨¡å‹çš„æ•°æ®é›†ï¼ˆåŒ…æ‹¬å›¾åƒå¢å¼ºå’Œæ ¼å¼è½¬æ¢ï¼‰ã€‚
æ¨¡å‹è®­ç»ƒä¸è¿­ä»£æ”¹è¿›

åˆ©ç”¨æ„å»ºå¥½çš„æ•°æ®é›†è¿›è¡Œ YOLO æ¨¡å‹çš„ fine-tuningï¼Œè®­ç»ƒåå¾—åˆ°çš„æ¨¡å‹å¯ç”¨äºä¸‹ä¸€è½®çš„é¢„æ ‡æ³¨ï¼Œä»è€Œä¸æ–­è¿­ä»£æ”¹è¿›ç¼ºé™·æ£€æµ‹æ•ˆæœã€‚


4. æ€»ç»“
æ€»ä½“æ¥è¯´ï¼Œè¿™å¥—ç³»ç»Ÿé‡‡ç”¨äº†æ¨¡å—åŒ–è®¾è®¡ï¼Œå°†ç¼ºé™·æ–‡ä»¶è§£æã€å›¾åƒå¤„ç†ã€é…å‡†å·®åˆ†è®¡ç®—ã€é¢„æ ‡æ³¨ç”Ÿæˆã€å‰ç«¯äº¤äº’æ ‡æ³¨ä»¥åŠæ•°æ®å­˜å‚¨å’Œæ¨¡å‹è®­ç»ƒç­‰åŠŸèƒ½åˆ†åˆ«å®ç°ã€‚å¯¹åˆå­¦è€…æ¥è¯´ï¼Œå¯ä»¥æŒ‰ä»¥ä¸‹æ€è·¯æ¥ç†è§£å’Œé€æ­¥å­¦ä¹ ï¼š

å…ˆç†è§£æ•°æ®è¾“å…¥éƒ¨åˆ†ï¼šå¦‚ä½•ä» .lrf æ–‡ä»¶ä¸­æå–ç¼ºé™·ä¿¡æ¯ï¼Œå¹¶æ ¹æ®ç¼–å·åŠ è½½å¯¹åº”å›¾åƒã€‚
å†äº†è§£å›¾åƒå¯¹é½ä¸å·®åˆ†è®¡ç®—ï¼šé‡ç‚¹ç†è§£ load_defect_pair ä¸ get_diff_map çš„å¤„ç†æµç¨‹ï¼Œè¿™éƒ¨åˆ†ç›´æ¥å½±å“åç»­ç¼ºé™·å®šä½ã€‚
æŒæ¡é¢„æ ‡æ³¨ç”Ÿæˆé€»è¾‘ï¼šå­¦ä¹ å¦‚ä½•åˆ©ç”¨æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼ˆYOLOï¼‰å’Œè§„åˆ™æ–¹æ³•ç”Ÿæˆåˆå§‹çš„æ ‡æ³¨ç»“æœã€‚
æœ€åå…³æ³¨å‰ç«¯äº¤äº’ä¸æ•°æ®å­˜å‚¨ï¼šç†è§£å¦‚ä½•é€šè¿‡ Streamlit ä¸ Label Studio ç»„ä»¶æ„å»ºç”¨æˆ·æ ‡æ³¨ç•Œé¢ï¼Œä»¥åŠå¦‚ä½•å°†æ ‡æ³¨ç»“æœå­˜å‚¨åˆ°æ•°æ®åº“ä¸­ä»¥ä¾¿åç»­ä½¿ç”¨ã€‚





1. å‰ç«¯å±•ç¤ºä¸äººå·¥æ ‡æ³¨
ä¸»è¦æ–‡ä»¶ä¸ç»„ä»¶
app.py
è¿™æ˜¯æ•´ä¸ªå‰ç«¯äº¤äº’çš„å…¥å£ï¼Œåˆ©ç”¨ Streamlit æ„å»ºäº†ä¸€ä¸ª Web åº”ç”¨ï¼ŒåŒæ—¶é›†æˆäº† Label Studio çš„æ ‡æ³¨ç»„ä»¶ï¼ˆé€šè¿‡ st_labelstudioï¼‰æ¥å±•ç¤ºå›¾åƒå’Œé¢„æ ‡æ³¨ä¿¡æ¯ã€‚

Label Studio ç»„ä»¶
å‰ç«¯é€šè¿‡è°ƒç”¨ st_labelstudio(config, interfaces, user, task) æ¥å¯åŠ¨æ ‡æ³¨ç•Œé¢ã€‚è¿™é‡Œçš„å„ä¸ªå‚æ•°è¯´æ˜å¦‚ä¸‹ï¼š

configï¼šå®šä¹‰äº†æ ‡æ³¨ç•Œé¢çš„å¸ƒå±€å’ŒåŠŸèƒ½ï¼Œæ¯”å¦‚æ˜¾ç¤ºå“ªäº›å›¾åƒï¼ˆå¦‚ image1ã€image2ã€image3 æˆ–æ›´å¤šï¼‰ï¼Œä»¥åŠå…è®¸ç”¨æˆ·ä½¿ç”¨å“ªç§æ ‡æ³¨æ–¹å¼ï¼ˆå¦‚çŸ©å½¢æ ‡æ³¨ï¼‰ã€‚
interfacesï¼šé…ç½®äº†ä¾§è¾¹æ ã€æ›´æ–°ã€æ·»åŠ ã€åˆ é™¤ç­‰å†…ç½®åŠŸèƒ½ã€‚
userï¼šæ ‡æ˜å½“å‰æ ‡æ³¨ç”¨æˆ·çš„ä¿¡æ¯ã€‚
taskï¼šç”± task_generator å‡½æ•°ç”Ÿæˆçš„ä»»åŠ¡æ•°æ®ï¼ŒåŒ…å«äº†å‰ç«¯éœ€è¦å±•ç¤ºçš„å›¾åƒæ•°æ®ï¼ˆé€šå¸¸æ˜¯ Base64 ç¼–ç çš„å­—ç¬¦ä¸²ï¼‰ä»¥åŠé¢„æ ‡æ³¨çš„è¾¹ç•Œæ¡†ä¿¡æ¯ã€‚
åœ¨ task_generator ä¸­ï¼Œå¯ä»¥çœ‹åˆ°å®ƒä¼šåˆ¤æ–­æ˜¯å¦å­˜åœ¨â€œå·²æœ‰æ ‡æ³¨â€ï¼ˆexisting_labelsï¼‰ï¼Œå¦‚æœæ²¡æœ‰ï¼Œåˆ™è°ƒç”¨é¢„æ ‡æ³¨é€»è¾‘ï¼ˆä¾‹å¦‚ YOLO æˆ– minmax æ–¹æ³•ï¼‰æ¥ç”Ÿæˆåˆæ­¥çš„ç¼ºé™·å€™é€‰æ¡†ï¼Œç„¶åå°†ç»“æœæ ¼å¼åŒ–ä¸ºç¬¦åˆ Label Studio è¦æ±‚çš„æ•°æ®ç»“æ„ã€‚
å½“ç”¨æˆ·åœ¨ç•Œé¢ä¸Šä¿®æ”¹æˆ–ç¡®è®¤åï¼Œæäº¤çš„æ•°æ®å°†ä»¥ JSON æ ¼å¼è¿”å›ç»™ Streamlitã€‚


å‰ç«¯å·¥ä½œæµç¨‹
å›¾åƒåŠ è½½ä¸é¢„å¤„ç†

åœ¨ app.py ä¸­ï¼Œé¦–å…ˆé€šè¿‡è¯»å–å­˜å‚¨å›¾åƒä¿¡æ¯çš„æ–‡ä»¶å¤¹ï¼ˆä¾‹å¦‚æ•°æ®ç›®å½•ä¸‹çš„ lot æ–‡ä»¶å¤¹ï¼‰ï¼Œæ ¹æ®å½“å‰é€‰ä¸­çš„ lot ID å’Œå›¾åƒç¼–å·è°ƒç”¨å‡½æ•° get_image_pair_for_studio_input æ¥è·å–å¤„ç†å¥½çš„å›¾åƒï¼ˆå‚è€ƒå›¾ã€æµ‹è¯•å›¾ã€å·®åˆ†å›¾ï¼‰ã€‚
è¿™äº›å›¾åƒç»è¿‡é¢œè‰²æ˜ å°„ã€å·ç§¯æ»¤æ³¢ç­‰å¤„ç†åä¼šè¢«è½¬æ¢ä¸º Base64 å­—ç¬¦ä¸²ï¼Œæ–¹ä¾¿ç›´æ¥åœ¨ HTML ä¸­åµŒå…¥æ˜¾ç¤ºã€‚
ä»»åŠ¡æ„å»º

è°ƒç”¨ task_generator å‡½æ•°ï¼Œæ„é€ ä¸€ä¸ªä»»åŠ¡ï¼ˆtaskï¼‰ã€‚ä»»åŠ¡ä¸­åŒ…å«äº†å…­ä¸ªå›¾åƒè§†å›¾ï¼ˆå¦‚ image1 ~ image6ï¼‰ï¼Œæ¯ä¸ªå›¾åƒå¯¹åº”çš„å†…å®¹ï¼ˆä¾‹å¦‚ç°åº¦å›¾ã€å·®åˆ†å›¾ç­‰ï¼‰ä¼šä»¥ data:image/jpeg;base64,â€¦â€¦ çš„æ ¼å¼ä¼ é€’åˆ°å‰ç«¯ã€‚
åŒæ—¶ï¼Œæ ¹æ®é¢„è®¾çš„é¢„æ ‡æ³¨æ–¹æ³•ï¼ˆYOLO æˆ– minmaxï¼‰ï¼Œç”Ÿæˆåˆæ­¥çš„æ ‡æ³¨ä¿¡æ¯ï¼ˆä¾‹å¦‚ç¼ºé™·å€™é€‰æ¡†ï¼‰ï¼Œè¿™äº›é¢„æ ‡æ³¨ç»“æœä¹Ÿä¼šä¼ å…¥ task ä¸­ã€‚
ç”¨æˆ·äº¤äº’

ç”¨æˆ·åœ¨ Label Studio çš„ç•Œé¢ä¸Šå¯ä»¥æŸ¥çœ‹é¢„æ ‡æ³¨ç»“æœï¼Œå¹¶æ ¹æ®éœ€è¦è¿›è¡Œä¿®æ”¹ï¼ˆä¾‹å¦‚è°ƒæ•´è¾¹ç•Œæ¡†çš„ä½ç½®æˆ–å°ºå¯¸ï¼‰ã€‚
æäº¤æ ‡æ³¨åï¼Œst_labelstudio ç»„ä»¶ä¼šè¿”å›æ›´æ–°åçš„æ ‡æ³¨ç»“æœï¼ˆJSON æ ¼å¼ï¼‰ï¼Œä»£ç ä¸­é€šè¿‡ has_results_raw_changed åˆ¤æ–­æ˜¯å¦æœ‰æ›´æ–°ï¼Œå¹¶æœ€ç»ˆå°†ç»“æœè¿›è¡Œä¿å­˜ã€‚



2. æ•°æ®å­˜å‚¨ä¸æ•°æ®é›†æ„å»º
æ•°æ®å­˜å‚¨éƒ¨åˆ†
æ•°æ®åº“æ“ä½œ
åœ¨ä»£ç ä¸­ï¼ŒSQLite è¢«ç”¨æ¥å­˜å‚¨æ¯æ¬¡æ ‡æ³¨çš„ç»“æœã€‚ä¸»è¦ä½¿ç”¨äº†å¦‚ä¸‹å‡½æ•°ï¼š

save_json_to_sqlite
è¯¥å‡½æ•°è´Ÿè´£å°†æ ‡æ³¨ç»“æœï¼ˆä¸€ä¸ª JSON å­—ç¬¦ä¸²ï¼‰ä¸å¯¹åº”çš„ image_path å­˜å…¥æ•°æ®åº“ã€‚é€»è¾‘åŒ…æ‹¬ï¼š
é¦–å…ˆæ£€æŸ¥å½“å‰å›¾ç‰‡æ˜¯å¦å·²ç»å­˜åœ¨æ ‡æ³¨è®°å½•ã€‚
å¦‚æœå­˜åœ¨ä¸”å†…å®¹å‘ç”Ÿå˜åŒ–ï¼Œåˆ™æ›´æ–°è®°å½•ï¼›å¦åˆ™ç›´æ¥æ’å…¥æ–°çš„è®°å½•ã€‚
fetch_results
æ ¹æ®ç»™å®šçš„ image_path ä»æ•°æ®åº“ä¸­è·å–ä¹‹å‰ä¿å­˜çš„æ ‡æ³¨ç»“æœï¼Œç”¨äºåœ¨é‡æ–°åŠ è½½ä»»åŠ¡æ—¶ï¼ˆä¾‹å¦‚ç”¨æˆ·é‡æ–°è¿›å…¥é¡µé¢ï¼‰æ˜¾ç¤ºå·²æœ‰æ ‡æ³¨ã€‚
å‰ç«¯ä¸æ•°æ®åº“çš„è¡”æ¥
åœ¨ app.py ä¸­ï¼Œå½“ç”¨æˆ·æäº¤æ ‡æ³¨ç»“æœåï¼Œç¨‹åºä¼šè°ƒç”¨ save_json_to_sqlite å°†æ–°çš„æ ‡æ³¨æ•°æ®ä¿å­˜åˆ° SQLite æ•°æ®åº“ä¸­ï¼Œç„¶åé€šè¿‡æ›´æ–° session çŠ¶æ€ï¼ˆä¾‹å¦‚ image_indexã€lot_indexï¼‰å®ç°åˆ‡æ¢åˆ°ä¸‹ä¸€å¼ å›¾åƒï¼Œå¹¶è°ƒç”¨ st.rerun() åˆ·æ–°é¡µé¢ã€‚

æ•°æ®é›†æ„å»ºéƒ¨åˆ†
åˆ›å»ºæ•°æ®é›†çš„ä¸»è¦å‡½æ•°ï¼šcreate_dataset
è¿™ä¸€éƒ¨åˆ†çš„ä»£ç é€šå¸¸ä½äºç”¨äºæ¨¡å‹è®­ç»ƒçš„æ¨¡å—ä¸­ï¼ˆä¾‹å¦‚ prelabel/model_based/YOLO/dataset.pyï¼‰ï¼Œä¸»è¦æµç¨‹å¦‚ä¸‹ï¼š

æå–æ ‡æ³¨ä¿¡æ¯
é€šè¿‡è°ƒç”¨ db_to_metadata å‡½æ•°ï¼Œä» SQLite æ•°æ®åº“ä¸­æå–æ‰€æœ‰æ ‡æ³¨è®°å½•ï¼Œå°†å®ƒä»¬è½¬æ¢æˆä¸€ä¸ª JSON æ ¼å¼çš„å…ƒæ•°æ®æ–‡ä»¶ã€‚æ¯æ¡è®°å½•åŒ…å«äº†å›¾åƒè·¯å¾„å’Œå¯¹åº”çš„ç¼ºé™·è¾¹ç•Œæ¡†ä¿¡æ¯ã€‚
æ•°æ®é›†åˆ’åˆ†
åˆ©ç”¨ train_test_split å°†æ•°æ®åˆ†ä¸ºè®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†ã€‚åˆ’åˆ†æ¯”ä¾‹é€šå¸¸æ˜¯ 70% è®­ç»ƒã€20% éªŒè¯ã€10% æµ‹è¯•ã€‚
å›¾åƒå¢å¼ºä¸é¢„å¤„ç†
å¯¹äºæ¯ä¸ªæ•°æ®é¡¹ï¼Œè¯»å–å›¾åƒæ–‡ä»¶ï¼Œè°ƒç”¨ get_diff_mapï¼ˆå¦‚æœä½¿ç”¨å·®åˆ†å›¾ä½œä¸ºè¾“å…¥ï¼‰å’Œå›¾åƒå¢å¼ºå‡½æ•°ï¼ˆå¦‚ process_and_augment_imagesï¼‰ã€‚
å›¾åƒå¢å¼ºä¸»è¦ä½¿ç”¨äº† albumentations åº“ï¼Œå®ç°éšæœºæ—‹è½¬ã€ç¿»è½¬ã€ä»¿å°„å˜æ¢ç­‰ï¼Œä»è€Œå¢åŠ æ•°æ®å¤šæ ·æ€§ï¼Œæ‰©å……è®­ç»ƒæ ·æœ¬æ•°é‡ã€‚
å¢å¼ºåçš„å›¾åƒä¼šä¿å­˜ä¸º PNG æ–‡ä»¶ï¼ŒåŒæ—¶ç”Ÿæˆå¯¹åº”çš„æ ‡æ³¨æ–‡æœ¬æ–‡ä»¶ï¼Œæ–‡æœ¬ä¸­è®°å½•äº†æ¯ä¸ªæ ‡æ³¨æ¡†çš„åæ ‡ï¼ˆè½¬æ¢ä¸ºç›¸å¯¹äºå›¾åƒå°ºå¯¸çš„ç™¾åˆ†æ¯”ï¼‰ã€‚
æ•°æ®é›†æ£€æŸ¥
æœ€åï¼Œè°ƒç”¨ dataset_checker å¯¹æ•°æ®é›†ç›®å½•è¿›è¡Œæ‰«æï¼Œæ£€æŸ¥æ˜¯å¦æœ‰å›¾åƒæ–‡ä»¶ç¼ºå¤±æˆ–æ ‡æ³¨æ–‡ä»¶ä¸ºç©ºï¼Œç¡®ä¿æ•°æ®é›†å®Œæ•´æ— è¯¯ã€‚
æ•°æ®é›†æ„å»ºç›®çš„
æ•´ä¸ªæ•°æ®é›†æ„å»ºæµç¨‹çš„ç›®æ ‡æ˜¯å°†ä»å‰ç«¯è·å¾—çš„æ ‡æ³¨æ•°æ®ï¼ˆä¿å­˜åœ¨ SQLite ä¸­ï¼‰è½¬æ¢æˆç¬¦åˆ YOLO æ¨¡å‹è®­ç»ƒè¦æ±‚çš„æ ¼å¼ï¼ŒåŒ…æ‹¬å›¾åƒæ–‡ä»¶å’Œå¯¹åº”çš„æ ‡æ³¨ï¼ˆé€šå¸¸ä¸ºæ–‡æœ¬æ ¼å¼ï¼‰ï¼ŒåŒæ—¶é€šè¿‡å›¾åƒå¢å¼ºæ¥æé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚



æ€»ç»“
å‰ç«¯å±•ç¤ºä¸äººå·¥æ ‡æ³¨
å‰ç«¯éƒ¨åˆ†ä¸»è¦é€šè¿‡ Streamlit å’Œ Label Studio ç»„ä»¶å®ç°ã€‚ä»£ç å…ˆåŠ è½½å›¾åƒï¼ˆç»è¿‡é¢„å¤„ç†ä¸å·®åˆ†è®¡ç®—ï¼‰ï¼Œæ„é€ ä»»åŠ¡å¹¶å±•ç¤ºç»™ç”¨æˆ·ï¼Œç”¨æˆ·å¯ä»¥ä¿®æ”¹é¢„æ ‡æ³¨ç»“æœï¼Œæœ€ç»ˆå°†æ ‡æ³¨ç»“æœä»¥ JSON æ ¼å¼è¿”å›ã€‚

æ•°æ®å­˜å‚¨ä¸æ•°æ®é›†æ„å»º
ç”¨æˆ·æäº¤çš„æ ‡æ³¨æ•°æ®è¢«ä¿å­˜åˆ° SQLite æ•°æ®åº“ä¸­ï¼Œé€šè¿‡å‡½æ•° save_json_to_sqlite å®ç°ï¼›åŒæ—¶ï¼Œé€šè¿‡ä»æ•°æ®åº“ä¸­æå–æ ‡æ³¨ä¿¡æ¯æ„å»ºå…ƒæ•°æ®ï¼Œåˆ©ç”¨æ•°æ®é›†æ„å»ºä»£ç å¯¹å›¾åƒè¿›è¡Œåˆ’åˆ†å’Œå¢å¼ºï¼Œç”Ÿæˆç”¨äº YOLO æ¨¡å‹è®­ç»ƒçš„å®Œæ•´æ•°æ®é›†ã€‚



åœ¨ save_json_to_sqlite ä¸­ï¼Œå½“ä½ ä¼ å…¥ä¸€ä¸ª img_pathï¼ˆå®é™…ä¸Šå°±æ˜¯ image_pathï¼‰æ—¶ï¼Œå‡½æ•°ä¼šå…ˆæ£€æŸ¥æ•°æ®åº“ä¸­æ˜¯å¦å·²æœ‰è¯¥ image_path å¯¹åº”çš„è®°å½•ï¼š

å¦‚æœå­˜åœ¨ä¸”å†…å®¹ä¸€è‡´ï¼Œåˆ™ä¸åšæ›´æ–°ï¼›
å¦‚æœå­˜åœ¨ä½†å†…å®¹ä¸åŒï¼Œåˆ™æ›´æ–°è¿™æ¡è®°å½•ï¼›
å¦‚æœä¸å­˜åœ¨ï¼Œåˆ™æ’å…¥æ–°çš„è®°å½•ã€‚
åœ¨ fetch_results ä¸­ï¼ŒåŒæ ·ä½¿ç”¨ä¼ å…¥çš„ image_path å»æ•°æ®åº“ä¸­æŸ¥æ‰¾å¯¹åº”çš„æ ‡æ³¨ç»“æœï¼Œå¹¶è¿”å›å®ƒã€‚

å› æ­¤ï¼Œä¸ºäº†èƒ½å¤Ÿæ­£ç¡®æŸ¥æ‰¾å’Œæ›´æ–°ç›¸åº”çš„è®°å½•ï¼Œè¿™ä¸¤ä¸ªå‡½æ•°ä¸­ä½¿ç”¨çš„ image_path åº”è¯¥æ˜¯åŒæ ·çš„â€”â€”ä¹Ÿå°±æ˜¯ä»£è¡¨åŒä¸€å¼ å›¾ç‰‡çš„å”¯ä¸€æ ‡è¯†ç¬¦ã€‚ç®€å•æ¥è¯´ï¼Œæ˜¯çš„ï¼Œå®ƒä»¬æŒ‡ä»£çš„åº”è¯¥æ˜¯åŒæ ·çš„ä¸œè¥¿ã€‚


1. é¡µé¢åˆå§‹åŒ–ä¸çŠ¶æ€ç®¡ç†
é¡µé¢è®¾ç½®ä¸ Session State
åœ¨ app.py å¼€å¤´ï¼Œä¼šè°ƒç”¨

python
è¤‡è£½
st.set_page_config(layout='wide')
è®¾ç½®é¡µé¢å¸ƒå±€ä¸ºå®½å±æ¨¡å¼ã€‚æ¥ç€ï¼Œé€šè¿‡æ£€æŸ¥ st.session_state ä¸­æ˜¯å¦å­˜åœ¨ 'previous_results_raw'ã€'image_index' å’Œ 'lot_index'ï¼Œæ¥åˆå§‹åŒ–è¿™äº›çŠ¶æ€å˜é‡ã€‚è¿™äº›å˜é‡ç”¨äºè®°å½•å½“å‰å±•ç¤ºçš„å›¾åƒç´¢å¼•ã€æ‰¹æ¬¡ï¼ˆlotï¼‰ç´¢å¼•ä»¥åŠä¸Šä¸€æ¬¡æäº¤çš„æ ‡æ³¨ç»“æœï¼Œç¡®ä¿é¡µé¢åˆ·æ–°æ—¶çŠ¶æ€èƒ½å¤Ÿä¿æŒåŒæ­¥ã€‚

æ•°æ®åº“åˆå§‹åŒ–
ä»£ç åœ¨å¯åŠ¨æ—¶ä¼šæ£€æŸ¥å¹¶åˆ›å»º SQLite æ•°æ®åº“å’Œå¯¹åº”çš„è¡¨ï¼š

python
è¤‡è£½
conn = sqlite3.connect(db_path)
cursor = conn.cursor()
cursor.execute('''
CREATE TABLE IF NOT EXISTS results_table (
    id INTEGER PRIMARY KEY,
    image_path TEXT,
    results_json TEXT
)
''')
conn.commit()
conn.close()
è¿™é‡Œ results_table è¡¨ä¸­ä½¿ç”¨ image_path ä½œä¸ºå”¯ä¸€æ ‡è¯†ï¼Œç”¨æ¥ä¿å­˜æ¯å¼ å›¾åƒå¯¹åº”çš„æ ‡æ³¨æ•°æ®ï¼ˆJSON æ ¼å¼ï¼‰ã€‚



2. ä¾§è¾¹æ é€‰æ‹©ä¸å›¾åƒç´¢å¼•æ›´æ–°
æ•°æ®ç›®å½•ä¸æ‰¹æ¬¡ï¼ˆlotï¼‰é€‰æ‹©
ä»£ç é€šè¿‡ os.listdir(data_dir) è·å–æ•°æ®ç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶å¤¹ï¼Œå¹¶è¿‡æ»¤å‡ºæ‰¹æ¬¡æ–‡ä»¶å¤¹ï¼ˆæ’é™¤å¦‚ log ç›®å½•ï¼‰ã€‚æ¥ç€ä½¿ç”¨

python
è¤‡è£½
st.sidebar.selectbox('Select Lot ID', lot_ids, index=st.session_state.lot_index)
è®©ç”¨æˆ·é€‰æ‹©ä¸€ä¸ªæ‰¹æ¬¡ã€‚æ­¤æ—¶æ ¹æ®é€‰ä¸­çš„æ‰¹æ¬¡ IDï¼Œåˆ©ç”¨ get_lrf_file å‡½æ•°è·å–å¯¹åº”çš„ç¼ºé™·æ–‡ä»¶ï¼ˆ.lrfï¼‰ï¼Œå†è°ƒç”¨ get_defect_list å¾—åˆ°å½“å‰æ‰¹æ¬¡ä¸­æ‰€æœ‰ç¼ºé™·å›¾åƒçš„ ID åˆ—è¡¨å’Œç¼ºé™·ç±»å‹ä¿¡æ¯ã€‚

å›¾åƒç´¢å¼•çš„å‰è¿›ä¸åé€€
åœ¨ä¾§è¾¹æ ä¸­è¿˜è®¾ç½®äº†â€œPrevious Imageâ€å’Œâ€œNext Imageâ€æŒ‰é’®ï¼Œç‚¹å‡»åä¼šæ›´æ–° st.session_state.image_indexï¼ˆä»¥åŠåœ¨åˆ°è¾¾è¾¹ç•Œæ—¶æ›´æ–° lot_indexï¼‰ã€‚è¿™æ ·å¯ä»¥æ–¹ä¾¿ç”¨æˆ·æµè§ˆå½“å‰æ‰¹æ¬¡ä¸­çš„æ‰€æœ‰å›¾åƒï¼Œç³»ç»Ÿä¼šæ ¹æ®æ›´æ–°åçš„ç´¢å¼•é‡æ–°åŠ è½½å¯¹åº”å›¾åƒã€‚

å›¾åƒç¼–å·é€‰æ‹©
æ ¹æ®æ›´æ–°åçš„ç´¢å¼•ï¼Œé€šè¿‡ st.sidebar.selectbox('Select Image ID', defect_images_id_list, index=st.session_state.image_index) æ¥ç¡®å®šå½“å‰è¦å±•ç¤ºçš„å›¾åƒç¼–å·ã€‚


3. å›¾åƒé¢„å¤„ç†ä¸ä»»åŠ¡æ„å»º
å‚æ•°è®¾ç½®
ç”¨æˆ·å¯ä»¥åœ¨ä¾§è¾¹æ é€šè¿‡æ»‘å—è°ƒæ•´å„é¡¹å‚æ•°ï¼Œå¦‚ vmin_levelï¼ˆç”¨äºé¢œè‰²æ˜ å°„ï¼‰ã€max_featuresã€max_shiftã€ransac_reproj_thresholdã€crop_sizeï¼ˆç”¨äºåç»­ç”Ÿæˆé¢„æ ‡æ³¨çš„æ¡†å¤§å°ï¼‰ä»¥åŠ conv_kernel_sizeï¼ˆç”¨äºå·ç§¯æ»¤æ³¢ï¼‰ã€‚è¿™äº›å‚æ•°å°†å½±å“åç»­å›¾åƒé…å‡†ä¸å·®åˆ†å›¾ç”Ÿæˆçš„æ•ˆæœã€‚

è·å–å¤„ç†åçš„å›¾åƒ
è°ƒç”¨å‡½æ•° get_image_pair_for_studio_input åˆ†åˆ«ä¸ºä¸¤ç±»å›¾åƒï¼ˆæ ‡è®°ä¸º "T" å’Œ "Rt"ï¼‰è¿›è¡Œå¤„ç†ï¼š

å†…éƒ¨æµç¨‹ï¼š

æ ¹æ®é€‰ä¸­çš„æ•°æ®ç›®å½•ã€æ‰¹æ¬¡ ID ä¸å›¾åƒç¼–å·ï¼Œå®šä½å­˜æ”¾å›¾åƒçš„ç›®å½•ã€‚
è°ƒç”¨ load_defect_pair è·å–å‚è€ƒå›¾å’Œæµ‹è¯•å›¾ï¼ˆåŒæ—¶åˆ¤æ–­æ˜¯å¦éœ€è¦ä½¿ç”¨ä¸­ä½å›¾ä½œä¸ºå‚è€ƒï¼‰ã€‚
é€šè¿‡ get_diff_map å¯¹ä¸¤å¹…å›¾åƒè¿›è¡Œé…å‡†å’Œå·®åˆ†è®¡ç®—ï¼Œè·å¾—å¯¹é½åçš„å›¾åƒã€å·®åˆ†å›¾ä»¥åŠç›¸å…³å…ƒæ•°æ®ï¼ˆä¾‹å¦‚æœ€å¤§ã€æœ€å°å·®åˆ†ç‚¹çš„ä½ç½®ï¼‰ã€‚
ä½¿ç”¨ apply_colormap å¯¹å›¾åƒè¿›è¡Œé¢œè‰²æ˜ å°„ï¼Œå·®åˆ†å›¾ç»è¿‡å·ç§¯æ»¤æ³¢å¤„ç†åè½¬æ¢æˆ Base64 å­—ç¬¦ä¸²ã€‚
æœ€ç»ˆè¿”å›ä¸€ä¸ªåŒ…å« Base64 ç¼–ç å›¾åƒï¼ˆé€šå¸¸ä¸ºå‚è€ƒå›¾ã€æµ‹è¯•å›¾å’Œå¤„ç†åçš„å·®åˆ†å›¾ï¼‰çš„åˆ—è¡¨ï¼Œä»¥åŠå·®åˆ†å›¾çš„å…ƒæ•°æ®ã€‚

ä»»åŠ¡æ•°æ®æ„å»º
å°† â€œTâ€ ç±»å›¾åƒå’Œ â€œRtâ€ ç±»å›¾åƒçš„ Base64 å­—ç¬¦ä¸²åˆ†åˆ«ç»„åˆæˆä¸€ä¸ª images_base64 åˆ—è¡¨ï¼ˆæ€»å…±6ä¸ªå›¾åƒè§†å›¾ï¼‰ï¼ŒåŒæ—¶æ„é€ ä¸€ä¸ª metadatas åˆ—è¡¨ä¿å­˜ç›¸åº”çš„å…ƒæ•°æ®ã€‚æ¥ç€ï¼Œè°ƒç”¨ task_generator å‡½æ•°ç”Ÿæˆä»»åŠ¡ï¼š

å¦‚æœåœ¨æ•°æ®åº“ä¸­æ²¡æœ‰è¯¥å›¾åƒçš„å·²æœ‰æ ‡æ³¨ï¼ˆé€šè¿‡è°ƒç”¨ fetch_results æ£€æŸ¥ï¼‰ï¼Œåˆ™è°ƒç”¨ generate_prelabels è‡ªåŠ¨ç”Ÿæˆé¢„æ ‡æ³¨ï¼ˆä¾‹å¦‚åŸºäº YOLO æˆ– minmax æ–¹æ³•ï¼‰ã€‚
å¦‚æœå·²æœ‰æ ‡æ³¨ï¼Œåˆ™å°†å…¶ç›´æ¥ä½œä¸ºä»»åŠ¡çš„ä¸€éƒ¨åˆ†å±•ç¤ºï¼Œæ–¹ä¾¿ç”¨æˆ·ä¿®æ”¹ã€‚
æœ€ç»ˆï¼Œä»»åŠ¡æ•°æ®æ ¼å¼ä¸ºä¸€ä¸ªå­—å…¸ï¼Œå†…å®¹å¤§è‡´å¦‚ä¸‹ï¼š


task = {
    'completions': [],
    'predictions': [{
        'model_version': 'prelabeling' æˆ– 'existing_labels',
        'result': annotations  # æ ‡æ³¨ä¿¡æ¯ï¼ŒåŒ…å«æ¯ä¸ªå›¾åƒçš„çŸ©å½¢æ¡†åŠæ ‡ç­¾
    }],
    'id': 1,
    'data': {
        'image1': "data:image/jpeg;base64,...",
        'image2': "data:image/jpeg;base64,...",
        ...  # å…¶ä»–å›¾åƒè§†å›¾
    }
}


4. å‰ç«¯æ ‡æ³¨ä¸æäº¤
Label Studio ç»„ä»¶è°ƒç”¨
è°ƒç”¨

python
è¤‡è£½
results_raw = st_labelstudio(config, interfaces, user, task_generator(...))
å°†ä»»åŠ¡ä¼ ç»™ Label Studio ç»„ä»¶ã€‚åœ¨è¿™ä¸ªæ ‡æ³¨ç•Œé¢ä¸­ï¼Œç”¨æˆ·å¯ä»¥æŸ¥çœ‹æ‰€æœ‰é¢„å¤„ç†å¥½çš„å›¾åƒå’Œé¢„æ ‡æ³¨ç»“æœï¼Œå¹¶å¯¹é¢„æ ‡æ³¨çš„ç¼ºé™·è¾¹ç•Œæ¡†è¿›è¡Œå¾®è°ƒæˆ–ä¿®æ”¹ã€‚

æ ‡æ³¨æäº¤ä¸ç»“æœæ›´æ–°
å½“ç”¨æˆ·ç‚¹å‡»â€œSubmitâ€åï¼Œç»„ä»¶ä¼šè¿”å›æ ‡æ³¨ç»“æœï¼ˆJSON æ ¼å¼ï¼‰ï¼Œå­˜æ”¾åœ¨ results_raw ä¸­ã€‚æ¥ä¸‹æ¥ï¼š

é€šè¿‡å‡½æ•° has_results_raw_changed æ£€æŸ¥æ­¤æ¬¡æäº¤çš„æ ‡æ³¨æ•°æ®ä¸ä¹‹å‰æ˜¯å¦å‘ç”Ÿäº†å˜åŒ–ã€‚
å¦‚æœå˜åŒ–å­˜åœ¨ï¼Œåˆ™è°ƒç”¨ sync_labels_across_3images å°†éƒ¨åˆ†æ ‡æ³¨ï¼ˆä¾‹å¦‚ image3 çš„æ ‡æ³¨ï¼‰åŒæ­¥åˆ°å…¶å®ƒè§†å›¾ï¼Œç¡®ä¿å‰ç«¯æ˜¾ç¤ºçš„ä¸€è‡´æ€§ã€‚
æœ€åï¼Œè°ƒç”¨ save_json_to_sqlite å°†æœ€ç»ˆçš„æ ‡æ³¨ç»“æœå­˜å…¥æ•°æ®åº“ä¸­ï¼Œå¹¶æ›´æ–° image_indexï¼ˆè‡ªåŠ¨åˆ‡æ¢åˆ°ä¸‹ä¸€å¼ å›¾åƒï¼‰ï¼Œæœ€åé€šè¿‡ st.rerun() åˆ·æ–°é¡µé¢ã€‚


5. æ•´ä¸ªå‰ç«¯å·¥ä½œæµç¨‹æ€»ç»“
åˆå§‹åŒ–ä¸çŠ¶æ€ç®¡ç†ï¼šé¡µé¢åŠ è½½æ—¶è®¾ç½®å¥½æ˜¾ç¤ºæ ¼å¼å’Œåˆå§‹çŠ¶æ€ï¼ˆå½“å‰å›¾åƒã€æ‰¹æ¬¡ä»¥åŠæ•°æ®åº“åˆå§‹åŒ–ï¼‰ã€‚
ä¾§è¾¹æ é€‰æ‹©ï¼šç”¨æˆ·åœ¨ä¾§è¾¹æ é€‰æ‹©æ‰¹æ¬¡å’Œå›¾åƒç¼–å·ï¼Œå¹¶é€šè¿‡æŒ‰é’®æ§åˆ¶å‰è¿›/åé€€ï¼Œæ›´æ–° Session çŠ¶æ€ã€‚
å›¾åƒåŠ è½½ä¸é¢„å¤„ç†ï¼šæ ¹æ®é€‰å®šçš„å›¾åƒç¼–å·ï¼Œè°ƒç”¨å›¾åƒé¢„å¤„ç†å‡½æ•°è·å–å‚è€ƒå›¾ã€æµ‹è¯•å›¾åŠå·®åˆ†å›¾ï¼Œå¤„ç†åçš„å›¾åƒä»¥ Base64 å½¢å¼ä¿å­˜ã€‚
ä»»åŠ¡æ„å»ºä¸é¢„æ ‡æ³¨ç”Ÿæˆï¼šåˆ©ç”¨ task_generator æ„å»ºä»»åŠ¡æ•°æ®ï¼Œä»»åŠ¡ä¸­åŒ…å«å›¾åƒå’Œé¢„æ ‡æ³¨ä¿¡æ¯ï¼Œè‹¥å·²æœ‰æ ‡æ³¨åˆ™ç›´æ¥åŠ è½½ï¼Œå¦åˆ™ç”Ÿæˆé¢„æ ‡æ³¨ã€‚
äº¤äº’æ ‡æ³¨ä¸ç»“æœæäº¤ï¼šç”¨æˆ·åœ¨ Label Studio ç»„ä»¶ä¸­ä¿®æ”¹æ ‡æ³¨åï¼Œæäº¤ç»“æœï¼›ç³»ç»Ÿæ£€æŸ¥æ•°æ®å˜åŒ–ååŒæ­¥ã€ä¿å­˜ï¼Œå¹¶è‡ªåŠ¨åˆ‡æ¢åˆ°ä¸‹ä¸€å›¾åƒï¼Œæ•´ä¸ªé¡µé¢åˆ·æ–°æ›´æ–°æ˜¾ç¤ºã€‚
é€šè¿‡è¿™ä¸€ç³»åˆ—æ­¥éª¤ï¼Œå‰ç«¯å®ç°äº†ä»å›¾åƒåŠ è½½ã€é¢„æ ‡æ³¨ç”Ÿæˆï¼Œåˆ°ç”¨æˆ·äº¤äº’å’Œæ ‡æ³¨ç»“æœå­˜å‚¨çš„å®Œæ•´å·¥ä½œæµç¨‹ï¼Œä½¿å¾—ç¼ºé™·æ ‡æ³¨è¿‡ç¨‹æ—¢è‡ªåŠ¨åŒ–åˆä¾¿äºäººå·¥æ ¡æ­£ã€‚


Lot ID
è¡¨ç¤ºä¸€ä¸ªæ‰¹æ¬¡æˆ–ä¸€ç»„å›¾åƒçš„æ ‡è¯†ç¬¦ã€‚å®ƒé€šå¸¸å¯¹åº”æ•°æ®ç›®å½•ä¸­çš„ä¸€ä¸ªæ–‡ä»¶å¤¹ï¼Œé‡Œé¢åŒ…å«äº†åŒä¸€æ‰¹æ¬¡çš„æ‰€æœ‰å›¾åƒå’Œç›¸å…³ç¼ºé™·ä¿¡æ¯ã€‚é€šè¿‡é€‰æ‹©ä¸åŒçš„ Lot IDï¼Œä½ å°±å¯ä»¥åˆ‡æ¢åˆ°ä¸åŒçš„æ•°æ®æ‰¹æ¬¡ã€‚

Image ID
è¡¨ç¤ºåœ¨æŸä¸ªç‰¹å®šæ‰¹æ¬¡ï¼ˆLotï¼‰ä¸­çš„å•å¼ å›¾åƒçš„æ ‡è¯†ç¬¦ã€‚å®ƒç”¨æ¥ç¡®å®šå…·ä½“å“ªå¼ å›¾åƒéœ€è¦å¤„ç†ã€å±•ç¤ºæˆ–è€…æ ‡æ³¨ã€‚æ¯”å¦‚åœ¨ä¸€ä¸ªæ‰¹æ¬¡å†…ï¼Œå¯èƒ½æœ‰æ•°ç™¾å¼ å›¾åƒï¼Œæ¯å¼ å›¾åƒéƒ½æœ‰å”¯ä¸€çš„ Image IDï¼Œç”¨æ¥åŒºåˆ†è¿™äº›å›¾åƒã€‚


ä¸‹é¢è¯¦ç»†è¯´æ˜â€œå›¾åƒé¢„å¤„ç†ä¸ä»»åŠ¡æ„å»ºâ€è¿™éƒ¨åˆ†çš„ä»£ç é€»è¾‘å’Œæµç¨‹ï¼Œå¸®åŠ©ä½ ç†è§£ç³»ç»Ÿå¦‚ä½•ä»åŸå§‹å›¾åƒç”Ÿæˆé€‚åˆå‰ç«¯æ ‡æ³¨ä»»åŠ¡çš„æ•°æ®ã€‚

1. å›¾åƒé¢„å¤„ç†
a. å‚æ•°è®¾ç½®
åœ¨ä¾§è¾¹æ ä¸­ï¼Œç”¨æˆ·å¯ä»¥é€šè¿‡æ»‘å—è®¾ç½®å¤šä¸ªå…³é”®å‚æ•°ï¼Œä¾‹å¦‚ï¼š

vmin_levelï¼šç”¨äºè®¾ç½®å·®åˆ†å›¾çš„æœ€å°é˜ˆå€¼ï¼Œè¿™ä¼šå½±å“é¢œè‰²æ˜ å°„çš„å¯¹æ¯”åº¦ã€‚
max_featuresã€max_shiftã€ransac_reproj_thresholdï¼šè¿™äº›å‚æ•°æ§åˆ¶å›¾åƒé…å‡†æ—¶ï¼ˆæ¯”å¦‚ä½¿ç”¨ SIFT æˆ– Correlation æ–¹æ³•ï¼‰çš„ç‰¹å¾æå–å’Œå¯¹é½è¿‡ç¨‹ã€‚
conv_kernel_sizeï¼šè®¾ç½®å·ç§¯æ ¸çš„å¤§å°ï¼Œç”¨äºå¯¹å·®åˆ†å›¾è¿›è¡Œå¹³æ»‘å¤„ç†ã€‚
b. è·å–å›¾åƒå¯¹ï¼ˆå‚è€ƒå›¾ã€æµ‹è¯•å›¾å’Œå·®åˆ†å›¾ï¼‰
è°ƒç”¨å‡½æ•° get_image_pair_for_studio_input æ¥å®ç°è¿™ä¸€è¿‡ç¨‹ã€‚å…¶ä¸»è¦é€»è¾‘å¦‚ä¸‹ï¼š

ç¡®å®šå›¾åƒç›®å½•
æ ¹æ®ä¼ å…¥çš„å‚æ•°ï¼ˆå¦‚æ•°æ®ç›®å½•ã€Lot IDã€Image ID å’Œå›¾åƒç±»å‹â€œTâ€æˆ–â€œRtâ€ï¼‰ï¼Œæ„å»ºå›¾åƒæ‰€åœ¨çš„ç›®å½•è·¯å¾„ã€‚

åŠ è½½å›¾åƒ

è°ƒç”¨ load_defect_pairï¼šåœ¨æŒ‡å®šç›®å½•ä¸‹ï¼Œæ ¹æ®ç¼ºé™·ç¼–å·åŠ è½½ç›¸åº”çš„æµ‹è¯•å›¾å’Œå‚è€ƒå›¾ã€‚è¯¥å‡½æ•°ä¼šæ ¹æ®æ–‡ä»¶ååç¼€ï¼ˆä¾‹å¦‚ç›´æ¥ç¼–å·ã€å¸¦ Uã€L ç­‰åç¼€ï¼‰åˆ¤æ–­å“ªå¼ å›¾ç‰‡ä¸ºæµ‹è¯•å›¾ï¼Œå“ªå¼ ä¸ºå‚è€ƒå›¾ã€‚
åˆ¤æ–­æ˜¯å¦å­˜åœ¨å¤šä¸ªå‚è€ƒå›¾ï¼šå¦‚æœæœ‰å¤šä¸ªï¼Œåˆ™é€šå¸¸é‡‡ç”¨ä¸­ä½æ•°å›¾åƒä½œä¸ºå‚è€ƒï¼Œä»¥å‡å°‘å™ªå£°çš„å½±å“ã€‚
å›¾åƒå¯¹é½ä¸å·®åˆ†è®¡ç®—

è°ƒç”¨ get_diff_mapï¼šå¯¹é½å‚è€ƒå›¾å’Œæµ‹è¯•å›¾ï¼Œè®¡ç®—å‡ºé…å‡†åçš„å·®åˆ†å›¾ã€‚æ­¤å‡½æ•°ä¼šè¿”å›å¯¹é½åçš„å‚è€ƒå›¾ã€æµ‹è¯•å›¾ã€å·®åˆ†å›¾åŠä¸€äº›å…ƒæ•°æ®ï¼ˆä¾‹å¦‚æœ€å¤§ã€æœ€å°å·®åˆ†ç‚¹çš„ä½ç½®ã€å¹³ç§»é‡ã€RMSE ç­‰ï¼‰ã€‚
å›¾åƒåå¤„ç†

åˆ†åˆ«è°ƒç”¨ apply_colormap å°†å‚è€ƒå›¾å’Œæµ‹è¯•å›¾ä»¥ç°åº¦ï¼ˆgrayï¼‰æ–¹å¼æ˜ å°„ï¼ŒåŒæ—¶å¯¹å·®åˆ†å›¾ä½¿ç”¨â€œseismicâ€é¢œè‰²æ˜ å°„ï¼ˆå¹¶æ ¹æ® vmin_level è°ƒæ•´å¯¹æ¯”åº¦ï¼‰ã€‚
å¯¹å·®åˆ†å›¾å†è¿›è¡Œå·ç§¯æ»¤æ³¢ï¼ˆè°ƒç”¨ conv_kernel ç”Ÿæˆå·ç§¯æ ¸ï¼Œåˆ©ç”¨ OpenCV çš„ cv2.filter2D è¿›è¡Œå¹³æ»‘ï¼‰ï¼Œå¢å¼ºå±€éƒ¨ç‰¹å¾æˆ–æ¶ˆé™¤å™ªå£°ã€‚
è½¬æ¢ä¸º Base64 ç¼–ç 

æœ€åï¼Œè°ƒç”¨ numpy_to_base64 å°†å¤„ç†åçš„å›¾åƒï¼ˆå‚è€ƒå›¾ã€æµ‹è¯•å›¾ä»¥åŠç»è¿‡å·ç§¯å¤„ç†çš„å·®åˆ†å›¾ï¼‰è½¬æ¢ä¸º Base64 å­—ç¬¦ä¸²ï¼Œæ–¹ä¾¿åœ¨å‰ç«¯ç›´æ¥ä»¥ HTML çš„ <img> æ ‡ç­¾åµŒå…¥æ˜¾ç¤ºã€‚
å‡½æ•°è¿”å›çš„ç»“æœé€šå¸¸ä¸ºä¸€ä¸ªåˆ—è¡¨ï¼ˆåŒ…å«ç»è¿‡å¤„ç†çš„å›¾åƒçš„ Base64 å­—ç¬¦ä¸²ï¼‰å’Œä¸€ä¸ªå…ƒæ•°æ®å­—å…¸ï¼ˆåŒ…å«é…å‡†å’Œå¹³ç§»ç­‰ä¿¡æ¯ï¼‰ã€‚

2. ä»»åŠ¡æ„å»º
ä»»åŠ¡æ„å»ºçš„ä¸»è¦ç›®æ ‡æ˜¯å°†é¢„å¤„ç†å¥½çš„å›¾åƒæ•°æ®ä»¥åŠè‡ªåŠ¨ç”Ÿæˆçš„é¢„æ ‡æ³¨ä¿¡æ¯æ•´åˆåˆ°ä¸€ä¸ªä»»åŠ¡ï¼ˆtaskï¼‰æ•°æ®ç»“æ„ä¸­ï¼Œä¾› Label Studio ç»„ä»¶è°ƒç”¨å±•ç¤ºå’Œä¿®æ”¹ã€‚

a. æ„é€ å›¾åƒæ•°æ®
åœ¨å‰ç«¯ä¸­ï¼Œä¼šåˆ†åˆ«è°ƒç”¨ get_image_pair_for_studio_input å¤„ç†ä¸¤ç±»å›¾åƒï¼ˆä¾‹å¦‚â€œTâ€å’Œâ€œRtâ€ï¼‰ï¼Œå¹¶å°†ä¸¤éƒ¨åˆ†çš„ Base64 å­—ç¬¦ä¸²ç»„åˆæˆä¸€ä¸ªåˆ—è¡¨ã€‚
å¦‚ï¼š
python
è¤‡è£½
images_base64 = [T_images[0], T_images[1], T_images[2],
                 Rt_images[0], Rt_images[1], Rt_images[2]]
è¿™6ä¸ªå›¾åƒåˆ†åˆ«å¯¹åº”ä¸åŒè§†å›¾ï¼ˆä¾‹å¦‚ï¼šimage1ï½image6ï¼‰ï¼Œç”¨äºå‰ç«¯å±•ç¤ºå‚è€ƒå›¾ã€æµ‹è¯•å›¾å’Œå·®åˆ†å›¾ã€‚
b. ç”Ÿæˆä»»åŠ¡å­—å…¸ï¼ˆTaskï¼‰
è°ƒç”¨ task_generator å‡½æ•°ï¼Œè¯¥å‡½æ•°è´Ÿè´£æ„é€ ä¼ é€’ç»™ Label Studio çš„ä»»åŠ¡æ•°æ®ã€‚å…¶ä¸»è¦é€»è¾‘åŒ…æ‹¬ï¼š

å®šä¹‰æ•°æ®ç»“æ„
æ„é€ ä¸€ä¸ªå­—å…¸ taskï¼ŒåŒ…å«ï¼š

data å­—æ®µï¼šé”®ä¸º image1 è‡³ image6ï¼Œå¯¹åº”çš„å€¼ä¸º Base64 ç¼–ç çš„å›¾åƒå­—ç¬¦ä¸²ï¼Œå½¢å¦‚ "data:image/jpeg;base64,..."ã€‚
completions å’Œ predictionsï¼šè¿™äº›å­—æ®µç”¨æ¥å­˜å‚¨ç”¨æˆ·çš„æ ‡æ³¨ç»“æœå’Œé¢„æ ‡æ³¨ä¿¡æ¯ã€‚
åˆ¤æ–­å·²æœ‰æ ‡æ³¨ä¸ç”Ÿæˆé¢„æ ‡æ³¨

å…ˆé€šè¿‡ fetch_results å‡½æ•°æ£€æŸ¥æ•°æ®åº“ä¸­æ˜¯å¦å·²æœ‰è¯¥å›¾åƒçš„æ ‡æ³¨ç»“æœã€‚å¦‚æœå­˜åœ¨ï¼Œåˆ™å°†è¿™äº›â€œexisting_labelsâ€ä¼ é€’ç»™ä»»åŠ¡ã€‚
å¦‚æœæ²¡æœ‰ï¼Œåˆ™è°ƒç”¨ generate_prelabels ç”Ÿæˆé¢„æ ‡æ³¨ï¼š
é¢„æ ‡æ³¨æ–¹æ³•å¯ä»¥æ˜¯åŸºäº YOLO æ¨¡å‹çš„ç›®æ ‡æ£€æµ‹ï¼ˆè°ƒç”¨ YOLO_prelabelï¼‰æˆ–åŸºäºå·®åˆ†å›¾çš„ minmax ç­–ç•¥ï¼ˆè°ƒç”¨ minmax_prelabelï¼‰ã€‚
é¢„æ ‡æ³¨ç”Ÿæˆçš„ç»“æœï¼ˆbounding boxes åŠæ ‡ç­¾ï¼‰å°†ä»¥ Label Studio è§„å®šçš„æ ¼å¼ä¿å­˜ï¼Œå¹¶æ”¾å…¥ predictions å­—æ®µä¸­ã€‚
è¿”å›ä»»åŠ¡æ•°æ®
æœ€ç»ˆï¼Œtask_generator è¿”å›ä¸€ä¸ªå®Œæ•´çš„ä»»åŠ¡å­—å…¸ï¼Œè¯¥å­—å…¸æ—¢åŒ…å«å›¾åƒæ•°æ®ï¼Œä¹ŸåŒ…å«é¢„æ ‡æ³¨æˆ–å·²æœ‰æ ‡æ³¨ä¿¡æ¯ã€‚

c. å‰ç«¯äº¤äº’
åœ¨ app.py ä¸­ï¼Œæœ€ç»ˆè°ƒç”¨ï¼š
python
è¤‡è£½
results_raw = st_labelstudio(config, interfaces, user, task_generator(...))
å°†æ„é€ å¥½çš„ä»»åŠ¡ä¼ é€’ç»™ Label Studio ç»„ä»¶ã€‚ç”¨æˆ·åœ¨è¯¥ç•Œé¢ä¸Šå¯ä»¥æŸ¥çœ‹æ‰€æœ‰å›¾åƒåŠé¢„æ ‡æ³¨ï¼Œå¹¶å¯¹æ ‡æ³¨ç»“æœè¿›è¡Œä¿®æ”¹ï¼Œæäº¤åä¼šå¾—åˆ°æ›´æ–°åçš„æ ‡æ³¨æ•°æ®ã€‚
æ€»ç»“
å›¾åƒé¢„å¤„ç†ï¼š

æ ¹æ®é€‰å®šçš„æ‰¹æ¬¡ï¼ˆLot IDï¼‰å’Œå›¾åƒç¼–å·ï¼ˆImage IDï¼‰ï¼Œç³»ç»Ÿé€šè¿‡ä¸€ç³»åˆ—å‡½æ•°å®Œæˆå›¾åƒåŠ è½½ã€å¯¹é½ã€å·®åˆ†è®¡ç®—ã€é¢œè‰²æ˜ å°„ã€å·ç§¯æ»¤æ³¢ç­‰å¤„ç†ï¼Œå¹¶å°†ç»“æœè½¬æ¢æˆ Base64 æ ¼å¼ï¼Œä¾¿äºåœ¨ç½‘é¡µä¸Šæ˜¾ç¤ºã€‚
ä»»åŠ¡æ„å»ºï¼š

å°†é¢„å¤„ç†åçš„å›¾åƒå’Œè‡ªåŠ¨ç”Ÿæˆçš„é¢„æ ‡æ³¨ï¼ˆæˆ–å·²æœ‰æ ‡æ³¨ï¼‰æ•´åˆåˆ°ä¸€ä¸ªä»»åŠ¡å­—å…¸ä¸­ï¼Œæ ¼å¼ç¬¦åˆ Label Studio çš„è¦æ±‚ã€‚è¯¥ä»»åŠ¡æ•°æ®åŒ…æ‹¬6ä¸ªè§†å›¾ï¼ˆä¾‹å¦‚ image1 è‡³ image6ï¼‰ï¼Œä½¿å¾—ç”¨æˆ·èƒ½å¤Ÿåœ¨å‰ç«¯äº¤äº’å¼åœ°æŸ¥çœ‹ã€ä¿®æ”¹å’Œæäº¤æ ‡æ³¨ç»“æœã€‚
æ•´ä¸ªæµç¨‹ä½¿å¾—åŸå§‹å›¾åƒç»è¿‡é¢„å¤„ç†åè‡ªåŠ¨ç”Ÿæˆåˆæ­¥ç¼ºé™·æ ‡æ³¨ï¼Œå¹¶ä»¥æ˜“äºäº¤äº’çš„å½¢å¼å‘ˆç°åœ¨å‰ç«¯ï¼Œä¸ºåç»­äººå·¥ç¡®è®¤å’Œä¿®æ”¹æä¾›äº†ä¾¿åˆ©ã€‚å¸Œæœ›è¿™ä¸ªè¯¦ç»†çš„è§£é‡Šèƒ½å¸®åŠ©ä½ æ›´å¥½åœ°ç†è§£è¿™éƒ¨åˆ†ä»£ç çš„é€»è¾‘å’Œå®ç°ç»†èŠ‚ï¼



å›¾ç‰‡åœ¨æ ‡æ³¨å‰éœ€è¦ç»è¿‡é¢„å¤„ç†ï¼Œä¸»è¦åŸå› æœ‰ä»¥ä¸‹å‡ ç‚¹ï¼š

çªå‡ºç¼ºé™·ç‰¹å¾
é¢„å¤„ç†ï¼ˆå¦‚å›¾åƒå¯¹é½ã€å·®åˆ†è®¡ç®—å’Œé¢œè‰²æ˜ å°„ï¼‰å¯ä»¥å°†å›¾åƒä¸­çš„ç¼ºé™·åŒºåŸŸæ›´åŠ æ˜æ˜¾åœ°çªå‡ºå‡ºæ¥ã€‚è¿™æ ·æ ‡æ³¨äººå‘˜åœ¨æŸ¥çœ‹æ—¶æ›´å®¹æ˜“å‘ç°å¼‚å¸¸åŒºåŸŸï¼Œä»è€Œæé«˜æ ‡æ³¨çš„å‡†ç¡®æ€§ã€‚

é™ä½å™ªéŸ³ä¸å¹²æ‰°
åŸå§‹å›¾åƒå¯èƒ½å­˜åœ¨å™ªéŸ³ã€äº®åº¦ä¸å‡æˆ–é¢œè‰²åå·®ï¼Œç»è¿‡é¢„å¤„ç†åå¯ä»¥ç»Ÿä¸€å›¾åƒçš„å¯¹æ¯”åº¦ã€äº®åº¦ç­‰å±æ€§ï¼Œå‡å°‘å¹²æ‰°å› ç´ ï¼Œä½¿ç¼ºé™·ä¿¡æ¯æ›´æ¸…æ™°ã€‚

ç»Ÿä¸€å›¾åƒæ ¼å¼
é€šè¿‡é¢„å¤„ç†ï¼Œæ‰€æœ‰å›¾åƒéƒ½ä¼šæŒ‰ç…§ç›¸åŒçš„æ ‡å‡†ï¼ˆå¦‚å°ºå¯¸ã€è‰²å½©ç©ºé—´ï¼‰å¤„ç†åå†è¿›è¡Œæ ‡æ³¨ï¼Œç¡®ä¿ä¸åŒæ¥æºçš„å›¾åƒåœ¨æ ‡æ³¨å¹³å°ä¸Šæ˜¾ç¤ºä¸€è‡´ï¼Œä¾¿äºæ¯”è¾ƒå’Œåˆ†æã€‚

è¾…åŠ©è‡ªåŠ¨é¢„æ ‡æ³¨
é¢„å¤„ç†åçš„å›¾åƒæ›´é€‚åˆç”¨è‡ªåŠ¨æ£€æµ‹ç®—æ³•ï¼ˆä¾‹å¦‚ YOLOï¼‰è¿›è¡Œåˆæ­¥ç¼ºé™·æ£€æµ‹ï¼Œä»è€Œç”Ÿæˆé¢„æ ‡æ³¨ç»“æœã€‚æ ‡æ³¨äººå‘˜åªéœ€è¦åœ¨æ­¤åŸºç¡€ä¸Šè¿›è¡Œå¾®è°ƒï¼Œè€Œæ— éœ€ä»é›¶å¼€å§‹æ ‡æ³¨ï¼Œå¤§å¤§æé«˜äº†å·¥ä½œæ•ˆç‡ã€‚

ç»¼ä¸Šæ‰€è¿°ï¼Œå›¾ç‰‡é¢„å¤„ç†åœ¨æ ‡æ³¨è¿‡ç¨‹ä¸­æ‰®æ¼”äº†æå‡å›¾åƒè´¨é‡ã€çªå‡ºå…³é”®ä¿¡æ¯å’Œè¾…åŠ©è‡ªåŠ¨é¢„æ ‡æ³¨çš„é‡è¦è§’è‰²ï¼Œä»è€Œå¸®åŠ©æ ‡æ³¨äººå‘˜æ›´é«˜æ•ˆã€å‡†ç¡®åœ°å®Œæˆç¼ºé™·æ ‡æ³¨ä»»åŠ¡ã€‚



ä¸‹é¢é€è¡Œè§£é‡Š task_generator å‡½æ•°çš„ä»£ç é€»è¾‘ï¼Œå¸®åŠ©ä½ ç†è§£æ¯ä¸€éƒ¨åˆ†çš„ä½œç”¨ï¼š

python
è¤‡è£½
def task_generator(images, crop_size, metadatas=None, method="minmax", model_path=None, label_type="rectangle", existing_labels=None):
å‡½æ•°å£°æ˜ä¸å‚æ•°ï¼š
imagesï¼šä¸€ä¸ªåŒ…å«é¢„å¤„ç†åå›¾åƒçš„åˆ—è¡¨ï¼Œè¿™é‡Œè¦æ±‚è‡³å°‘åŒ…å« 6 å¼ å›¾åƒï¼ˆé€šå¸¸æ˜¯ image1~image6ï¼Œåˆ†åˆ«å¯¹åº”å‚è€ƒå›¾ã€æµ‹è¯•å›¾ã€å·®åˆ†å›¾ç­‰ï¼‰ã€‚
crop_sizeï¼šç”¨äºç”Ÿæˆé¢„æ ‡æ³¨æ—¶è¾¹ç•Œæ¡†çš„å°ºå¯¸å‚æ•°ï¼ˆä¾‹å¦‚ï¼ŒåŸºäº min/max ä½ç½®ç”Ÿæˆçš„å€™é€‰æ¡†å¤§å°ï¼‰ã€‚
metadatasï¼šåŒ…å«å›¾åƒé…å‡†åŠå·®åˆ†å›¾è®¡ç®—åç”Ÿæˆçš„å…ƒæ•°æ®ä¿¡æ¯ï¼ˆå¦‚å¹³ç§»ã€æœ€å¤§/æœ€å°å·®åˆ†ç‚¹ä½ç½®ç­‰ï¼‰ï¼Œå¯èƒ½å¯¹é¢„æ ‡æ³¨æœ‰è¾…åŠ©ä½œç”¨ã€‚
methodï¼šé¢„æ ‡æ³¨çš„æ–¹æ³•é€‰æ‹©ï¼Œä¾‹å¦‚ "minmax"ï¼ˆåŸºäºæœ€å°æœ€å¤§å·®åˆ†ç‚¹ç”Ÿæˆï¼‰æˆ–è€… "YOLO"ï¼ˆåŸºäºæ·±åº¦å­¦ä¹ æ£€æµ‹ï¼‰ã€‚
model_pathï¼šå½“ä½¿ç”¨ YOLO æ–¹æ³•æ—¶ï¼Œæ¨¡å‹æƒé‡æ–‡ä»¶çš„è·¯å¾„ã€‚
label_typeï¼šæ ‡æ³¨ç±»å‹ï¼Œé»˜è®¤æ˜¯ "rectangle"ï¼ˆçŸ©å½¢æ ‡æ³¨ï¼‰ã€‚
existing_labelsï¼šè‹¥å·²å­˜åœ¨æ ‡æ³¨æ•°æ®ï¼Œåˆ™ä¼ å…¥å·²æœ‰æ ‡æ³¨ä¿¡æ¯ï¼Œé¿å…é‡æ–°ç”Ÿæˆé¢„æ ‡æ³¨ã€‚
python
è¤‡è£½
    task = {
        'completions': [],
        'predictions': [],
        'id': 1,
        'data': {
            'image1': f"data:image/jpeg;base64,{images[0]}",
            'image2': f"data:image/jpeg;base64,{images[1]}",
            'image3': f"data:image/jpeg;base64,{images[2]}",
            'image4': f"data:image/jpeg;base64,{images[3]}",
            'image5': f"data:image/jpeg;base64,{images[4]}",
            'image6': f"data:image/jpeg;base64,{images[5]}"
        }
    }
æ„é€ ä»»åŠ¡å­—å…¸ taskï¼š
'completions'ï¼šä¸ºç©ºåˆ—è¡¨ï¼Œé€šå¸¸ç”¨äºå­˜å‚¨ç”¨æˆ·æœ€ç»ˆçš„æ ‡æ³¨å®Œæˆè®°å½•ï¼ˆè¿™é‡Œæš‚æœªä½¿ç”¨ï¼‰ã€‚
'predictions'ï¼šç”¨äºä¿å­˜é¢„æ ‡æ³¨ä¿¡æ¯ï¼ˆæˆ–å·²æœ‰æ ‡æ³¨ï¼‰ï¼Œç¨åä¼šå¡«å…¥ç”Ÿæˆçš„æ ‡æ³¨ç»“æœã€‚
'id'ï¼šä»»åŠ¡çš„æ ‡è¯†ç¬¦ï¼Œè®¾ç½®ä¸º 1ï¼ˆåœ¨ç®€å•ç¤ºä¾‹ä¸­å¯ä»¥å›ºå®šï¼‰ã€‚
'data'ï¼šå…³é”®éƒ¨åˆ†ï¼Œå°†å›¾åƒæ•°æ®ç»„ç»‡æˆä¸€ä¸ªå­—å…¸ï¼Œé”®åä¸º image1 è‡³ image6ï¼Œæ¯ä¸ªå€¼ä¸ºç»è¿‡ Base64 ç¼–ç çš„ JPEG å›¾ç‰‡å­—ç¬¦ä¸²ï¼Œå¹¶å¸¦ä¸Šæ•°æ®å¤´ï¼ˆ"data:image/jpeg;base64,"ï¼‰ï¼Œæ–¹ä¾¿å‰ç«¯ç›´æ¥æ˜¾ç¤ºã€‚
python
è¤‡è£½
    if existing_labels:
        annotations = extract_annotations(existing_labels)
        task['predictions'].append({
            'model_version': 'existing_labels',
            'result': annotations
        })
å·²æœ‰æ ‡æ³¨å¤„ç†ï¼š
å¦‚æœå‡½æ•°å‚æ•° existing_labels ä¸ä¸ºç©ºï¼Œåˆ™è¯´æ˜æ•°æ®åº“ä¸­å·²ç»æœ‰è¯¥å›¾åƒçš„æ ‡æ³¨æ•°æ®ã€‚
è°ƒç”¨ extract_annotations(existing_labels) ä»å·²æœ‰æ•°æ®ä¸­æå–æ ‡æ³¨ï¼ˆä¾‹å¦‚æ¯ä¸ªåŒºåŸŸçš„è¾¹ç•Œæ¡†ã€æ ‡ç­¾ç­‰ï¼‰ã€‚
å°†æå–å‡ºçš„æ ‡æ³¨ç»“æœåŒ…è£…æˆä¸€ä¸ªå­—å…¸ï¼Œæ ‡è¯†æ¨¡å‹ç‰ˆæœ¬ä¸º "existing_labels"ï¼Œå¹¶è¿½åŠ åˆ° task['predictions'] ä¸­ã€‚
python
è¤‡è£½
    else:
        print("no labels found, generating prelabels...")
        annotations = generate_prelabels(metadatas, crop_size, method=method, model_path=model_path, t_image=images[2], rt_image=images[5], label_type=label_type)
        task['predictions'].append({
            'model_version': 'prelabeling',
            'result': annotations
        })
ç”Ÿæˆé¢„æ ‡æ³¨ï¼š
å¦‚æœ existing_labels ä¸ºç©ºï¼Œè¯´æ˜å½“å‰å›¾åƒè¿˜æ²¡æœ‰æ ‡æ³¨æ•°æ®ï¼Œæ­¤æ—¶éœ€è¦ç”Ÿæˆé¢„æ ‡æ³¨ç»“æœã€‚
æ‰“å°æç¤ºä¿¡æ¯ï¼š"no labels found, generating prelabels..."ã€‚
è°ƒç”¨ generate_prelabels å‡½æ•°ï¼Œä¼ å…¥ï¼š
metadatasï¼šå›¾åƒé…å‡†åç”Ÿæˆçš„å…ƒæ•°æ®ï¼Œå¯èƒ½åŒ…å«å·®åˆ†å›¾ä¸­æœ€å¤§/æœ€å°ç‚¹ç­‰ä¿¡æ¯ï¼›
crop_sizeï¼šç”¨äºç¡®å®šå€™é€‰æ¡†å¤§å°ï¼›
methodï¼šé€‰æ‹©ä½¿ç”¨å“ªç§é¢„æ ‡æ³¨ç­–ç•¥ï¼ˆä¾‹å¦‚ "minmax" æˆ– "YOLO"ï¼‰ï¼›
model_pathï¼šè‹¥æ–¹æ³•ä¸º YOLOï¼ŒæŒ‡å®šæ¨¡å‹æƒé‡è·¯å¾„ï¼›
t_imageï¼šä¼ å…¥ images[2]ï¼Œé€šå¸¸ä½œä¸ºå·®åˆ†å›¾æˆ–è€…ç”¨äºæ£€æµ‹çš„å›¾åƒï¼›
rt_imageï¼šä¼ å…¥ images[5]ï¼Œå¦ä¸€ç±»å›¾åƒï¼ˆæ¯”å¦‚å³ä¾§æˆ–å¦ä¸€è§’åº¦çš„å·®åˆ†å›¾ï¼‰ï¼›
label_typeï¼šæ ‡æ³¨çš„ç±»å‹ï¼ˆä¾‹å¦‚çŸ©å½¢ï¼‰ã€‚
å¾—åˆ°ç”Ÿæˆçš„é¢„æ ‡æ³¨ç»“æœåï¼Œå°†å®ƒä»¥å­—å…¸å½¢å¼å­˜å…¥ task['predictions']ï¼Œå¹¶æ ‡è®°ç‰ˆæœ¬ä¸º "prelabeling"ã€‚
python
è¤‡è£½
    return task
è¿”å›ä»»åŠ¡æ•°æ®ï¼š
æœ€åï¼Œå°†æ„é€ å¥½çš„ä»»åŠ¡å­—å…¸ task è¿”å›ã€‚è¯¥å­—å…¸åŒ…å«æ‰€æœ‰å‰ç«¯æ‰€éœ€çš„æ•°æ®å’Œæ ‡æ³¨ä¿¡æ¯ï¼Œä¾› Label Studio ç»„ä»¶åŠ è½½æ˜¾ç¤ºã€‚
æ€»ç»“
ä»»åŠ¡æ„å»ºçš„æ ¸å¿ƒç›®çš„æ˜¯ï¼šå°†ç»è¿‡é¢„å¤„ç†åçš„å›¾åƒå’Œè‡ªåŠ¨ç”Ÿæˆï¼ˆæˆ–å·²æœ‰ï¼‰çš„æ ‡æ³¨ç»“æœæ•´åˆä¸ºä¸€ä¸ªç¬¦åˆ Label Studio æ¥å£è¦æ±‚çš„æ•°æ®ç»“æ„ã€‚
å…³é”®æ­¥éª¤ï¼š
å°† 6 å¼ å›¾åƒï¼ˆå‚è€ƒå›¾ã€æµ‹è¯•å›¾ã€å·®åˆ†å›¾ç­‰ï¼‰è½¬æ¢ä¸º Base64 å­—ç¬¦ä¸²ï¼Œå¹¶ç»„ç»‡æˆä»»åŠ¡æ•°æ®çš„ data éƒ¨åˆ†ã€‚
æ£€æŸ¥æ˜¯å¦æœ‰ç°æˆçš„æ ‡æ³¨æ•°æ®ï¼Œè‹¥æœ‰åˆ™æå–å¹¶ç›´æ¥ä½¿ç”¨ï¼›è‹¥æ— ï¼Œåˆ™è°ƒç”¨è‡ªåŠ¨é¢„æ ‡æ³¨å‡½æ•°ç”Ÿæˆé¢„æ ‡æ³¨ä¿¡æ¯ã€‚
å°†é¢„æ ‡æ³¨ç»“æœå°è£…åˆ° predictions å­—æ®µä¸­ï¼Œå¹¶è¿”å›æ•´ä¸ªä»»åŠ¡å­—å…¸ã€‚
è¿™æ ·è®¾è®¡ä½¿å¾—å‰ç«¯ç»„ä»¶æ—¢èƒ½æ˜¾ç¤ºé¢„å¤„ç†åçš„å›¾åƒï¼Œä¹Ÿèƒ½åŠ è½½æˆ–ç”Ÿæˆåˆå§‹çš„æ ‡æ³¨ç»“æœï¼Œæ–¹ä¾¿ç”¨æˆ·è¿›è¡Œäººå·¥æ ¡æ­£ã€‚




1. æ•°æ®åº“å­˜å‚¨çš„è®¾è®¡
æ•°æ®åº“è¡¨ç»“æ„
åœ¨ä»£ç ä¸­ï¼Œä½¿ç”¨ SQLite æ•°æ®åº“å­˜å‚¨æ ‡æ³¨ç»“æœï¼Œè¡¨ç»“æ„å®šä¹‰å¦‚ä¸‹ï¼ˆåœ¨ app.py ä¸­ï¼‰ï¼š

python
è¤‡è£½
conn = sqlite3.connect(db_path)
cursor = conn.cursor()
cursor.execute('''
CREATE TABLE IF NOT EXISTS results_table (
    id INTEGER PRIMARY KEY,
    image_path TEXT,
    results_json TEXT
)
''')
conn.commit()
conn.close()
idï¼šæ•°æ®åº“è‡ªåŠ¨ç”Ÿæˆçš„ä¸»é”®ã€‚
image_pathï¼šç”¨äºå”¯ä¸€æ ‡è¯†ä¸€å¼ å›¾ç‰‡ï¼Œä¸€èˆ¬ç”±æ•°æ®ç›®å½•ã€Lot IDã€Image ID ç»„åˆè€Œæˆã€‚
results_jsonï¼šå­˜å‚¨æ ‡æ³¨ç»“æœçš„ JSON å­—ç¬¦ä¸²ï¼Œè¿™ä¸ª JSON å­—ç¬¦ä¸²åŒ…å«äº†å‰ç«¯æ ‡æ³¨çš„è¯¦ç»†å†…å®¹ï¼ˆå¦‚æ ‡æ³¨åŒºåŸŸã€æ ‡ç­¾ã€åæ ‡ç­‰ï¼‰ã€‚
2. å‰ç«¯æ ‡æ³¨ç»“æœå¦‚ä½•å­˜å‚¨
å…³é”®å‡½æ•°ä»‹ç»
2.1 fetch_results
ä½œç”¨ï¼šåœ¨ç”¨æˆ·åŠ è½½æŸå¼ å›¾ç‰‡æ—¶ï¼Œé€šè¿‡ image_path ä»æ•°æ®åº“ä¸­æŸ¥æ‰¾è¯¥å›¾ç‰‡æ˜¯å¦å·²æœ‰æ ‡æ³¨è®°å½•ã€‚
ä»£ç é€»è¾‘ï¼ˆç®€åŒ–ç‰ˆï¼‰ï¼š
python
è¤‡è£½
def fetch_results(image_path, db_path):
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    cursor.execute('SELECT results_json FROM results_table WHERE image_path = ?', (image_path,))
    result = cursor.fetchone()
    conn.close()
    if result:
        return json.loads(result[0])
    return None
ä½¿ç”¨åœºæ™¯ï¼šåœ¨ app.py ä¸­ï¼ŒåŠ è½½å½“å‰å›¾åƒä¹‹å‰ï¼Œä¼šå…ˆè°ƒç”¨è¯¥å‡½æ•°ï¼Œå¦‚æœæœ‰è®°å½•ï¼Œåˆ™å°†å·²æœ‰æ ‡æ³¨åŠ è½½åˆ° Label Studio ç»„ä»¶ä¸­ï¼Œæ–¹ä¾¿ç”¨æˆ·ä¿®æ”¹æˆ–æŸ¥çœ‹å·²æœ‰ç»“æœã€‚
2.2 save_json_to_sqlite
ä½œç”¨ï¼šå½“ç”¨æˆ·åœ¨å‰ç«¯æ ‡æ³¨é¡µé¢æäº¤æ ‡æ³¨ç»“æœåï¼Œå°†è¿”å›çš„ JSON æ ‡æ³¨ç»“æœå­˜å…¥æ•°æ®åº“ä¸­ã€‚
ä»£ç é€»è¾‘ï¼ˆç®€åŒ–ç‰ˆï¼‰ï¼š
python
è¤‡è£½
def save_json_to_sqlite(img_path, results_raw, db_path):
    json_string = json.dumps(results_raw)
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    # æ£€æŸ¥è¯¥ image_path æ˜¯å¦å·²æœ‰è®°å½•
    cursor.execute('SELECT results_json FROM results_table WHERE image_path = ?', (img_path,))
    existing_entry = cursor.fetchone()
    if existing_entry:
        existing_json_string = existing_entry[0]
        if existing_json_string == json_string:
            print("Same img_path and same results_raw. No update needed.")
        else:
            cursor.execute('UPDATE results_table SET results_json = ? WHERE image_path = ?', (json_string, img_path))
            print("Same img_path but different results_raw. Updated the entry.")
    else:
        cursor.execute('INSERT INTO results_table (image_path, results_json) VALUES (?, ?)', (img_path, json_string))
        print("New img_path. Inserted a new entry.")
    conn.commit()
    conn.close()
    print("Connection closed")
ä½¿ç”¨åœºæ™¯ï¼šåœ¨å‰ç«¯æ ‡æ³¨æäº¤åï¼Œapp.py ä¼šæ£€æŸ¥è¿”å›çš„ results_rawï¼ˆæ ‡æ³¨ç»“æœï¼‰ï¼Œå¹¶è°ƒç”¨è¯¥å‡½æ•°æŠŠæ ‡æ³¨ç»“æœä¸å¯¹åº”çš„ image_path å†™å…¥æ•°æ®åº“ã€‚è¿™æ ·ä¸‹æ¬¡åŠ è½½è¯¥å›¾ç‰‡æ—¶ï¼Œå°±èƒ½é€šè¿‡ fetch_results æ‰¾åˆ°å¯¹åº”çš„æ ‡æ³¨æ•°æ®ã€‚
3. å‰ç«¯å¦‚ä½•ä½¿ç”¨è¿™äº›åç«¯ä»£ç 
åœ¨ä½ çš„ app.py ä¸­ï¼Œæ•´ä¸ªæµç¨‹å¤§è‡´å¦‚ä¸‹ï¼š

åŠ è½½å›¾åƒåŠåˆå§‹åŒ–ä»»åŠ¡

æ ¹æ® Lot ID ä¸ Image ID æ„é€ ä¸€ä¸ªæ ‡è¯†ç¬¦ï¼ˆå¦‚ img_pathï¼‰ï¼Œä¾‹å¦‚ï¼š
python
è¤‡è£½
img_path = f"{data_dir}, {selected_lot_id}, {selected_image_id}"
é€šè¿‡ fetch_results(img_path, db_path) æ£€æŸ¥è¯¥å›¾ç‰‡æ˜¯å¦å·²æœ‰æ ‡æ³¨è®°å½•ã€‚å¦‚æœæœ‰ï¼Œå°±ç›´æ¥åŠ è½½å·²æœ‰æ ‡æ³¨ï¼›å¦åˆ™ï¼Œä½¿ç”¨é¢„æ ‡æ³¨é€»è¾‘ç”Ÿæˆåˆå§‹æ ‡æ³¨ã€‚
æ„é€ ä»»åŠ¡å¹¶è°ƒç”¨ Label Studio ç»„ä»¶

è°ƒç”¨ task_generator æ„é€ ä»»åŠ¡æ•°æ®ï¼Œå°†å›¾åƒæ•°æ®å’Œé¢„æ ‡æ³¨æˆ–å·²æœ‰æ ‡æ³¨å°è£…åœ¨ä»»åŠ¡å­—å…¸ä¸­ï¼Œç„¶åè°ƒç”¨ï¼š
python
è¤‡è£½
results_raw = st_labelstudio(config, interfaces, user, task_generator(...))
ç»„ä»¶ä¼šå±•ç¤ºå›¾åƒåŠæ ‡æ³¨ä¿¡æ¯ï¼Œç”¨æˆ·å¯ä»¥å¯¹å…¶è¿›è¡Œä¿®æ”¹ã€‚
æäº¤æ ‡æ³¨åä¿å­˜åˆ°åç«¯

å½“ç”¨æˆ·ç‚¹å‡»â€œSubmitâ€åï¼Œç»„ä»¶è¿”å›æ›´æ–°åçš„æ ‡æ³¨ç»“æœï¼ˆJSON æ ¼å¼ï¼‰ã€‚åœ¨ app.py ä¸­ï¼Œä»£ç ä¼šæ£€æµ‹æ˜¯å¦æœ‰å˜åŒ–ï¼ˆä½¿ç”¨ has_results_raw_changed å‡½æ•°ï¼‰ã€‚
å¦‚æœæœ‰å˜åŒ–ï¼Œåˆ™è°ƒç”¨ save_json_to_sqlite(img_path, results_raw, db_path) å°†æœ€æ–°çš„æ ‡æ³¨ç»“æœå­˜å…¥æ•°æ®åº“ä¸­ã€‚
é¡µé¢åˆ·æ–°ä¸æ•°æ®æ›´æ–°

ä¿å­˜æˆåŠŸåï¼Œç¨‹åºæ›´æ–° st.session_state.image_indexï¼Œç„¶åè°ƒç”¨ st.rerun() åˆ·æ–°é¡µé¢ï¼Œè¿™æ ·ä¸‹ä¸€æ¬¡åŠ è½½æ—¶ï¼Œå°±ä¼šæ ¹æ®å½“å‰çš„ image_path ä½¿ç”¨ fetch_results ä»æ•°æ®åº“ä¸­åŠ è½½æœ€æ–°æ ‡æ³¨è®°å½•ã€‚
4. æ€»ç»“
åç«¯æ•°æ®åº“ä¸»è¦é€šè¿‡ image_path æ¥ä½œä¸ºå”¯ä¸€æ ‡è¯†ï¼Œæ¯ä¸ªæ ‡æ³¨è®°å½•ä»¥ JSON å­—ç¬¦ä¸²çš„å½¢å¼ä¿å­˜åˆ° results_json å­—æ®µã€‚
å½“ç”¨æˆ·åŠ è½½å›¾ç‰‡æ—¶ï¼Œè°ƒç”¨ fetch_results æ£€æŸ¥æ˜¯å¦æœ‰ç°æˆçš„æ ‡æ³¨ï¼Œè‹¥æœ‰åˆ™åŠ è½½åˆ°å‰ç«¯ã€‚
å½“ç”¨æˆ·å®Œæˆæ ‡æ³¨å¹¶æäº¤åï¼Œè°ƒç”¨ save_json_to_sqlite å°†è¿”å›çš„æ ‡æ³¨ç»“æœå­˜å‚¨æˆ–æ›´æ–°åˆ°æ•°æ®åº“ä¸­ã€‚
è¿™å¥—æµç¨‹ä¿è¯äº†å‰ç«¯æ ‡æ³¨ç»“æœèƒ½å¤ŸæŒä¹…åŒ–å­˜å‚¨ï¼Œæ–¹ä¾¿åç»­æŸ¥è¯¢ã€æ›´æ–°æˆ–å¯¼å‡ºæ•°æ®ç”¨äºè®­ç»ƒæ¨¡å‹ã€‚



1. åˆå§‹åŒ–ä¸è®¾ç½®
é¡µé¢é…ç½®ä¸çŠ¶æ€åˆå§‹åŒ–
é¡µé¢è®¾ç½®
åœ¨æ–‡ä»¶æœ€å¼€å§‹è°ƒç”¨äº†ï¼š

python
è¤‡è£½
st.set_page_config(layout='wide')
è¿™å°†é¡µé¢å¸ƒå±€è®¾ç½®ä¸ºå®½å±æ¨¡å¼ï¼Œä¿è¯åœ¨æ˜¾ç¤ºå¤šå¼ å›¾åƒï¼ˆä¾‹å¦‚ 6 å¼ å›¾åƒè§†å›¾ï¼‰æ—¶èƒ½å¤Ÿæœ‰è¶³å¤Ÿç©ºé—´ã€‚

Session State çš„åˆå§‹åŒ–
ä¸ºäº†åœ¨é¡µé¢åˆ·æ–°æ—¶ä¿æŒä¸€äº›çŠ¶æ€ä¿¡æ¯ï¼ˆä¾‹å¦‚å½“å‰å›¾åƒç´¢å¼•ã€æ‰¹æ¬¡ç´¢å¼•ä»¥åŠä¸Šä¸€æ¬¡æäº¤çš„æ ‡æ³¨ç»“æœï¼‰ï¼Œä»£ç æ£€æŸ¥å¹¶åˆå§‹åŒ–äº†ä»¥ä¸‹å˜é‡ï¼š

python
è¤‡è£½
if 'previous_results_raw' not in st.session_state:
    st.session_state.previous_results_raw = None
if 'image_index' not in st.session_state:
    st.session_state.image_index = 0
if 'lot_index' not in st.session_state:
    st.session_state.lot_index = 0
è¿™äº›å˜é‡åç»­ç”¨äºæ§åˆ¶ç”¨æˆ·æµè§ˆå›¾åƒã€ä¿æŒå·²æœ‰æ ‡æ³¨æ•°æ®ä»¥åŠç®¡ç†æ‰¹æ¬¡åˆ‡æ¢ã€‚

2. æ•°æ®åº“åˆå§‹åŒ–
åœ¨å‰ç«¯å¯åŠ¨æ—¶ï¼Œä»£ç ä¼šè¿æ¥ SQLite æ•°æ®åº“å¹¶åˆ›å»ºå­˜å‚¨æ ‡æ³¨ç»“æœçš„è¡¨ï¼š

python
è¤‡è£½
conn = sqlite3.connect(db_path)
cursor = conn.cursor()
cursor.execute('''
CREATE TABLE IF NOT EXISTS results_table (
    id INTEGER PRIMARY KEY,
    image_path TEXT,
    results_json TEXT
)
''')
conn.commit()
conn.close()
ç»“æœè¡¨ç»“æ„ï¼š
image_path ç”¨ä½œå”¯ä¸€æ ‡è¯†ï¼Œæ¯æ¡è®°å½•å¯¹åº”ä¸€å¼ å›¾ç‰‡ã€‚
results_json å­˜å‚¨æ ‡æ³¨æ•°æ®ï¼ˆJSON æ ¼å¼ï¼‰ï¼Œè¿™éƒ¨åˆ†æ•°æ®ä¼šåœ¨æ ‡æ³¨æäº¤åå†™å…¥æ•°æ®åº“ä¸­ã€‚
3. ä¾§è¾¹æ é€‰æ‹©ä¸å›¾åƒå¯¼èˆª
æ•°æ®ç›®å½•ä¸æ‰¹æ¬¡ï¼ˆLot IDï¼‰é€‰æ‹©
é€šè¿‡è¯»å–æ•°æ®ç›®å½• data_dir ä¸‹çš„æ–‡ä»¶å¤¹ï¼Œç­›é€‰å‡ºæ‰€æœ‰æ‰¹æ¬¡ï¼ˆLot IDï¼‰ï¼Œæ’é™¤æ— å…³æ–‡ä»¶å¤¹ï¼ˆå¦‚ logï¼‰ã€‚
ä½¿ç”¨ st.sidebar.selectbox å±•ç¤ºæ‰¹æ¬¡åˆ—è¡¨ï¼Œç”¨æˆ·å¯ä»¥é€‰æ‹©ä¸åŒæ‰¹æ¬¡ï¼›åŒæ—¶ä»£ç åˆ©ç”¨ st.session_state.lot_index æ¥ä¿æŒå½“å‰é€‰ä¸­æ‰¹æ¬¡ã€‚
å›¾åƒç´¢å¼•ä¸å‰è¿›åé€€æŒ‰é’®
å›¾åƒç¼–å·åˆ—è¡¨
è°ƒç”¨å‡½æ•° get_lrf_file å’Œ get_defect_list å¾—åˆ°å½“å‰æ‰¹æ¬¡ä¸­çš„ç¼ºé™·æ–‡ä»¶åŠå¯¹åº”çš„å›¾åƒç¼–å·åˆ—è¡¨ï¼ˆä»¥åŠç¼ºé™·ç±»å‹ä¿¡æ¯ï¼‰ã€‚
æŒ‰é’®æ“ä½œ
åœ¨ä¾§è¾¹æ ä¸­è®¾ç½®äº†â€œPrevious Imageâ€å’Œâ€œNext Imageâ€æŒ‰é’®ï¼Œç‚¹å‡»åä¼šæ›´æ–° st.session_state.image_indexã€‚å½“åˆ°è¾¾å½“å‰æ‰¹æ¬¡çš„å¤´æˆ–å°¾æ—¶ï¼Œè¿˜ä¼šè‡ªåŠ¨æ›´æ–° lot_indexï¼ˆå³åˆ‡æ¢æ‰¹æ¬¡ï¼‰ï¼Œä»è€Œå®ç°è¿ç»­æµè§ˆæ•´ä¸ªæ•°æ®é›†ã€‚
å›¾åƒç¼–å·é€‰æ‹©
åˆ©ç”¨ st.sidebar.selectbox å±•ç¤ºå½“å‰æ‰¹æ¬¡ä¸­çš„å›¾åƒç¼–å·ï¼Œå…è®¸ç”¨æˆ·ç›´æ¥é€‰æ‹©æŸå¼ å›¾åƒè¿›è¡Œæ ‡æ³¨ã€‚
4. å›¾åƒé¢„å¤„ç†ä¸ä»»åŠ¡æ•°æ®æ„å»º
è·å–å¤„ç†åçš„å›¾åƒæ•°æ®
è°ƒç”¨ get_image_pair_for_studio_input
è¿™éƒ¨åˆ†ä»£ç åˆ†åˆ«ä¸ºä¸¤ç§å›¾åƒç±»å‹ï¼ˆä¾‹å¦‚æ ‡è®°ä¸º "T" å’Œ "Rt"ï¼‰è°ƒç”¨è¯¥å‡½æ•°ï¼Œå®Œæˆä»¥ä¸‹æ“ä½œï¼š

åŠ è½½å›¾åƒå¯¹ï¼šé€šè¿‡ Lot IDã€Image ID å®šä½åˆ°å¯¹åº”çš„å›¾åƒæ–‡ä»¶å¤¹ï¼Œä»ä¸­åŠ è½½æµ‹è¯•å›¾å’Œå‚è€ƒå›¾ã€‚
å›¾åƒå¯¹é½ä¸å·®åˆ†è®¡ç®—ï¼šè°ƒç”¨å†…éƒ¨çš„ load_defect_pair å’Œ get_diff_map è¿›è¡Œå›¾åƒé…å‡†ï¼Œè®¡ç®—ä¸¤å›¾å·®åˆ†ï¼ˆç”¨æ¥çªå‡ºç¼ºé™·ï¼‰ã€‚
é¢œè‰²æ˜ å°„ä¸å·ç§¯æ»¤æ³¢ï¼šå¯¹å‚è€ƒå›¾ã€æµ‹è¯•å›¾ä½¿ç”¨ç°åº¦æ˜ å°„ï¼Œå¯¹å·®åˆ†å›¾ä½¿ç”¨â€œseismicâ€æ˜ å°„ï¼Œå†ç»è¿‡å·ç§¯æ»¤æ³¢å¹³æ»‘å¤„ç†ã€‚
Base64 ç¼–ç ï¼šå°†å¤„ç†åçš„å›¾åƒè½¬æ¢ä¸º Base64 ç¼–ç å­—ç¬¦ä¸²ï¼Œæ–¹ä¾¿ç›´æ¥åµŒå…¥ HTML æ˜¾ç¤ºã€‚
ç»„åˆå›¾åƒæ•°æ®
å¾—åˆ°çš„å›¾åƒæ•°æ®è¢«ç»„åˆæˆä¸€ä¸ªåˆ—è¡¨ images_base64ï¼Œé€šå¸¸åŒ…å« 6 ä¸ªè§†å›¾ï¼ˆä¾‹å¦‚ image1~image6ï¼Œå¯¹åº”ä¸åŒè§’åº¦æˆ–å¤„ç†æ–¹å¼çš„å›¾åƒï¼‰ã€‚

æ„é€ ä»»åŠ¡æ•°æ®ï¼ˆTaskï¼‰
è°ƒç”¨ task_generator
ä½¿ç”¨é¢„å¤„ç†åçš„å›¾åƒå’Œéƒ¨åˆ†å…ƒæ•°æ®ï¼ˆmetadatasï¼‰ï¼Œè°ƒç”¨ task_generator æ„é€ ä»»åŠ¡å­—å…¸ï¼š
ä»»åŠ¡å­—å…¸çš„ data å­—æ®µä¸­å­˜æ”¾å›¾åƒæ•°æ®ï¼ˆä»¥ "data:image/jpeg;base64,..." æ ¼å¼ï¼‰ï¼Œä¾› Label Studio ç»„ä»¶åŠ è½½ã€‚
å¦‚æœæ•°æ®åº“ä¸­å·²å­˜åœ¨æ ‡æ³¨ï¼ˆé€šè¿‡ fetch_results åˆ¤æ–­ï¼‰ï¼Œåˆ™å°†å·²æœ‰æ ‡æ³¨ä¼ å…¥ï¼›å¦åˆ™ï¼Œæ ¹æ®é¢„è®¾æ–¹æ³•ï¼ˆä¾‹å¦‚ YOLO æˆ– minmaxï¼‰ç”Ÿæˆé¢„æ ‡æ³¨ä¿¡æ¯ï¼Œå¹¶å°†å…¶å­˜å…¥ predictions å­—æ®µã€‚
5. å‰ç«¯æ ‡æ³¨äº¤äº’ä¸ç»“æœæäº¤
Label Studio ç»„ä»¶è°ƒç”¨
è°ƒç”¨ï¼š
python
è¤‡è£½
results_raw = st_labelstudio(config, interfaces, user, task_generator(...))
è¿™ä¸€æ­¥å¯åŠ¨äº† Label Studio ç»„ä»¶ï¼Œå±•ç¤ºä»»åŠ¡æ•°æ®ï¼ˆå›¾åƒåŠæ ‡æ³¨ï¼‰ç»™ç”¨æˆ·ã€‚
configï¼šå®šä¹‰äº†å‰ç«¯ç•Œé¢å¸ƒå±€ï¼ˆå¦‚ä¸¤è¡Œæ˜¾ç¤ºå›¾åƒã€æ¯ä¸ªå›¾åƒå¯¹åº”çš„æ ‡æ³¨å·¥å…·ï¼‰ã€‚
interfaces ä¸ userï¼šé…ç½®äº†ç”¨æˆ·ç•Œé¢ä¸­æ˜¾ç¤ºçš„å·¥å…·å’Œå½“å‰æ ‡æ³¨è€…ä¿¡æ¯ã€‚
task_generator è¿”å›çš„ä»»åŠ¡æ•°æ®åŒ…å«äº†å›¾åƒå’Œåˆå§‹æ ‡æ³¨ã€‚
ç”¨æˆ·æ ‡æ³¨ä¸æäº¤
ç”¨æˆ·åœ¨å‰ç«¯äº¤äº’ç•Œé¢ä¸­å¯ä»¥è°ƒæ•´é¢„æ ‡æ³¨çš„è¾¹ç•Œæ¡†æˆ–ç›´æ¥æ·»åŠ æ–°çš„æ ‡æ³¨ã€‚
å½“ç”¨æˆ·ç‚¹å‡»â€œSubmitâ€åï¼ŒLabel Studio ç»„ä»¶ä¼šå°†æ ‡æ³¨ç»“æœï¼ˆJSON æ ¼å¼ï¼‰è¿”å›ç»™åº”ç”¨ï¼Œå¹¶å­˜å‚¨åœ¨å˜é‡ results_raw ä¸­ã€‚
æ ‡æ³¨ç»“æœå¤„ç†ä¸å­˜å‚¨
æ£€æµ‹æ ‡æ³¨å˜åŒ–
ä½¿ç”¨ has_results_raw_changed å‡½æ•°æ¯”è¾ƒå½“å‰æäº¤çš„æ ‡æ³¨æ•°æ®ä¸ä¸Šæ¬¡æäº¤çš„æ•°æ®æ˜¯å¦æœ‰å˜åŒ–ï¼Œä»¥é¿å…é‡å¤ä¿å­˜ã€‚
ä¿å­˜åˆ°æ•°æ®åº“
è°ƒç”¨ save_json_to_sqlite(img_path, results_raw, db_path)ï¼Œå°†å½“å‰ image_path å¯¹åº”çš„æ ‡æ³¨ç»“æœå†™å…¥æ•°æ®åº“ï¼ˆå¦‚æœ‰é‡å¤åˆ™æ›´æ–°è®°å½•ï¼‰ã€‚
æ›´æ–°çŠ¶æ€ä¸åˆ·æ–°é¡µé¢
ä¿å­˜å®Œæˆåï¼Œæ›´æ–° st.session_state.image_indexï¼ˆè‡ªåŠ¨åˆ‡æ¢åˆ°ä¸‹ä¸€å¼ å›¾åƒï¼‰ï¼Œå¹¶è°ƒç”¨ st.rerun() åˆ·æ–°é¡µé¢ï¼Œä½¿å¾—ä¸‹æ¬¡åŠ è½½æ—¶èƒ½æ˜¾ç¤ºæœ€æ–°çš„æ ‡æ³¨è®°å½•ã€‚
6. æ•´ä½“æµç¨‹æ€»ç»“
åˆå§‹åŒ–ï¼šè®¾ç½®é¡µé¢å¸ƒå±€ã€åˆå§‹åŒ– Session State ä¸æ•°æ®åº“è¡¨ã€‚
ä¾§è¾¹æ é€‰æ‹©ï¼šç”¨æˆ·é€šè¿‡ä¾§è¾¹æ é€‰æ‹©æ‰¹æ¬¡ï¼ˆLot IDï¼‰å’Œå›¾åƒç¼–å·ï¼ŒåŒæ—¶é€šè¿‡å‰åæŒ‰é’®å¯¼èˆªæµè§ˆå›¾åƒã€‚
å›¾åƒé¢„å¤„ç†ï¼šè°ƒç”¨ç›¸å…³å‡½æ•°åŠ è½½å›¾åƒå¯¹ï¼Œè¿›è¡Œå›¾åƒé…å‡†ã€å·®åˆ†è®¡ç®—ã€é¢œè‰²æ˜ å°„åŠå·ç§¯æ»¤æ³¢ï¼Œæœ€ç»ˆè½¬æ¢æˆ Base64 æ ¼å¼ã€‚
ä»»åŠ¡æ„å»ºï¼šå°†å›¾åƒæ•°æ®å’Œé¢„æ ‡æ³¨æˆ–å·²æœ‰æ ‡æ³¨æ•´åˆåˆ°ä»»åŠ¡å­—å…¸ä¸­ï¼Œä¼ é€’ç»™ Label Studio ç»„ä»¶ã€‚
ç”¨æˆ·æ ‡æ³¨ï¼šç”¨æˆ·åœ¨äº¤äº’ç•Œé¢ä¸­ä¿®æ”¹æˆ–ç¡®è®¤æ ‡æ³¨ï¼Œæäº¤åè¿”å›æ ‡æ³¨ç»“æœã€‚
ç»“æœå­˜å‚¨ä¸æ›´æ–°ï¼šæ£€æµ‹ç»“æœå˜åŒ–åï¼Œé€šè¿‡ save_json_to_sqlite å°†æ ‡æ³¨ç»“æœå­˜å…¥ SQLite æ•°æ®åº“ï¼ŒåŒæ—¶æ›´æ–° Session State å¹¶åˆ·æ–°é¡µé¢ã€‚
è¿™ç§è®¾è®¡ä½¿å¾—å‰ç«¯å’Œåç«¯ä¹‹é—´å½¢æˆä¸€ä¸ªé—­ç¯ï¼šç”¨æˆ·æ¯æ¬¡æ ‡æ³¨éƒ½ä¼šå†™å…¥æ•°æ®åº“ï¼Œä¸‹æ¬¡åŠ è½½æ—¶ç›´æ¥ä»æ•°æ®åº“è¯»å–å·²æœ‰æ ‡æ³¨ï¼Œä¿è¯æ•°æ®çš„ä¸€è‡´æ€§å’ŒæŒä¹…åŒ–å­˜å‚¨ï¼ŒåŒæ—¶æ”¯æŒç”¨æˆ·åœ¨æ¯æ¬¡æ ‡æ³¨åè‡ªåŠ¨åˆ‡æ¢åˆ°ä¸‹ä¸€å¼ å›¾åƒè¿›è¡Œè¿ç»­ä½œä¸šã€‚





